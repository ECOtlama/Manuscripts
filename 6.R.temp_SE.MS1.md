##Population genomics of Rana temporaria across the latitudinal environmental gradient in Scandinavia. 

Adaptation across elevation in Andrew's toad. 

http://onlinelibrary.wiley.com/doi/10.1111/mec.13722/abstract?campaign=woletoc

LHT variation in Rana temporaria across latitude. 

Very little known about their population structure. 

Aim: 

Detect loci associated with environment across latitude

1. Characterise population structure

2. Genome scan for ecologically relevant loci related to the latitudinal gradient. 

3. Spatial interpolation of genomic turnover/ temporal interpolation of genomic turnover (GF + GDM)










***
Compare to Johannsen et al. 2006

http://onlinelibrary.wiley.com/doi/10.1111/j.1365-294X.2006.02866.x/full

 (i) Are there clear geographic patterns of within population genetic variability and degree of among population genetic variability in this species? 
 
 (ii) Are there clear geographic patterns of occurrence and population sizes in this species? 
 
 (iii) Is there evidence that the current patterns of genetic variability and differentiation in this species are better explained by their current demography, rather than their colonization history?

1. What is the fine-scale connectivity within each sampling area?

2. IBD vs IBE?

3. Signatures of selection? 

I will run analyses based on Laurent et al. 2015 (white sand lizards) http://onlinelibrary.wiley.com/doi/10.1111/mec.13385/epdf
****



1. Population Structure 
   
  - PCA
  - TESS3
  - fastStructure
 
  - IBD
  
  - Fst
 
2.1 Outlier detection

2.2 Environmental Association Analysis

3.1 Random Forest

3.2 GDM


##Data

1. All data

2. Subset of the data adjusted for the number of reads (rerun pyRAD)

###Dataset1



###Dataset2 

copy all the .edit files from SEFinalSamples.edits > SEFinalSamples/subset5Mil.SE/edits

count the reads for each sample

```
grep -c ^'>' *edit -> SE.readcount
```

Downsample to 1Mil reads per sample. (Mostly because Finland samples have such few reads, and this population would drop out if I increased the minimum number of reads). 

Use a perl script (random_sequence_sample.pl). Which I've uploaded on gdc (and the mac). 


```
for i in edits/*.fq.trim.edit; do perl random_sequence_sample.pl -i $i -o subset/$i.subset.edit -n 1000000; done
```


###Filter Dataset

####Dataset 2

/gdc_home4/alexjvr/SEFinalSamples/subset1Mil.SE/outfiles/subset.Filter/SEsubset.vcf


Filter for missingness of 0.5 and MAC 3 (3/(118*2) = 1.2% MAF)

50% genotyping rate. And MAC of 3. (across 230 indivs = 3/460 = 0.65%) - I should probably increase this! Rather use a MAF of 1%

```
vcftools --vcf SEsubset.vcf --max-missing 0.5 --mac 3 --recode --recode-INFO-all --out SEsubset.vcf.s2

Output:

Parameters as interpreted:
	--vcf SEsubset.vcf
	--recode-INFO-all
	--mac 3
	--max-missing 0.5
	--out SEsubset.vcf.s2
	--recode

Eighth Header entry should be INFO: INFO    
After filtering, kept 177 out of 177 Individuals
Outputting VCF file...
After filtering, kept 19866 out of a possible 410602 Sites
Run Time = 28.00 seconds
```

And check the missingness for the individuals:

```
vcftools --vcf SEsubset.vcf.s2.recode.vcf --missing-indv

mawk '!/IN/' out.imiss | cut -f5 > totalmissing

gnuplot << \EOF 
set terminal dumb size 120, 30
set autoscale 
unset label
set title "Histogram of % missing data per individual"
set ylabel "Number of Occurrences"
set xlabel "% of missing data"
#set yr [0:100000]
binwidth=0.01
bin(x,width)=width*floor(x/width) + binwidth/2.0
plot 'totalmissing' using (bin( $1,binwidth)):(1.0) smooth freq with boxes
pause -1
EOF
```

Output:

![alt_txt][Fig.1]
[Fig.1]:https://cloud.githubusercontent.com/assets/12142475/17670563/8015ec8c-630a-11e6-8822-646a217ea4eb.png

Most of the samples have <50% missing data.

And if I try with --max-missing 0.8 followed by the rest of the filtering

```
vcftools --vcf SEsubset.vcf --max-missing 0.8 --mac 3 --recode --recode-INFO-all --out SEsubset.s2_0.8

Parameters as interpreted:
	--vcf SEsubset.vcf
	--recode-INFO-all
	--mac 3
	--max-missing 0.8
	--out SEsubset.s2_0.8
	--recode

Eighth Header entry should be INFO: INFO    
After filtering, kept 177 out of 177 Individuals
Outputting VCF file...
After filtering, kept 4929 out of a possible 410602 Sites
Run Time = 24.00 seconds
```

![alt_txt][Fig.2]
[Fig.2]:https://cloud.githubusercontent.com/assets/12142475/17670824/aab2b5fa-630b-11e6-8d23-cdb6de5be98a.png

This is significantly less loci, and not much better i.t.o. missingness. So I will use the first filter, and remove the 7 individuals with >0.5 missingness

```
--vcf SEsubset.vcf.s2.recode.vcf --remove remove.names --recode --recode-INFO-all --out SEsubset.s3

VCFtools - v0.1.12b
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf SEsubset.vcf.s2.recode.vcf
	--exclude remove.names
	--recode-INFO-all
	--out SEsubset.s3
	--recode

Excluding individuals in 'exclude' list
After filtering, kept 167 out of 177 Individuals
Outputting VCF file...
After filtering, kept 19866 out of a possible 19866 Sites
Run Time = 3.00 seconds

```


Rename the samples in vcf file:

First get a list of all the samples:

```
bcftools query -l SEsubset.s3.recode.vcf
```

copy and paste this to excel. And rename accordingly (I remove the "cat" and ".fq.trim"). Nano and paste into a new file.

Paste back:

```
bcftools reheader SEsubset.s3.recode.vcf -s new.names -o SEsubset.s3.vcf
```

3. Thin to 1 SNP per locus:

```
vcftools --vcf SEsubset.s3.vcf --thin 500 --recode --recode-INFO-all --out SEsubset.s3.thinned.vcf

Parameters as interpreted:
	--vcf SEsubset.s3.vcf
	--recode-INFO-all
	--thin 500
	--out SEsubset.s3.thinned.vcf
	--recode

After filtering, kept 167 out of 167 Individuals
Outputting VCF file...
After filtering, kept 5290 out of a possible 19866 Sites
Run Time = 1.00 seconds
```

4.Filter for >0.6 obs Het

Based on my recent checks on the pyRAD data, I should also filter all SNPs with >0.7 observed Heterozygosity.

I will do this in R using the PLINK file.

Convert to plink

```
vcftools --vcf SEsubset.s3.thinned.vcf.recode.vcf --plink --out SEsubset.s4
```

Calculate HWE for all loci in PLINK

```
plink --file SEsubset.s4 --hardy
```

PLINK output plink.hwe has a very strange format - multiple spaces between columns - so I couldn't figure out how to cut a specific column using linux

I sorted everything in excel.

There are only 30 SNPs with O.Het >0.6 (i.e. 0.56%)

```
923:86
45299:91
131938:21
31269:23
15018:23
107525:44
80914:106
109021:9
53856:9
31387:44
88409:3
116529:47
17502:52
3086:06:00
33252:37
62935:14
121937:13
85675:18
132142:1
45819:46
75796:21
58278:85
130290:76
71033:77
95774:102
121298:22
67455:2
100258:5
113742:72
26:17:00
```

Remove with plink

```
nano SNPstoexclude.txt

plink --file SEsubset.s4 --exclude SNPtoexclude.txt --recodeA --recode --out SEsubset.Final
```

Final dataset:

167 individuals

5217 SNPs

0.706 Genotyping rate

Use pgdspider to convert .ped PLINK file to vcf. And keep plink and vcf files on mac:

/Users/alexjvr/2016RADAnalysis/SE.MS1/input.files/

And replace the headers  (pgdspider doubles the names). 


###Summary Statistics




###1. Population Structure

####1. Geographic prior

   ##### a. TESS3
 
 TESS3 uses a new method to infer ancestry: Geographically constrained least-squares estimation of ancestry coefficients.  
http://onlinelibrary.wiley.com/doi/10.1111/1755-0998.12471/epdf

K is chosen by evaluating the cross-entropy criterion for each K. This method finds the minimum number of "bits" or samples from a normal probability distribution (p) that can predict a non-normal probability distribution (q). So the smaller this number is, the better the K. 


R package has been released in devtools: 

https://github.com/cayek/TESS3/blob/master/README.md

I need to use LEA to convert my data into TESS3 format: 

For this I had to upgrade R. The following link shows how to set up R-studio to use different versions of R: 

https://support.rstudio.com/hc/en-us/articles/200486138-Using-Different-Versions-of-R

In command line: 

```
export RSTUDIO_WHICH_R=/usr/local/bin/R

open -a rstudio
```

Make sure that R3.2.5 is launched. 

LEA is a bioconductor package. 

http://www.bioconductor.org/packages/release/bioc/html/LEA.html


In R: 

```
source("http://bioconductor.org/biocLite.R")
biocLite("LEA")

library(LEA)

setwd("/Users/alexjvr/2016RADAnalysis/4_SE.MS1/TESS3")
output = vcf2geno("SEsubset.Final2.vcf")
```

```
	- number of detected individuals:	167
	- number of detected loci:		5189

For SNP info, please check ./SEsubset.Final.vcfsnp.

0 line(s) were removed because these are not SNPs.
Please, check ./SEsubset.Final.removed file, for more informations.

```

Now I need the .coords file, which is a file with a lat & long column for each individual (no individual names). 

list all the samples in the vcf file

```
bcftools query -l SEsubset.Final.vcf
```

```
nano coords.SE  ##paste all the coords into this file
```

To run TESS3: 

The executable needs to be copied to the current directory
```
cp ~/Applications/TESS3-master/build/TESS3 .

./TESS3 -x SEsubset.Final2.geno -r coords.SE -K 2 -q K2.1.Q -g K2.1.G -f K2.1.Fst -y K2.1.sum -c 0.05
```

Run this for K 1-5 x 10 iterations. 

-I can be used to select a random subset of samples. But this full dataset ran in ~10sec, so probably not necessary. 

-y = least-squares criterion

-c = percentage of the masked genotypes. (0.05 by default). If this is set, the cross-entropy criterion is calculated. 

-i = max nr of iterations. (default = 200)

Paste all of the entropy scores into a csv file. And plot in R: 

```
####################################
######Graph of cross-entropy scores

setwd("/Users/alexjvr/2016RADAnalysis/4_SE.MS1/TESS3")
library(ggplot2)

SEsubset.entropy <- read.csv("cross.Entropy.K1_5.csv")
SEsubset.entropy <- as.data.frame(CHS.entropy)
SEsubset.entropy

ggplot(SEsubset.entropy, aes(x=SEsubset.entropy$K, y=SEsubset.entropy$cross.entropy)) + geom_point(shape=1) + ggtitle("Cross-entropy for SE subset") + ylab("Cross-entropy") + xlab("K")
```



From the Min-Entropy graph, K = 2

I interpret this as the biggest change in cross-entropy scores, as they do in this tutorial: http://membres-timc.imag.fr/Olivier.Francois/tutoRstructure.pdf

![alt_txt][Fig.3]
[Fig.3]:https://cloud.githubusercontent.com/assets/12142475/17696151/7bc79cd0-63a4-11e6-912f-92bc3af35b6f.png


```
###Graphic display of TESS output
#########
setwd("/Users/alexjvr/2016RADAnalysis/4_SE.MS1/TESS3")

#install.packages("fields")
library(fields)
#install.packages("RColorBrewer")
library(RColorBrewer)
source("MapDisplay/POPSutilities.R")

Qmatrix <- read.table("TessK1_5/K3.1.Q")
coords <- read.table("coords.SE")
plot(coords, pch = 19, xlab = "Longitude", ylab= "Latitude")
#?map
map(add = T, boundary = T, interior = T, col = "grey80")

asc.raster=("MapDisplay/lowResEurope.asc")
asc.raster
grid=createGridFromAsciiRaster(asc.raster)
constraints=getConstraintsFromAsciiRaster(asc.raster,cell_value_min=0)   ##constrains the map to the raster file size
maps(matrix = Qmatrix, coords, grid, method = "max", main = "Ancestry coefficients", xlab = "Longitude", ylab = "Latitude")
map(add = T, interior = F)
```
Remember to swap long & lat from the order in my own data. And move MapDisplay and ascii files to the working directory. 


Tess3 graph for K=2 and K=3

![alt_txt][SE.K2]
[SE.K2]:https://cloud.githubusercontent.com/assets/12142475/17726697/8f2cea8e-644c-11e6-9867-17d365531734.png


![alt_txt][SE.K3]
[SE.K3]:https://cloud.githubusercontent.com/assets/12142475/17726706/9581f938-644c-11e6-85d2-c7a6a325e2c8.png


    
   ### b. sPCA

###2. Non-geographic prior

   ### a. fastStructure
    
Information here:

https://rajanil.github.io/fastStructure/

http://phylobotanist.blogspot.co.uk/2014/08/trying-to-use-faststructure.html

####Run fastStructure

Convert input to Structure format using pgdSpider. Choose the specific fastStructure format. And change marker type to SNPs. Everything else should be left as is. All the columns are in the PLINK files.

fastStructure can be run from the Applications folder, or specify the path in bash: 

```
python /Users/alexjvr/Applications/fastStructure/fastStructure/structure.py -K 1 --format=str --input=SEsubset.fast.str --output=SEsubset_K1.1
```

I haven't figured out how to write a script to loop through fastStructure, but change the output file for each run. I.e. I have to manually run K 1-10 x 10 runs. According to the google group, this is how it has to be done. The runs take just a few seconds each.


####Assessing K:

```    
python /Users/alexjvr/Applications/fastStructure/fastStructure/chooseK.py --input=SEsubset_*


Model complexity that maximizes marginal likelihood = 4
Model components used to explain structure in data = 1
```

chooseK.py gives a range of best K, rather than an optimal K. So this is not very useful for me!!

https://groups.google.com/forum/#!topic/structure-software/s_rc_ueq6CU

Google groups suggests comparing plots for all optimal K, here K1-4. 

In stead of choosing the most likely K as before in Structure, use CLUMPP to average over all the iterations for the most likely K (Here K1-4.

```

```



Import and plot in R: 

```

```

####CLUMPP

http://web.stanford.edu/group/rosenberglab/papers/clumppNote.pdf

https://r-how.com/packages/strataG/clumpp.run

new program for converting data: http://onlinelibrary.wiley.com/doi/10.1111/1755-0998.12559/full  (StrataG)

###2.1 Fst outlier analysis


###snmf in LEA

http://membres-timc.imag.fr/Olivier.Francois/LEA/files/LEA_snmf.html



####PCAdapt


####BayPass???


###2.2 EAA

####Env data

Extracting env data from worldclim and preparing input files: 

http://www.gis-blog.com/r-raster-data-acquisition/

https://web.archive.org/web/20130323135103/http://cran.r-project.org/web/packages/dismo/vignettes/sdm.pdf

I need a table with all the sites and all the BioClimatic variables (as on pg25 of the above link)

In R: 

```
###LFMM

##extract env data
##Tutorial: https://ecologicaconciencia.wordpress.com/2013/11/29/obtaining-macroclimate-data-with-r-to-model-species-distributions/

#install.packages("rgdal") ##had to install gdal first: brew install gdal on comp command line
library(rgdal)
#install.packages("raster")
library(raster)

climate <- getData('worldclim', var='bio', res=2.5) ##extracts 19 BioClim variables from worldclim at 2.5' resolution. 

climate  ##make sure it's a RasterStack
names(climate)  ##lists bio1-19
plot(climate$bio1) ##This should be of the whole world

climate2 <- crop(climate, extent(9,23,52,70)) ##crop to map extent
climate2    
spplot(climate2, main="BioClim Variables", xlim=c(9,23) , ylim=c(52,70))

spplot(climate2$bio1, main="BIO1:Annual Mean Temperature")
spplot(climate2$bio2, main="BIO2:Mean Diurnal Range")
spplot(climate2$bio3, main="BIO3:Isothermality (BIO2/BIO7) (* 100)")
spplot(climate2$bio4, main="BIO4:Temperature Seasonality (standard deviation *100)")
spplot(climate2$bio5, main="BIO5:Max Temperature of Warmest Month")
spplot(climate2$bio6, main="BIO6:Min Temperature of Coldest Month")
spplot(climate2$bio7, main="BIO7:Temperature Annual Range (BIO5-BIO6)")
spplot(climate2$bio8, main="BIO8:Mean Temperature of Wettest Quarter")
spplot(climate2$bio9, main="BIO9:Mean Temperature of Driest Quarter")
spplot(climate2$bio10, main="BIO10:Mean Temperature of Warmest Quarter")
spplot(climate2$bio11, main="BIO11:Mean Temperature of Coldest Quarter")
spplot(climate2$bio12, main="BIO12:Annual Precipitation")
spplot(climate2$bio13, main="BIO13:Precipitation of Wettest Month")
spplot(climate2$bio14, main="BIO14:Precipitation of Driest Month")
spplot(climate2$bio15, main="BIO15:Precipitation Seasonality (Coefficient of Variation)")
spplot(climate2$bio16, main="BIO16:Precipitation of Wettest Quarter")
spplot(climate2$bio17, main="BIO17:Precipitation of Driest Quarter")
spplot(climate2$bio18, main="BIO18:Precipitation of Warmest Quarter")
spplot(climate2$bio19, main="BIO19:Precipitation of Coldest Quarter")
```

This will give you plots in the following format: 

![alt_txt][BIO2]
[BIO2]:https://cloud.githubusercontent.com/assets/12142475/17744854/717c7dce-64a1-11e6-813c-546e9eb45532.png

And with sample locations plotted: 
```
###plot sample localities on one of these maps: 

SEpop.coords <- read.table(file = "~/2016RADAnalysis/4_SE.MS1/lfmm/pop.coords.SE")
head(SEpop.coords)


xy <- SEpop.coords[,c(1,2)]
spdf <- SpatialPointsDataFrame(coords = xy, data = SEpop.coords,
                               proj4string = CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"))
spdf  ##convert dataframe to spatial points

spplot(climate2$bio2, main="BIO2:Mean Diurnal Range", 
       sp.layout = c("sp.points", spdf, col="black", pch=16))
```

![alt_txt][BIO2.samples]
[BIO2.samples]:https://cloud.githubusercontent.com/assets/12142475/17745873/8a19331e-64a5-11e6-8913-90aed2c55d88.png


Extract point location information: 
```
presvals <- extract(climate2, SEpop.coords)   ##extract bioclim data for point locations
head(presvals)

setwd("/Users/alexjvr/2016RADAnalysis/4_SE.MS1/lfmm/")
write.csv(presvals, file = "SE.BIOclim.csv")  ###write to .csv
```


I have genomic data for 17 of the 19 populations: 

![alt_txt][sample.info]
[sample.info]:https://cloud.githubusercontent.com/assets/12142475/17747316/31f1a070-64ac-11e6-8bad-8ad54efa3f00.png

Reduce the number of variables using PC method: 

https://duncanjg.files.wordpress.com/2008/03/mnp-workshop3.pdf
```


```


####LFMM

http://membres-timc.imag.fr/Olivier.Francois/lfmm/files/LEA_1.html

```
export RSTUDIO_WHICH_R=/usr/local/bin/R

open -a rstudio
```

Make sure that R3.3.1 is launched. (Or later than R3.2)

LEA is a bioconductor package. 

http://www.bioconductor.org/packages/release/bioc/html/LEA.html


In R: 

```
source("http://bioconductor.org/biocLite.R")
biocLite("LEA")

library(LEA)

```
##Import genomic data into LEA in lfmm format

**I'm doing this in R on the gdc server, because my Rstudio keeps crashing. I think the problem was that I hadn't corrected the BIOclim file to include data for all individuals. 
The .env file format is specific, and the .csv needs to be converted to .env in R, even if the format looks the same

```
setwd("/gdc_home4/alexjvr/SE.analysis_20160817/lfmm/")

env <- read.csv("BIOclim_allindivs_SEsubset.csv.env") ###read in the environmental data
write.env(env, "SE.env")   ##convert to correct .env format
[1] "SE.env"


project = lfmm("SEsubset.Final2.lfmm", "SE.env", K = 2, repetitions = 5, project = "new")  ##run LFMM with this .env file
```

output: 
```
The project is saved into :
 SEsubset.Final2_SE.lfmmProject 

To load the project, use:
 project = load.lfmmProject("SEsubset.Final2_SE.lfmmProject")

To remove the project, use:
 remove.lfmmProject("SEsubset.Final2_SE.lfmmProject")

[1] "********************************"
[1] "* K = 2  repetition 1  d = 1   *"
[1] "********************************"
Summary of the options:

        -n (number of individuals)      167
        -L (number of loci)             5189
        -K (number of latent factors)   6
        -o (output file)                SEsubset.Final2_SE.lfmm/K6/run1/SEsubset.Final2_r1
        -i (number of iterations)       10000
        -b (burnin)                     5000
        -s (seed random init)           1959483173
        -p (number of processes (CPU))  1
        -x (genotype file)              SEsubset.Final2.lfmm
        -v (variable file)              SE.env
        -D (number of covariables)      20
        -d (the dth covariable)         1

Read variable file:
 	SE.env		OK.

Read genotype file:
 	SEsubset.Final2.lfmm		OK.

<<<<
	 Analyse for variable 1

		Start of the Gibbs Sampler algorithm.

	[                                                                           ]
	[==================
	
		End of the Gibbs Sampler algorithm.
	
	ED:866608.6876   DIC: 866591.3606

        The statistics for the run are registered in:
                SEsubset.Final2_SE.lfmm/K2/run5/SEsubset.Final2_r5_s20.2.dic.

        The zscores for variable 20 are registered in:
                SEsubset.Final2_SE.lfmm/K2/run5/SEsubset.Final2_r5_s20.2.zscore.
        The columns are: zscores, -log10(p-values), p-values.

        -------------------------
        The execution for variable 20 worked without error.
>>>>

The project is saved into :
 SEsubset.Final2_SE.lfmmProject

To load the project, use:
 project = load.lfmmProject("SEsubset.Final2_SE.lfmmProject")

To remove the project, use:
 remove.lfmmProject("SEsubset.Final2_SE.lfmmProject")
```

***Error: nr individuals in lfmm dataset different to env dataset. Obviously. So either 1) reduce the genomic dataset to population-level data, or 2) increase the env data so that all the individuals are represented. 


I've increased the env data so that all individuals are represented - i.e. the env data is duplicated throughout the dataset. 

```
zs = z.scores("SEsubset.Final2_SE.lfmmProject", K = 2)


```




###3.1 Gradient Forest

Scripts: 

http://datadryad.org/bitstream/handle/10255/dryad.69620/gf.gdm.snpModels.4dryad.R?sequence=1


###3.2 Generalised Dissimilarity Model (GDM)





