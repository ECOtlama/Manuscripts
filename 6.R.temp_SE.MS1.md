##Population genomics of Rana temporaria across the latitudinal environmental gradient in Scandinavia. 

Adaptation across elevation in Andrew's toad. 

http://onlinelibrary.wiley.com/doi/10.1111/mec.13722/abstract?campaign=woletoc

LHT variation in Rana temporaria across latitude. 

Very little known about their population structure. 

Aim: 

Detect loci associated with environment across latitude

1. Characterise population structure

2. Genome scan for ecologically relevant loci related to the latitudinal gradient. 

3. Spatial interpolation of genomic turnover/ temporal interpolation of genomic turnover (GF + GDM)










***
Compare to Johannsen et al. 2006

http://onlinelibrary.wiley.com/doi/10.1111/j.1365-294X.2006.02866.x/full

 (i) Are there clear geographic patterns of within population genetic variability and degree of among population genetic variability in this species? 
 
 (ii) Are there clear geographic patterns of occurrence and population sizes in this species? 
 
 (iii) Is there evidence that the current patterns of genetic variability and differentiation in this species are better explained by their current demography, rather than their colonization history?

1. What is the fine-scale connectivity within each sampling area?

2. IBD vs IBE?

3. Signatures of selection? 

I will run analyses based on Laurent et al. 2015 (white sand lizards) http://onlinelibrary.wiley.com/doi/10.1111/mec.13385/epdf
****



1. Population Structure 
   
  - PCA
  - TESS3
  - fastStructure
 
  - IBD
  
  - Fst
 
2.1 Outlier detection

2.2 Environmental Association Analysis

3.1 Random Forest

3.2 GDM


##Data

1. All data

2. Subset of the data adjusted for the number of reads (rerun pyRAD)

###Dataset1



###Dataset2 

copy all the .edit files from SEFinalSamples.edits > SEFinalSamples/subset5Mil.SE/edits

count the reads for each sample

```
grep -c ^'>' *edit -> SE.readcount
```

Downsample to 1Mil reads per sample. (Mostly because Finland samples have such few reads, and this population would drop out if I increased the minimum number of reads). 

Use a perl script (random_sequence_sample.pl). Which I've uploaded on gdc (and the mac). 


```
for i in edits/*.fq.trim.edit; do perl random_sequence_sample.pl -i $i -o subset/$i.subset.edit -n 1000000; done
```


###Filter Dataset

####Dataset 2

/gdc_home4/alexjvr/SEFinalSamples/subset1Mil.SE/outfiles/subset.Filter/SEsubset.vcf


Filter for missingness of 0.5 and MAC 3 (3/(118*2) = 1.2% MAF)

50% genotyping rate. And MAC of 3. (across 230 indivs = 3/460 = 0.65%) - I should probably increase this! Rather use a MAF of 1%

```
vcftools --vcf SEsubset.vcf --max-missing 0.5 --mac 3 --recode --recode-INFO-all --out SEsubset.vcf.s2

Output:

Parameters as interpreted:
	--vcf SEsubset.vcf
	--recode-INFO-all
	--mac 3
	--max-missing 0.5
	--out SEsubset.vcf.s2
	--recode

Eighth Header entry should be INFO: INFO    
After filtering, kept 177 out of 177 Individuals
Outputting VCF file...
After filtering, kept 19866 out of a possible 410602 Sites
Run Time = 28.00 seconds
```

And check the missingness for the individuals:

```
vcftools --vcf SEsubset.vcf.s2.recode.vcf --missing-indv

mawk '!/IN/' out.imiss | cut -f5 > totalmissing

gnuplot << \EOF 
set terminal dumb size 120, 30
set autoscale 
unset label
set title "Histogram of % missing data per individual"
set ylabel "Number of Occurrences"
set xlabel "% of missing data"
#set yr [0:100000]
binwidth=0.01
bin(x,width)=width*floor(x/width) + binwidth/2.0
plot 'totalmissing' using (bin( $1,binwidth)):(1.0) smooth freq with boxes
pause -1
EOF
```

Output:

![alt_txt][Fig.1]
[Fig.1]:https://cloud.githubusercontent.com/assets/12142475/17670563/8015ec8c-630a-11e6-8822-646a217ea4eb.png

Most of the samples have <50% missing data.

And if I try with --max-missing 0.8 followed by the rest of the filtering

```
vcftools --vcf SEsubset.vcf --max-missing 0.8 --mac 3 --recode --recode-INFO-all --out SEsubset.s2_0.8

Parameters as interpreted:
	--vcf SEsubset.vcf
	--recode-INFO-all
	--mac 3
	--max-missing 0.8
	--out SEsubset.s2_0.8
	--recode

Eighth Header entry should be INFO: INFO    
After filtering, kept 177 out of 177 Individuals
Outputting VCF file...
After filtering, kept 4929 out of a possible 410602 Sites
Run Time = 24.00 seconds
```

![alt_txt][Fig.2]
[Fig.2]:https://cloud.githubusercontent.com/assets/12142475/17670824/aab2b5fa-630b-11e6-8d23-cdb6de5be98a.png

This is significantly less loci, and not much better i.t.o. missingness. So I will use the first filter, and remove the 7 individuals with >0.5 missingness

```
--vcf SEsubset.vcf.s2.recode.vcf --remove remove.names --recode --recode-INFO-all --out SEsubset.s3

VCFtools - v0.1.12b
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf SEsubset.vcf.s2.recode.vcf
	--exclude remove.names
	--recode-INFO-all
	--out SEsubset.s3
	--recode

Excluding individuals in 'exclude' list
After filtering, kept 167 out of 177 Individuals
Outputting VCF file...
After filtering, kept 19866 out of a possible 19866 Sites
Run Time = 3.00 seconds

```


Rename the samples in vcf file:

First get a list of all the samples:

```
bcftools query -l SEsubset.s3.recode.vcf
```

copy and paste this to excel. And rename accordingly (I remove the "cat" and ".fq.trim"). Nano and paste into a new file.

Paste back:

```
bcftools reheader SEsubset.s3.recode.vcf -s new.names -o SEsubset.s3.vcf
```

3. Thin to 1 SNP per locus:

```
vcftools --vcf SEsubset.s3.vcf --thin 500 --recode --recode-INFO-all --out SEsubset.s3.thinned.vcf

Parameters as interpreted:
	--vcf SEsubset.s3.vcf
	--recode-INFO-all
	--thin 500
	--out SEsubset.s3.thinned.vcf
	--recode

After filtering, kept 167 out of 167 Individuals
Outputting VCF file...
After filtering, kept 5290 out of a possible 19866 Sites
Run Time = 1.00 seconds
```

4.Filter for >0.6 obs Het

Based on my recent checks on the pyRAD data, I should also filter all SNPs with >0.7 observed Heterozygosity.

I will do this in R using the PLINK file.

Convert to plink

```
vcftools --vcf SEsubset.s3.thinned.vcf.recode.vcf --plink --out SEsubset.s4
```

Calculate HWE for all loci in PLINK

```
plink --file SEsubset.s4 --hardy
```

PLINK output plink.hwe has a very strange format - multiple spaces between columns - so I couldn't figure out how to cut a specific column using linux

I sorted everything in excel.

There are only 30 SNPs with O.Het >0.6 (i.e. 0.56%)

```
923:86
45299:91
131938:21
31269:23
15018:23
107525:44
80914:106
109021:9
53856:9
31387:44
88409:3
116529:47
17502:52
3086:06:00
33252:37
62935:14
121937:13
85675:18
132142:1
45819:46
75796:21
58278:85
130290:76
71033:77
95774:102
121298:22
67455:2
100258:5
113742:72
26:17:00
```

Remove with plink

```
nano SNPstoexclude.txt

plink --file SEsubset.s4 --exclude SNPtoexclude.txt --recodeA --recode --out SEsubset.Final
```

Final dataset:

167 individuals

5217 SNPs

0.706 Genotyping rate

Use pgdspider to convert .ped PLINK file to vcf. And keep plink and vcf files on mac:

/Users/alexjvr/2016RADAnalysis/SE.MS1/input.files/

And replace the headers  (pgdspider doubles the names). 


###Summary Statistics




###1. Population Structure

####1. Geographic prior

   ##### a. TESS3
 
 TESS3 uses a new method to infer ancestry: Geographically constrained least-squares estimation of ancestry coefficients.  
http://onlinelibrary.wiley.com/doi/10.1111/1755-0998.12471/epdf

K is chosen by evaluating the cross-entropy criterion for each K. This method finds the minimum number of "bits" or samples from a normal probability distribution (p) that can predict a non-normal probability distribution (q). So the smaller this number is, the better the K. 


R package has been released in devtools: 

https://github.com/cayek/TESS3/blob/master/README.md

I need to use LEA to convert my data into TESS3 format: 

For this I had to upgrade R. The following link shows how to set up R-studio to use different versions of R: 

https://support.rstudio.com/hc/en-us/articles/200486138-Using-Different-Versions-of-R

In command line: 

```
export RSTUDIO_WHICH_R=/usr/local/bin/R

open -a rstudio
```

Make sure that R3.2.5 is launched. 

LEA is a bioconductor package. 

http://www.bioconductor.org/packages/release/bioc/html/LEA.html


In R: 

```
source("http://bioconductor.org/biocLite.R")
biocLite("LEA")

library(LEA)

setwd("/Users/alexjvr/2016RADAnalysis/4_SE.MS1/TESS3")
output = vcf2geno("SEsubset.Final2.vcf")
```

```
	- number of detected individuals:	167
	- number of detected loci:		5189

For SNP info, please check ./SEsubset.Final.vcfsnp.

0 line(s) were removed because these are not SNPs.
Please, check ./SEsubset.Final.removed file, for more informations.

```

Now I need the .coords file, which is a file with a lat & long column for each individual (no individual names). 

list all the samples in the vcf file

```
bcftools query -l SEsubset.Final.vcf
```

```
nano coords.SE  ##paste all the coords into this file
```

To run TESS3: 

The executable needs to be copied to the current directory
```
cp ~/Applications/TESS3-master/build/TESS3 .

./TESS3 -x SEsubset.Final2.geno -r coords.SE -K 2 -q K2.1.Q -g K2.1.G -f K2.1.Fst -y K2.1.sum -c 0.05
```

Run this for K 1-5 x 10 iterations. 

-I can be used to select a random subset of samples. But this full dataset ran in ~10sec, so probably not necessary. 

-y = least-squares criterion

-c = percentage of the masked genotypes. (0.05 by default). If this is set, the cross-entropy criterion is calculated. 

-i = max nr of iterations. (default = 200)

Paste all of the entropy scores into a csv file. And plot in R: 

```
####################################
######Graph of cross-entropy scores

setwd("/Users/alexjvr/2016RADAnalysis/4_SE.MS1/TESS3")
library(ggplot2)

SEsubset.entropy <- read.csv("cross.Entropy.K1_5.csv")
SEsubset.entropy <- as.data.frame(CHS.entropy)
SEsubset.entropy

ggplot(SEsubset.entropy, aes(x=SEsubset.entropy$K, y=SEsubset.entropy$cross.entropy)) + geom_point(shape=1) + ggtitle("Cross-entropy for SE subset") + ylab("Cross-entropy") + xlab("K")
```



From the Min-Entropy graph, K = 2

I interpret this as the biggest change in cross-entropy scores, as they do in this tutorial: http://membres-timc.imag.fr/Olivier.Francois/tutoRstructure.pdf

![alt_txt][Fig.3]
[Fig.3]:https://cloud.githubusercontent.com/assets/12142475/17696151/7bc79cd0-63a4-11e6-912f-92bc3af35b6f.png


```
###Graphic display of TESS output
#########
setwd("/Users/alexjvr/2016RADAnalysis/4_SE.MS1/TESS3")

#install.packages("fields")
library(fields)
#install.packages("RColorBrewer")
library(RColorBrewer)
source("MapDisplay/POPSutilities.R")

Qmatrix <- read.table("TessK1_5/K3.1.Q")
coords <- read.table("coords.SE")
plot(coords, pch = 19, xlab = "Longitude", ylab= "Latitude")
#?map
map(add = T, boundary = T, interior = T, col = "grey80")

asc.raster=("MapDisplay/lowResEurope.asc")
asc.raster
grid=createGridFromAsciiRaster(asc.raster)
constraints=getConstraintsFromAsciiRaster(asc.raster,cell_value_min=0)   ##constrains the map to the raster file size
maps(matrix = Qmatrix, coords, grid, method = "max", main = "Ancestry coefficients", xlab = "Longitude", ylab = "Latitude")
map(add = T, interior = F)
```
Remember to swap long & lat from the order in my own data. And move MapDisplay and ascii files to the working directory. 


Tess3 graph for K=2 and K=3

![alt_txt][SE.K2]
[SE.K2]:https://cloud.githubusercontent.com/assets/12142475/17726697/8f2cea8e-644c-11e6-9867-17d365531734.png


![alt_txt][SE.K3]
[SE.K3]:https://cloud.githubusercontent.com/assets/12142475/17726706/9581f938-644c-11e6-85d2-c7a6a325e2c8.png


    
   ### b. sPCA

###2. Non-geographic prior

   ### a. fastStructure
    
Information here:

https://rajanil.github.io/fastStructure/

http://phylobotanist.blogspot.co.uk/2014/08/trying-to-use-faststructure.html

####Run fastStructure

Convert input to Structure format using pgdSpider. Choose the specific fastStructure format. And change marker type to SNPs. Everything else should be left as is. All the columns are in the PLINK files.

fastStructure can be run from the Applications folder, or specify the path in bash: 

```
python /Users/alexjvr/Applications/fastStructure/fastStructure/structure.py -K 1 --format=str --input=SEsubset.fast.str --output=SEsubset_K1.1
```

I haven't figured out how to write a script to loop through fastStructure, but change the output file for each run. I.e. I have to manually run K 1-10 x 10 runs. According to the google group, this is how it has to be done. The runs take just a few seconds each.


####Assessing K:

```    
python /Users/alexjvr/Applications/fastStructure/fastStructure/chooseK.py --input=SEsubset_*


Model complexity that maximizes marginal likelihood = 4
Model components used to explain structure in data = 1
```

chooseK.py gives a range of best K, rather than an optimal K. So this is not very useful for me!!

https://groups.google.com/forum/#!topic/structure-software/s_rc_ueq6CU

Google groups suggests comparing plots for all optimal K, here K1-4. 

In stead of choosing the most likely K as before in Structure, use CLUMPP to average over all the iterations for the most likely K (Here K1-4.

```

```



Import and plot in R: 

```

```

####CLUMPP

http://web.stanford.edu/group/rosenberglab/papers/clumppNote.pdf

https://r-how.com/packages/strataG/clumpp.run

new program for converting data: http://onlinelibrary.wiley.com/doi/10.1111/1755-0998.12559/full  (StrataG)

###2.1 Fst outlier analysis


###snmf in LEA

http://membres-timc.imag.fr/Olivier.Francois/LEA/files/LEA_snmf.html



####PCAdapt


####BayPass???


###2.2 EAA

####Env data

Extracting env data from worldclim and preparing input files: 

http://www.gis-blog.com/r-raster-data-acquisition/

https://web.archive.org/web/20130323135103/http://cran.r-project.org/web/packages/dismo/vignettes/sdm.pdf

I need a table with all the sites and all the BioClimatic variables (as on pg25 of the above link)

In R: 

```
###LFMM

##extract env data
##Tutorial: https://ecologicaconciencia.wordpress.com/2013/11/29/obtaining-macroclimate-data-with-r-to-model-species-distributions/

#install.packages("rgdal") ##had to install gdal first: brew install gdal on comp command line
library(rgdal)
#install.packages("raster")
library(raster)

climate <- getData('worldclim', var='bio', res=2.5) ##extracts 19 BioClim variables from worldclim at 2.5' resolution. 

climate  ##make sure it's a RasterStack
names(climate)  ##lists bio1-19
plot(climate$bio1) ##This should be of the whole world

climate2 <- crop(climate, extent(9,23,52,70)) ##crop to map extent
climate2    
spplot(climate2, main="BioClim Variables", xlim=c(9,23) , ylim=c(52,70))

spplot(climate2$bio1, main="BIO1:Annual Mean Temperature")
spplot(climate2$bio2, main="BIO2:Mean Diurnal Range")
spplot(climate2$bio3, main="BIO3:Isothermality (BIO2/BIO7) (* 100)")
spplot(climate2$bio4, main="BIO4:Temperature Seasonality (standard deviation *100)")
spplot(climate2$bio5, main="BIO5:Max Temperature of Warmest Month")
spplot(climate2$bio6, main="BIO6:Min Temperature of Coldest Month")
spplot(climate2$bio7, main="BIO7:Temperature Annual Range (BIO5-BIO6)")
spplot(climate2$bio8, main="BIO8:Mean Temperature of Wettest Quarter")
spplot(climate2$bio9, main="BIO9:Mean Temperature of Driest Quarter")
spplot(climate2$bio10, main="BIO10:Mean Temperature of Warmest Quarter")
spplot(climate2$bio11, main="BIO11:Mean Temperature of Coldest Quarter")
spplot(climate2$bio12, main="BIO12:Annual Precipitation")
spplot(climate2$bio13, main="BIO13:Precipitation of Wettest Month")
spplot(climate2$bio14, main="BIO14:Precipitation of Driest Month")
spplot(climate2$bio15, main="BIO15:Precipitation Seasonality (Coefficient of Variation)")
spplot(climate2$bio16, main="BIO16:Precipitation of Wettest Quarter")
spplot(climate2$bio17, main="BIO17:Precipitation of Driest Quarter")
spplot(climate2$bio18, main="BIO18:Precipitation of Warmest Quarter")
spplot(climate2$bio19, main="BIO19:Precipitation of Coldest Quarter")
```

This will give you plots in the following format: 

![alt_txt][BIO2]
[BIO2]:https://cloud.githubusercontent.com/assets/12142475/17744854/717c7dce-64a1-11e6-813c-546e9eb45532.png

And with sample locations plotted: 
```
###plot sample localities on one of these maps: 

SEpop.coords <- read.table(file = "~/2016RADAnalysis/4_SE.MS1/lfmm/pop.coords.SE")
head(SEpop.coords)


xy <- SEpop.coords[,c(1,2)]
spdf <- SpatialPointsDataFrame(coords = xy, data = SEpop.coords,
                               proj4string = CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"))
spdf  ##convert dataframe to spatial points

spplot(climate2$bio2, main="BIO2:Mean Diurnal Range", 
       sp.layout = c("sp.points", spdf, col="black", pch=16))
```

![alt_txt][BIO2.samples]
[BIO2.samples]:https://cloud.githubusercontent.com/assets/12142475/17745873/8a19331e-64a5-11e6-8913-90aed2c55d88.png


Extract point location information: 
```
presvals <- extract(climate2, SEpop.coords)   ##extract bioclim data for point locations
head(presvals)

setwd("/Users/alexjvr/2016RADAnalysis/4_SE.MS1/lfmm/")
write.csv(presvals, file = "SE.BIOclim.csv")  ###write to .csv
```


I have genomic data for 17 of the 19 populations: 

![alt_txt][sample.info]
[sample.info]:https://cloud.githubusercontent.com/assets/12142475/17747316/31f1a070-64ac-11e6-8bad-8ad54efa3f00.png

Reduce the number of variables using PC method: 

https://duncanjg.files.wordpress.com/2008/03/mnp-workshop3.pdf
```


```


####LFMM

http://membres-timc.imag.fr/Olivier.Francois/lfmm/files/LEA_1.html

```
export RSTUDIO_WHICH_R=/usr/local/bin/R

open -a rstudio
```

Make sure that R3.3.1 is launched. (Or later than R3.2)

LEA is a bioconductor package. 

http://www.bioconductor.org/packages/release/bioc/html/LEA.html


In R: 

```
source("http://bioconductor.org/biocLite.R")
biocLite("LEA")

library(LEA)

```
##Import genomic data into LEA in lfmm format

**I'm doing this in R on the gdc server, because my Rstudio keeps crashing. I think the problem was that I hadn't corrected the BIOclim file to include data for all individuals. 
The .env file format is specific, and the .csv needs to be converted to .env in R, even if the format looks the same

```
setwd("/gdc_home4/alexjvr/SE.analysis_20160817/lfmm/")

env <- read.csv("BIOclim_allindivs_SEsubset.csv.env") ###read in the environmental data
write.env(env, "SE.env")   ##convert to correct .env format
[1] "SE.env"


project = lfmm("SEsubset.Final2.lfmm", "SE.env", K = 2, repetitions = 5, project = "new")  ##run LFMM with this .env file
```

output: 
```
The project is saved into :
 SEsubset.Final2_SE.lfmmProject 

To load the project, use:
 project = load.lfmmProject("SEsubset.Final2_SE.lfmmProject")

To remove the project, use:
 remove.lfmmProject("SEsubset.Final2_SE.lfmmProject")

[1] "********************************"
[1] "* K = 2  repetition 1  d = 1   *"
[1] "********************************"
Summary of the options:

        -n (number of individuals)      167
        -L (number of loci)             5189
        -K (number of latent factors)   6
        -o (output file)                SEsubset.Final2_SE.lfmm/K6/run1/SEsubset.Final2_r1
        -i (number of iterations)       10000
        -b (burnin)                     5000
        -s (seed random init)           1959483173
        -p (number of processes (CPU))  1
        -x (genotype file)              SEsubset.Final2.lfmm
        -v (variable file)              SE.env
        -D (number of covariables)      20
        -d (the dth covariable)         1

Read variable file:
 	SE.env		OK.

Read genotype file:
 	SEsubset.Final2.lfmm		OK.

<<<<
	 Analyse for variable 1

		Start of the Gibbs Sampler algorithm.

	[                                                                           ]
	[==================
	
		End of the Gibbs Sampler algorithm.
	
	ED:866608.6876   DIC: 866591.3606

        The statistics for the run are registered in:
                SEsubset.Final2_SE.lfmm/K2/run5/SEsubset.Final2_r5_s20.2.dic.

        The zscores for variable 20 are registered in:
                SEsubset.Final2_SE.lfmm/K2/run5/SEsubset.Final2_r5_s20.2.zscore.
        The columns are: zscores, -log10(p-values), p-values.

        -------------------------
        The execution for variable 20 worked without error.
>>>>

The project is saved into :
 SEsubset.Final2_SE.lfmmProject

To load the project, use:
 project = load.lfmmProject("SEsubset.Final2_SE.lfmmProject")

To remove the project, use:
 remove.lfmmProject("SEsubset.Final2_SE.lfmmProject")
```

***Error: nr individuals in lfmm dataset different to env dataset. Obviously. So either 1) reduce the genomic dataset to population-level data, or 2) increase the env data so that all the individuals are represented. 


I've increased the env data so that all individuals are represented - i.e. the env data is duplicated throughout the dataset. 

```
zs = z.scores(project, K = 2, d=10) ##Where d is the env variable in question

# Combine the z-scores using the Stouffer method
zs.stouffer = apply(zs, MARGIN = 1, median)

# compute the inflation factor
lambda = median(zs.stouffer^2)/.456

# compute adjusted p-values
cp.values = pchisq(zs.stouffer^2/lambda, df = 1, lower = FALSE)

for (alpha in c(.05)) {  ##(alpha in c(.05,.1,.15,.2)) ##for all FDR
    # expected FDR
    print(paste("expected FDR:", alpha))
    L = length(cp.values)
    # return a list of candidates with an expected FDR of alpha.
    w = which(sort(cp.values) < alpha * (1:L) / L)
    candidates = order(cp.values)[w]

    # estimated FDR and True Positif rate
    estimated.FDR = length(which(candidates <= 350))/length(candidates)
    estimated.TP = length(which(candidates > 350))/50
    print(paste("FDR:", estimated.FDR, "True Positive:", estimated.TP))
}

candidates

BIO01: 
[1] "expected FDR: 0.05"
[1] "FDR: 0.166666666666667 True Positive: 0.1"
> 
> candidates
[1] 3172 2581 4851  239 3630 1881

BIO02
[1] "expected FDR: 0.05"
[1] "FDR: 0.0784313725490196 True Positive: 0.94"
> 
> candidates
 [1] 1066 1675 5082  914 1136 2799  415 1855 4322 3178 1100 5027 4070 4580 3952
[16]  159 1056  655  212 4676 1019  227 3206 1285  173 1062  483 4224 4927 4636
[31] 3354 4478 2442 4770  813  365  391 2438  787 3139 1431 4132 1372 3340 1345
[46] 1063 1852 3838 1636 3765 4067

BIO03
[1] "expected FDR: 0.05"
[1] "FDR: 0.0666666666666667 True Positive: 0.28"

[1] 1066 1478 4770  603 1136 2849 3467  221 4891 4254 4125 3952 4580 5082 1598


BIO04
[1] "expected FDR: 0.05"
[1] "FDR: 0 True Positive: 0.02"

[1] 620

BIO05
[1] "expected FDR: 0.05"
[1] "FDR: 0.111111111111111 True Positive: 0.8"
> 
> candidates
 [1] 1066 5082 4580 1675 1136 3178 1431 2799 4224 1855 4770  415 3355 1063 1100
[16] 3952  391  603  221  227 3206 2849 4322  159  212 4478 3467 1056 1478  173
[31]  914 3198 4927 3171 2437 4676 5027 4125 4553 3838 2442 1285 2778 4132 1685

BIO06
[1] "expected FDR: 0.05"
[1] "FDR: 0.03125 True Positive: 1.24"
> 
> candidates
 [1] 3373  914 2337 3297 4070 1480  483  365 5001 5010 3340 3399 1996 2811 4260
[16] 5027 1291 3464  819 1359 3926 4859 2092 1319 2185 4384 1345 3006 1082 1675
[31] 1266 1151 2893 4322  970 1033  846 2658 3896  407  807 3962 3466 3283  263
[46]  219 1554  893 4389  634 2204  813 3142 2890 1768 5179 2438 2958 1062 3384
[61] 5093 1144 1897 2851


```


#####lfmm run 2

I'm running lfmm with only the 4 environmental variables that I want to test in the genomic turnover analysis: 

1. nr Days above 6deg

2. BIO2

3. BIO15

4. BIO18

And for K 2 - 7 (pop structure is important to take into account). 


Created a new .env file with only these environmental variables. And rerun lfmm in R on fgcz: 

```
source("http://bioconductor.org/biocLite.R")
biocLite("LEA")

library(LEA)
```

Import genomic data into LEA in lfmm format
```
setwd("/srv/kenlab/alexjvr_p1795/SE.Analyses/lfmm/")

env <- read.csv("SE.4ENVvar.csv.env", header=T) ###read in the environmental data. Remember headers on the .csv
write.env(env, "SE.4.env")   ##convert to correct .env format
[1] "SE.4.env"


project = lfmm("SEsubset.4env.lfmm", "SE.4.env", K = 2, repetitions = 5, project = "new")  ##run LFMM with this .env file

[1] "********************************"
[1] "* K = 2  repetition 1  d = 1   *"
[1] "********************************"
Summary of the options:

        -n (number of individuals)      167
        -L (number of loci)             5189
        -K (number of latent factors)   2
        -o (output file)                SEsubset.4env_SE.lfmm/K2/run1/SEsubset.4env_r1
        -i (number of iterations)       10000
        -b (burnin)                     5000
        -s (seed random init)           1093701227
        -p (number of processes (CPU))  1
        -x (genotype file)              SEsubset.4env.lfmm
        -v (variable file)              SE.4.env
        -D (number of covariables)      4
        -d (the dth covariable)         1

Read variable file:
        SE.4.env                OK.

Read genotype file:
        SEsubset.4env.lfmm              OK.

<<<<
         Analyse for variable 1

                Start of the Gibbs Sampler algorithm.

        [                                                                           ]
        [========

zs = z.scores(project, K = 2, d=1) ##Where d is the env variable in question

# Combine the z-scores using the Stouffer method
zs.stouffer = apply(zs, MARGIN = 1, median)

# compute the inflation factor
lambda = median(zs.stouffer^2)/.456

# compute adjusted p-values
cp.values = pchisq(zs.stouffer^2/lambda, df = 1, lower = FALSE)

for (alpha in c(.05)) {  ##(alpha in c(.05,.1,.15,.2)) ##for all FDR
    # expected FDR
    print(paste("expected FDR:", alpha))
    L = length(cp.values)
    # return a list of candidates with an expected FDR of alpha.
    w = which(sort(cp.values) < alpha * (1:L) / L)
    candidates = order(cp.values)[w]

    # estimated FDR and True Positif rate
    estimated.FDR = length(which(candidates <= 350))/length(candidates)
    estimated.TP = length(which(candidates > 350))/50
    print(paste("FDR:", estimated.FDR, "True Positive:", estimated.TP))
}

candidates: 

temp
[1] "expected FDR: 0.05"
[1] "FDR: 0.137931034482759 True Positive: 0.5"
[1] 1066 1675 5082  914 1136  415 2799 1855 4322 3178 5027 1100  159 4070  212
[16] 1056 4580 4676 3206  483  655 3952  227 1285  173 4224 2442 1019 4927

BIO2
[1] "expected FDR: 0.05"
[1] "FDR: 0.0625 True Positive: 0.3"
 [1] 1066 1478 4770  603 2849 3467 1136  221 4891 4254 4125 3952 4580 5082 2676
[16] 2492


BIO15
[1] "expected FDR: 0.05"
[1] "FDR: 0.0588235294117647 True Positive: 0.96"
 [1] 1431  391  415  159 1685 5082 1056 4224 1100 1063 2372  263  603 2048 1169
[16] 4121 3791 3355 2917 3650 4901 3565 1598  267 2441  829 4770 2442 2437 3198
[31]  914 2462 4125 4437 4173 4556 2276 4528 1066 1822 3790 3206 1191 5103 4923
[46] 3053 1356 2455 1253 3113 2849


BIO18
[1] "expected FDR: 0.05"
[1] "FDR: 0.0714285714285714 True Positive: 0.26"
[1]   35 3178 3584 2784 1788 2068 3605 5169 3189 4478 2778 2716 1205 4170
```




####BayEnv2

https://bitbucket.org/tguenther/bayenv2_public/src/8e4039f64d61?at=default

1. Input file with subset of 500 SNPs for co-variance matrix (pop structure)

2. Input file with all SNPs for the association analysis

3. ENV input file with normalised environmental parameters. I will first use only temperature. 

 NB: population order in the input files should all be the same. 


#####1. Large input

Convert using pgdspider


#####2. 500SNPs 

First convert to genepop using pgspider to get a list of all the SNPs

Randomly choose 500 SNPs and paste into a file

```
vcftools --vcf SEsubset.Final2.vcf --snps 500Snps.names --recode --recode-INFO-all --out SEsubset500

VCFtools - v0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf SEsubset.Final2.vcf
	--recode-INFO-all
	--out SEsubset500
	--recode
	--snps 500Snps.names

After filtering, kept 167 out of 167 Individuals
Outputting VCF file...
After filtering, kept 481 out of a possible 5189 Sites
Run Time = 0.00 seconds


```

I had a problem with the vcf file. I had to change the header to include some information, because it would not be read properly: 

hashtag hashtag FORMAT= (smaller than symbol) ID=GT,Number=1,Type=String,Description="Genotype" (bigger than symbol)


Generate the co-variance matrix:

Bayenv2 needs to be run from the command line from its folder: /Users/alexjvr/Applications/bayenv2/compiled_on_a_mac

Estimate the matrix 
```
./bayenv2 -i /Users/alexjvr/2016RADAnalysis/4_SE.MS1/BayEnv/SE.500.Bayenv.txt -p 16 -k 100000 -r 63479 > /Users/alexjvr/2016RADAnalysis/4_SE.MS1/BayEnv/SEmatrix.out
```
run on mac. Started 16 Sept 16:44 - 


#####3. Env variables

I downloaded all the BioClim point data before. 

I'm initially using only BIO10 - mean temp of the warmest quarter. 

Note that I messed up the population structure of these SE files - I lumped the two Kiruna pops together. 

I normalised and transposed these data in excel. And changed the order to that of the populations in the BayEnv files (this can be seen in the names.all.bayenv_sample.txt file and verified using the SE.samplesize.txt file. 

ENV input
```
/Users/alexjvr/2016RADAnalysis/4_SE.MS1/BayEnv/BIO10.SE
```

#####4. Run Bayenv2 

Copy the bayenv2 executable folder to gdcsrv as well as all the SE.BayEnv input files: /gdc_home4/alexjvr/SE.analysis_20160817/SE.BayEnv

split the SNPSFILE into individual loci: 
```
split -d -a 10 -l 2 SE.all.Bayenv.txt snp_batch
```

and run bayenv2 corrolation
```
for f in $(ls snp_batch*); do ./bayenv2 -i $f -e BIO10.SE -m SE.FinalMATRIX -k 100000 -r $RANDOM -p 16 -n 1 -t -c; done
```

#####BayENV2 Run2

Corrected the input files to include all 17 populations

Created a new .env file with 4 standardised environmental variables

1. days above 6 deg

2. BIO2

3. BIO15

4. BIO18

Estimate corrolation matrix

```
./bayenv2 -i /Users/alexjvr/2016RADAnalysis/4_SE.MS1/SE.BayEnv/SE.all_17pops.500.bayenv.txt -p 17 -k 100000 -r 63479 > /Users/alexjvr/2016RADAnalysis/4_SE.MS1/SE.BayEnv/SE.Matrixrun2.txt
```

Copy the bayenv2 executable folder to gdcsrv as well as all the SE.BayEnv input files: /gdc_home4/alexjvr/SE.analysis_20160817/SE.BayEnv

split the SNPSFILE into individual loci: 
```
split -d -a 10 -l 2 SE.all_17pops.bayenv.txt snp_batch
```

and run bayenv2 corrolation
```
for f in $(ls snp_batch*); do ./bayenv2 -i $f -e SE.tBIO2.15.18_ENV -m SE.MATRIX2 -k 100000 -r $RANDOM -p 17 -n 4 -t -c; done
```





###3.1 Gradient Forest

Scripts: 

http://datadryad.org/bitstream/handle/10255/dryad.69620/gf.gdm.snpModels.4dryad.R?sequence=1

#####MEM

Calculate Moran's Eigenvector Maps (MEM) for a set of coordinates. 

In Rstudio (R3.1.2)
```
###Create Moran's Eigenvector Maps (MEM) from set of coordinates:
##http://artax.karlin.mff.cuni.cz/r-help/library/codep/html/mevmap.html
#############
###Method 1
#library(adespatial)
#install.packages("SoDA")
library(SoDA)
library(coda)
library(vegan)

SE.xy <- read.table("SE.coords", header=T)
SE.xy
SE.XY <- geoXY(SE.xy$x, SE.xy$y)  #Change to Cartesian coordinates. Make sure lat and long are in the right order.

SE.dist <- dist(SE.XY, method="euclidean")  ##calculate euclidean distance between all the points and print matrix. 
SE.dist2 <- as.matrix(SE.dist)
map <- eigenmap(x=SE.dist,opt.coord = SE.XY, weighting=Wf.PCNM)
map
plot(map)
summary(map)

scr <- eigenmap.score(object=map,target=SE.dist2)
head(scr)
```

As suggested by Manel et al. 2010b, use only the positive MEMs as these are more likely to account for the broad-scale spatial genetic variation generated by e.g. demographic history and unaccounted for environmental variables. 

In this case there are only 2 positive MEMs. 

#####Env Variables

I included 4 environemental variables: 

1. annual days above 6 deg Celcius. 

The 6 -8 deg was calculated by Judith B to be important for growth based on her and the SE experimental work. I'm using 6 deg here, but could use 8 or 10 deg if needed. 

The rest of the data are from WorldClim (www.worldclim.org; Hijmans et al. 2005) ##Check the reference and the resolution here.

##And check the corrolation between all 4 variables. 

2. BIO2 - mean diurnal range of temperature

3. BIO15 - precipitation seasonality

4. BIO18 - summer precipitation

5. Geog distance  ##I'm adding this in as a fifth corrolate, since this is probably what explains most of the variation. 

Make sure Fin is the first population as this will be the 0 point. 
```
#Great circle distance between samples

##Geographic distance between all SE populations
##using package Rdist

library(fields)
#Import .csv with coordinates

setwd("/Users/alexjvr/2016RADAnalysis/4_SE.MS1/GradForest/")

SE.dist <- read.table("pop.coords.SE_N2S", header=T)
head(SE.dist)



#rdist.earth (in fields package) wants only long & lat
SE_lon.lat <- cbind(SE.dist$y, SE.dist$x)
SE_lon.lat

#calculate great circle distances
distance.matrix.SERAD <- rdist.earth(SE_lon.lat)
summary(distance.matrix.SERAD)
dim(distance.matrix.SERAD)

#and use only the lower half of the matrix
upper.tri(distance.matrix.SERAD)
distance.matrix.SERAD[lower.tri(distance.matrix.SERAD)]<-NA
distance.matrix.SERAD

#change from matrix to dataframe
bli <- as.data.frame(distance.matrix.SERAD)
head(bli)
colnames(bli) <- SE.dist$name
rownames(bli) <- SE.dist$name

bli[lower.tri(bli,diag=TRUE)]=NA  #Prepare to drop duplicates and meaningless information
bli=as.data.frame(as.table(as.matrix(bli)))  #Turn into a 3-column table
bli
bli=na.omit(bli)  #Get rid of the junk we flagged above
bli
colnames(bli)<-c("site1", "site2", "dist(km)")
head(bli)

bli2 <- bli[sort("site2"),]

head(bli2)


##write to csv
write.csv(bli, file="distance.SE.csv",row.names=F)

```

Calculate MAF for all loci in Plink: 

```
vcftools --vcf SEsubset.Final2.vcf --plink --out SEsubset.Final2.plink

VCFtools - v0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf SEsubset.Final2.vcf
	--out SEsubset.Final2.plink
	--plink

After filtering, kept 167 out of 167 Individuals
Writing PLINK PED and MAP files ... 
Done.
After filtering, kept 5189 out of a possible 5189 Sites
Run Time = 1.00 seconds

```

Find the sample names in the *nosex file, and add pop names (i.e. 3 columns) to create a file for specifying clusters > SE.PlinkCluster

And calculate MAF with Plink
```
 plink --file SEsubset.Final2.plink --within SE.PlinkCluster --freq

@----------------------------------------------------------@
|        PLINK!       |     v1.07      |   10/Aug/2009     |
|----------------------------------------------------------|
|  (C) 2009 Shaun Purcell, GNU General Public License, v2  |
|----------------------------------------------------------|
|  For documentation, citation & bug-report instructions:  |
|        http://pngu.mgh.harvard.edu/purcell/plink/        |
@----------------------------------------------------------@

Web-based version check ( --noweb to skip )
Recent cached web-check found... OK, v1.07 is current

+++ PLINK 1.9 is now available! See above website for details +++ 

Writing this text to log file [ plink.log ]
Analysis started: Wed Sep 21 21:36:24 2016

Options in effect:
	--file SEsubset.Final2.plink
	--within SE.PlinkCluster
	--freq

5189 (of 5189) markers to be included from [ SEsubset.Final2.plink.map ]
Warning, found 167 individuals with ambiguous sex codes
These individuals will be set to missing ( or use --allow-no-sex )
Writing list of these individuals to [ plink.nosex ]
167 individuals read from [ SEsubset.Final2.plink.ped ] 
0 individuals with nonmissing phenotypes
Assuming a disease phenotype (1=unaff, 2=aff, 0=miss)
Missing phenotype value is also -9
0 cases, 0 controls and 167 missing
0 males, 0 females, and 167 of unspecified sex
Reading clusters from [ SE.PlinkCluster ]
167 of 167 individuals assigned to 17 cluster(s)
Before frequency and genotyping pruning, there are 5189 SNPs
167 founders and 0 non-founders found
11 heterozygous haploid genotypes; set to missing
Writing list of heterozygous haploid genotypes to [ plink.hh ]
Writing stratified allele frequencies (founders-only) to [ plink.frq.strat ] 

Analysis finished: Wed Sep 21 21:36:25 2016

```

1. Import into R to reformat the output - by population and loci as columns

2. Remove all loci fixed in >2 pops

3. Rename loci 

4. Find outliers identified with BayENV2 and LFMM. 




```
################################################################################
# Scripts to model & map genetic turnover using gradient forests and generalized
# dissimilarity modeling described in Fitzpatrick & Keller (in press) Ecology Letters
#
# written by MC Fitzpatrick at the Appalachian Lab, Frostburg, MD 2013-2014
# with input on mapping functions from M. Lisk
#
# Code is provided as is, without support 
################################################################################

################################################################################
# BEGIN SCRIPTS FOR GRADIENT FOREST MODELING - GDM SCRIPTS BEGINS @ LINE 148
################################################################################
# load libraries, read in data, etc. -------------------------------------------
#https://r-forge.r-project.org/R/?group_id=973 #download from sourceforge
#This needs to be run on the latest version of R (3.3.1)
#install.packages("/Users/alexjvr/Downloads/extendedForest_1.6.1.tar.gz") ##need extendedForest first
#install.packages("/Users/alexjvr/Downloads/gradientForest_0.1-17.tar.gz")

library(gradientForest)
library(raster)

# read in data file with minor allele freqs & env/space variables
gfData <- read.csv("poplarSNP.ENV.data.4.GF.csv")
envGF <- gfData[,3:13] # get climate & MEM variables

# build individual SNP datasets
SNPs_ref <- gfData[,grep("REFERENCE",colnames(gfData))] # reference
GI5 <- gfData[,grep("GI5",colnames(gfData))] # GIGANTEA-5 (GI5)
################################################################################


# GRADIENT FOREST MODELING -----------------------------------------------------
maxLevel <- log2(0.368*nrow(envGF)/2) #account for correlations, see ?gradientForest 

# Fit gf models for reference SNPs 
gfRef <- gradientForest(cbind(envGF, SNPs_ref), predictor.vars=colnames(envGF),
                         response.vars=colnames(SNPs_ref), ntree=500, 
                         maxLevel=maxLevel, trace=T, corr.threshold=0.50)

# Fit gf models for GI5 SNPs
gfGI5 <- gradientForest(cbind(envGF, GI5), predictor.vars=colnames(envGF),
                          response.vars=colnames(GI5), ntree=500, 
                          maxLevel=maxLevel, trace=T, corr.threshold=0.50)

# plot output, see ?plot.gradientForest
type = "O"
plot(gfRef, plot.type=type)
plot(gfGI5, plot.type=type)
################################################################################


# Mapping spatial genetic variation --------------------------------------------
###### functions to support mapping #####
# builds RGB raster from transformed environment
# snpPreds = dataframe of transformed variables from gf or gdm model
# rast = a raster mask to which RGB values are to be mapped
# cellNums = cell IDs to which RGB values should be assigned
pcaToRaster <- function(snpPreds, rast, mapCells){
  require(raster)
  
  pca <- prcomp(snpPreds, center=TRUE, scale.=FALSE)
    
  ##assigns to colors, edit as needed to maximize color contrast, etc.
  a1 <- pca$x[,1]; a2 <- pca$x[,2]; a3 <- pca$x[,3]
  r <- a1+a2; g <- -a2; b <- a3+a2-a1
  
  ##scales colors
  scalR <- (r-min(r))/(max(r)-min(r))*255
  scalG <- (g-min(g))/(max(g)-min(g))*255
  scalB <- (b-min(b))/(max(b)-min(b))*255
  
  ##assigns color to raster
  rast1 <- rast2 <- rast3 <- rast
  rast1[mapCells] <- scalR
  rast2[mapCells] <- scalG
  rast3[mapCells] <- scalB
  ##stacks color rasters
  outRast <- stack(rast1, rast2, rast3)
  return(outRast)
}

# Function to map difference between spatial genetic predictions
# predMap1 = dataframe of transformed variables from gf or gdm model for first set of SNPs
# predMap2 = dataframe of transformed variables from gf or gdm model for second set of SNPs
# rast = a raster mask to which Procrustes residuals are to be mapped
# mapCells = cell IDs to which Procrustes residuals values should be assigned
RGBdiffMap <- function(predMap1, predMap2, rast, mapCells){
  require(vegan)
  PCA1 <- prcomp(predMap1, center=TRUE, scale.=FALSE)
  PCA2 <- prcomp(predMap2, center=TRUE, scale.=FALSE)
  diffProcrust <- procrustes(PCA1, PCA2, scale=TRUE, symmetrical=FALSE)
  residMap <- residuals(diffProcrust)
  rast[mapCells] <- residMap
  return(list(max(residMap), rast))
}

# OK, on to mapping. Script assumes:
# (1) a dataframe named env_trns containing extracted raster data (w/ cell IDs)
# and env. variables used in the models & with columns as follows: cell, bio1, bio2, etc.
#
# (2) a raster mask of the study region to which the RGB data will be written

# transform env using gf models, see ?predict.gradientForest
predRef <- predict(gfRef, env_trns[,-1]) # remove cell column before transforming
predGI5 <- predict(gfGI5, env_trns[,-1])

# map continuous variation - reference SNPs
refRGBmap <- pcaToRaster(predRef, mask, env_trns$cell)
plotRGB(refRGBmap)
writeRaster(refRGBmap, "/.../refSNPs_map.tif", format="GTiff", overwrite=TRUE)

# map continuous variation - GI5 SNPs
GI5RGBmap <- pcaToRaster(predGI5, mask, env_trns$cell)
plotRGB(refRGBmap)
writeRaster(refRGBmap, "/.../GI5SNPs_map.tif", format="GTiff", overwrite=TRUE)

# Difference between maps (GI5 and reference) 
diffGI5 <- RGBdiffMap(predRef, predGI5, rast=mask, mapCells=env_trns$cell)
plot(diffGI5[[2]])
writeRaster(diffGI5[[2]], "/.../diffRef_GI5.tif", format="GTiff", overwrite=TRUE)
################################################################################


# Calculate and map "genetic offset" under climate change ----------------------
# Script assumes:
  # (1) a dataframe of transformed env. variables for CURRENT climate 
  # (e.g., predGI5 from above).
  #
  # (2) a dataframe named env_trns_future containing extracted raster data of 
  # env. variables for FUTURE a climate scenario, same structure as env_trns

# first transform FUTURE env. variables
projGI5 <- predict(gfGI5, env_trns_future[,-1])

# calculate euclidean distance between current and future genetic spaces  
genOffsetGI5 <- sqrt((projGI5[,1]-predGI5[,1])^2+(projGI5[,2]-predGI5[,2])^2
                    +(projGI5[,3]-predGI5[,3])^2+(projGI5[,4]-predGI5[,4])^2
                    +(projGI5[,5]-predGI5[,5])^2+(projGI5[,6]-predGI5[,6])^2
                    +(projGI5[,7]-predGI5[,7])^2)

# assign values to raster - can be tricky if current/future climate
# rasters are not identical in terms of # cells, extent, etc.
mask[env_trns_future$cell] <- genOffsetGI5
plot(mask)
################################################################################
# END SCRIPTS FOR GRADIENT FOREST MODELING
################################################################################
```



```
################################################################################
# BEGIN SCRIPTS FOR GENERALIZED DISSIMILARITY MODELING
################################################################################
# load libraries, read in data, etc. -------------------------------------------
library(Gdm01)
library(raster)
# read in data file with Fst & env variables (in GDM site-pair format)
# note Fst values were scaled 0-1 to facilitate model convergence
gdmData <- read.csv("poplarFst.ENV.data.4.GDM.csv")

# build individual SNP datasets
SNPs_ref <- gdmData[,c(1,6:24)] # reference
GI5 <- gdmData[,c(3,6:24)] # GIGANTEA-5 (GI5)
################################################################################


# Fit generalized dissimilarity models -----------------------------------------
GEO=T # use geographic distance as a predictor?
# reference SNPs
gdmRef <- gdm.fit(SNPs_ref, geo=GEO)
gdmRef$explained
gdm.plot(gdmRef, plot.layout=c(3,4))
refSplines <- isplineExtract(gdmRef) # extract spline data for custom plotting

# GI5 SNPs
gdmGI5 <- gdm.fit(GI5, geo=GEO)
gdmGI5$explained
gdm.plot(gdmGI5, plot.layout=c(3,4))
GI5Splines <- isplineExtract(gdmGI5) # extract spline data for custom plotting
################################################################################


# Mapping spatial genetic variation --------------------------------------------

# Follows identical procedure as above for gf, but uses ?gdm.transform instead
# Also note that if geo. dist. is a predictor in the model, x & y rasters
# can be supplied in addition to env. layers.
predRef <- gdm.transform(gdmRef, env_trns[,-1]) # remove cell column
predGI5 <- gdm.transform(gdmGI5, env_trns[,-1])

# map continuous variation - reference SNPs
refRGBmap <- pcaToRaster(predRef, mask, env_trns$cell)
plotRGB(refRGBmap)
writeRaster(refRGBmap, "/.../refSNPs_map.tif", format="GTiff", overwrite=TRUE)

# map continuous variation - GI5 SNPs
GI5RGBmap <- pcaToRaster(predGI5, mask, env_trns$cell)
plotRGB(refRGBmap)
writeRaster(refRGBmap, "/.../GI5SNPs_map.tif", format="GTiff", overwrite=TRUE)

# Difference between maps (GI5 and reference) 
diffGI5 <- RGBdiffMap(predRef, predGI5, rast=mask, mapCells=env_trns$cell)
plot(diffGI5[[2]])
writeRaster(diffGI5[[2]], "/.../diffRef_GI5.tif", format="GTiff", overwrite=TRUE)
################################################################################

# Calculate and map "genetic offset" under climate change ----------------------
# Same approach as above for gf, but uses ?gdm.predict function, which calculates
# distance directly. These values can then be mapped.

genOffsetGI5 <- gdm.predict(gdmGI5, envPred)

# see ?gdm.predict for description of format of envPred.
# Basic structure is (e.g., for a model with geo=T, bio_1, elev):
# Observed  weights x.t1      y.t1    x.t2    y.t2  bio_1.t1  elev.t1   bio_1.t2  elev.t2
#   0.214     1     -152.25   65.42   -152.25 65.42 -5.6      235       -2.1      235   
# where Observed distances are required, but can be dummy values ranging 0-1

# assign values to raster - can be tricky if current/future climate
# rasters are not identical in terms of # cells, extent, etc.
mask[env_trns_future$cell] <- genOffsetGI5
plot(mask)
################################################################################
# END SCRIPTS FOR GENERALIZED DISSIMILARITY MODELING
################################################################################

```





