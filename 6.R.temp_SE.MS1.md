##Population genomics of Rana temporaria across the latitudinal environmental gradient in Scandinavia. 

Adaptation across elevation in Andrew's toad. 

http://onlinelibrary.wiley.com/doi/10.1111/mec.13722/abstract?campaign=woletoc

LHT variation in Rana temporaria across latitude. 

Very little known about their population structure. 

Aim: 

Detect loci associated with environment across latitude

1. Characterise population structure

2. Genome scan for ecologically relevant loci related to the latitudinal gradient. 

3. Spatial interpolation of genomic turnover/ temporal interpolation of genomic turnover (GF + GDM)










***
Compare to Johannsen et al. 2006

http://onlinelibrary.wiley.com/doi/10.1111/j.1365-294X.2006.02866.x/full

 (i) Are there clear geographic patterns of within population genetic variability and degree of among population genetic variability in this species? 
 
 (ii) Are there clear geographic patterns of occurrence and population sizes in this species? 
 
 (iii) Is there evidence that the current patterns of genetic variability and differentiation in this species are better explained by their current demography, rather than their colonization history?

1. What is the fine-scale connectivity within each sampling area?

2. IBD vs IBE?

3. Signatures of selection? 

I will run analyses based on Laurent et al. 2015 (white sand lizards) http://onlinelibrary.wiley.com/doi/10.1111/mec.13385/epdf
****



1. Population Structure 
   
  - PCA
  - TESS3
  - fastStructure
 
  - IBD
  
  - Fst
 
2.1 Outlier detection

2.2 Environmental Association Analysis

3.1 Random Forest

3.2 GDM


##Data

1. All data

2. Subset of the data adjusted for the number of reads (rerun pyRAD)

###Dataset1



###Dataset2 

copy all the .edit files from SEFinalSamples.edits > SEFinalSamples/subset5Mil.SE/edits

count the reads for each sample

```
grep -c ^'>' *edit -> SE.readcount
```

Downsample to 1Mil reads per sample. (Mostly because Finland samples have such few reads, and this population would drop out if I increased the minimum number of reads). 

Use a perl script (random_sequence_sample.pl). Which I've uploaded on gdc (and the mac). 


```
for i in edits/*.fq.trim.edit; do perl random_sequence_sample.pl -i $i -o subset/$i.subset.edit -n 1000000; done
```


###Filter Dataset

####Dataset 2

/gdc_home4/alexjvr/SEFinalSamples/subset1Mil.SE/outfiles/subset.Filter/SEsubset.vcf


Filter for missingness of 0.5 and MAC 3 (3/(118*2) = 1.2% MAF)

50% genotyping rate. And MAC of 3. (across 230 indivs = 3/460 = 0.65%) - I should probably increase this! Rather use a MAF of 1%

```
vcftools --vcf SEsubset.vcf --max-missing 0.5 --mac 3 --recode --recode-INFO-all --out SEsubset.vcf.s2

Output:

Parameters as interpreted:
	--vcf SEsubset.vcf
	--recode-INFO-all
	--mac 3
	--max-missing 0.5
	--out SEsubset.vcf.s2
	--recode

Eighth Header entry should be INFO: INFO    
After filtering, kept 177 out of 177 Individuals
Outputting VCF file...
After filtering, kept 19866 out of a possible 410602 Sites
Run Time = 28.00 seconds
```

And check the missingness for the individuals:

```
vcftools --vcf SEsubset.vcf.s2.recode.vcf --missing-indv

mawk '!/IN/' out.imiss | cut -f5 > totalmissing

gnuplot << \EOF 
set terminal dumb size 120, 30
set autoscale 
unset label
set title "Histogram of % missing data per individual"
set ylabel "Number of Occurrences"
set xlabel "% of missing data"
#set yr [0:100000]
binwidth=0.01
bin(x,width)=width*floor(x/width) + binwidth/2.0
plot 'totalmissing' using (bin( $1,binwidth)):(1.0) smooth freq with boxes
pause -1
EOF
```

Output:

![alt_txt][Fig.1]
[Fig.1]:https://cloud.githubusercontent.com/assets/12142475/17670563/8015ec8c-630a-11e6-8822-646a217ea4eb.png

Most of the samples have <50% missing data.

And if I try with --max-missing 0.8 followed by the rest of the filtering

```
vcftools --vcf SEsubset.vcf --max-missing 0.8 --mac 3 --recode --recode-INFO-all --out SEsubset.s2_0.8

Parameters as interpreted:
	--vcf SEsubset.vcf
	--recode-INFO-all
	--mac 3
	--max-missing 0.8
	--out SEsubset.s2_0.8
	--recode

Eighth Header entry should be INFO: INFO    
After filtering, kept 177 out of 177 Individuals
Outputting VCF file...
After filtering, kept 4929 out of a possible 410602 Sites
Run Time = 24.00 seconds
```

![alt_txt][Fig.2]
[Fig.2]:https://cloud.githubusercontent.com/assets/12142475/17670824/aab2b5fa-630b-11e6-8d23-cdb6de5be98a.png

This is significantly less loci, and not much better i.t.o. missingness. So I will use the first filter, and remove the 7 individuals with >0.5 missingness

```
--vcf SEsubset.vcf.s2.recode.vcf --remove remove.names --recode --recode-INFO-all --out SEsubset.s3

VCFtools - v0.1.12b
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf SEsubset.vcf.s2.recode.vcf
	--exclude remove.names
	--recode-INFO-all
	--out SEsubset.s3
	--recode

Excluding individuals in 'exclude' list
After filtering, kept 167 out of 177 Individuals
Outputting VCF file...
After filtering, kept 19866 out of a possible 19866 Sites
Run Time = 3.00 seconds

```


Rename the samples in vcf file:

First get a list of all the samples:

```
bcftools query -l SEsubset.s3.recode.vcf
```

copy and paste this to excel. And rename accordingly (I remove the "cat" and ".fq.trim"). Nano and paste into a new file.

Paste back:

```
bcftools reheader SEsubset.s3.recode.vcf -s new.names -o SEsubset.s3.vcf
```

3. Thin to 1 SNP per locus:

```
vcftools --vcf SEsubset.s3.vcf --thin 500 --recode --recode-INFO-all --out SEsubset.s3.thinned.vcf

Parameters as interpreted:
	--vcf SEsubset.s3.vcf
	--recode-INFO-all
	--thin 500
	--out SEsubset.s3.thinned.vcf
	--recode

After filtering, kept 167 out of 167 Individuals
Outputting VCF file...
After filtering, kept 5290 out of a possible 19866 Sites
Run Time = 1.00 seconds
```

4.Filter for >0.7 obs Het

Based on my recent checks on the pyRAD data, I should also filter all SNPs with >0.7 observed Heterozygosity.

I will do this in R using the PLINK file.

Convert to plink

```
vcftools --vcf SEsubset.s3.thinned.vcf.recode.vcf --plink --out SEsubset.s4
```

Calculate HWE for all loci in PLINK

```
plink --file SEsubset.s4 --hardy
```

PLINK output plink.hwe has a very strange format - multiple spaces between columns - so I couldn't figure out how to cut a specific column using linux

I sorted everything in excel.

There are only 30 SNPs with O.Het >0.6 (i.e. 0.56%)

```
923:86
45299:91
131938:21
31269:23
15018:23
107525:44
80914:106
109021:9
53856:9
31387:44
88409:3
116529:47
17502:52
3086:06:00
33252:37
62935:14
121937:13
85675:18
132142:1
45819:46
75796:21
58278:85
130290:76
71033:77
95774:102
121298:22
67455:2
100258:5
113742:72
26:17:00
```

Remove with plink

```
nano SNPstoexclude.txt

plink --file SEsubset.s4 --exclude SNPtoexclude.txt --recodeA --recode --out SEsubset.Final
```

Final dataset:

167 individuals

5217 SNPs

0.706 Genotyping rate

Use pgdspider to convert .ped PLINK file to vcf. And keep plink and vcf files on mac:

/Users/alexjvr/2016RADAnalysis/1.2_Phylo/input.files/

And replace the headers


###Summary Statistics




###1. Population Structure

####TESS3


####DAPC


####fastStructure


###2.1 Fst outlier analysis


####PCAdapt


####BayPass???


###2.2 EAA

####LFMM


###3.1 Random Forest


###3.2 Generalised Dissimilarity Model (GDM)





