#CH: Adaptation to elevation

1. What are the signals of adaptation to elevation? 

2. Are they the same across different elevational gradients? 

3. Genomic turnover -> ie. where is the most selective pressure & what will the effects of future climate be?


##Data generation

For summary stats and pop structure, I need datasets with little missing data, 1 SNP per locus. 

1. Data filtering MAF, missingness, Het, 1 SNP per locus. 

Analyses: 

1. Pairwise Fst

2. Het per population

3. Fis per pop

4. nucleotide diversity per pop

5. PCA

##Datasets & Summary statistics

###1. Dataset for summary stats & pop structure

CHall.forPCA.recode.vcf

Analysis Plan: 

1. Summary statistics (nucleotide diversity, EHet & ObsHet) 

2. Fst between pops

3. Per pop inbreeding co-efficient (Fis)

4. Partitioning of variance in data - AMOVA
		- Within or between pops
		- CHN/CHS vs pops
		- elevation vs pops

5. IBD: all
	CHN
	CHS

6. Pop Structure
	- PCA
	- fastStructure
	- TESS3
	- Tree based on genetic distance


Based on these result, I will decide how to partition the data further. 

This dataset has little missing data. -> produced from s1 file as created below from the 23Gb .vcf start file. 

```
vcftools --vcf CHall_1027.s1.recode.vcf --max-missing 0.8 --recode --recode-INFO-all --out CHall.maxmiss0.8

VCFtools - v0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf CHall_1027.s1.recode.vcf
	--recode-INFO-all
	--max-missing 0.8
	--out CHall.maxmiss0.8
	--recode

After filtering, kept 1029 out of 1029 Individuals
Outputting VCF file...
After filtering, kept 3368 out of a possible 142303 Sites
Run Time = 24.00 seconds

vcftools --vcf CHall.maxmiss0.8.recode.vcf --thin 200 --recode --recode-INFO-all --out CHall.maxmiss0.8_thin200

VCFtools - v0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf CHall.maxmiss0.8.recode.vcf
	--recode-INFO-all
	--thin 200
	--out CHall.maxmiss0.8_thin200
	--recode

After filtering, kept 1029 out of 1029 Individuals
Outputting VCF file...
After filtering, kept 1842 out of a possible 3368 Sites
Run Time = 2.00 seconds

vcftools --vcf CHall.maxmiss0.8_thin200.recode.vcf --missing-indv

mawk '!/IN/' out.imiss | cut -f5 > totalmissing

gnuplot << \EOF 
set terminal dumb size 120, 30
set autoscale 
unset label
set title "Histogram of % missing data per individual"
set ylabel "Number of Occurrences"
set xlabel "% of missing data"
#set yr [0:100000]
binwidth=0.01
bin(x,width)=width*floor(x/width) + binwidth/2.0
plot 'totalmissing' using (bin( $1,binwidth)):(1.0) smooth freq with boxes
pause -1
EOF
```

![alt_txt][CHsubset_0.8]
[CHsubset_0.8]:https://cloud.githubusercontent.com/assets/12142475/18847292/eeefa0ae-8429-11e6-8a55-97543deee600.png

remove indivs with >0.5 missing data (from out.imiss)
```
vcftools --vcf CHall.maxmiss0.8_thin200.recode.vcf --remove 0.8remove --recode --recode-INFO-all --out CHall.forPCA

Parameters as interpreted:
	--vcf CHall.maxmiss0.8_thin200.recode.vcf
	--exclude 0.8remove
	--recode-INFO-all
	--out CHall.forPCA
	--recode

Excluding individuals in 'exclude' list
After filtering, kept 1002 out of 1029 Individuals
Outputting VCF file...
After filtering, kept 1842 out of a possible 1842 Sites
Run Time = 2.00 seconds
```

Remove duplicate of seeo_04 (seeo_04cat incuded with less missing data)

```
vcftools --vcf CHall.forPCA.recode.vcf --remove-indv seeo_04.fq.trim --recode --recode-INFO-all --out CHall.Dataset1
```

and rename the samples in the file. Specify the old and new names. 
```
bcftools reheader CHall.Dataset1.recode.vcf -s new.names -o CHall.Dataset1.Final_1001.1842.vcf
```

####6. Pop Structure

1. PCA

2. fastStructure (hierarchical)

3. TESS3

4. distance-based Tree

#####1. PCA

I will remove the contaminated/potentially problematic individuals from the vcf file before starting
```
vcftools --vcf CHall.Dataset1.Final_1001.1842.vcf --remove contaminated.indivs --recode --recode-INFO-all --out CHall.Dataset1_992.1842
```

Convert to Plink.raw for Adegenet. (this needs to be done on the server because I ran out of memory on the mac)

PCA to decide how to divide pops

#######PCAdapt

Part1: For entire dataset, with populations specified as they will be subdivided. 

In R: 
```
path_to_CHall <- "CHall.Dataset1_992.1842.recode.vcf"

CHall <- read.pcadapt(path_to_CHall, type="vcf")
Summary:

        - input file      CHall.Dataset1_992.1842.recode.vcf
        - output file     CHall.Dataset1_992.1842.recode.pcadapt

	- number of individuals detected:	992
	- number of loci detected:		1838

For SNP info, please check CHall.Dataset1_992.1842.recode.vcfsnp.

4 line(s) have been removed because these are not SNPs.
Please, check CHall.Dataset1_992.1842.recode.removed file, for more information.

```

Check the nr of PCs

```
x <- pcadapt(CHall, K=20, transpose=F)
Reading file CHall.Dataset1_992.1842.recode.pcadapt...
Number of SNPs: 1838
Number of individuals: 992
Number of SNPs with minor allele frequency lower than 0.05 ignored: 274
163639 out of 1823296 missing data ignored.

plot(x,option="screeplot")  ##PC for pop structure = on the steep curve
```

![alt_txt][992.1838.K20]
[992.1838.K20]:https://cloud.githubusercontent.com/assets/12142475/19148506/5fb30228-8bbd-11e6-8bd1-76298366f634.png




Plot the PCA using population information


```
poplist <- read.table("popnames.removed")
plot(x,option="scores",pop=poplist)

```
![alt_txt][992.1838.PCA]
[992.1838.PCA]:https://cloud.githubusercontent.com/assets/12142475/19149771/da1e4b66-8bc3-11e6-9c9b-8bd86c57d3dd.png



This shows the subdivision and the individuals removed once the data is subset. 
Also a single individual from Ticino that assigns to CHN. 

Note pizo_07, a Ticino sample that groups with the Valais samples. This only happens at K4 in the structure plots. 




Part 2: Test of the PCADAPT results with the small dataset

Use the Final .vcf input file. And divide the file according to the elevations. 
```
--vcf CHall.Dataset1_992.1842 --keep HighLow.names --recode --recode-INFO-all --out CH.all.HighLow

VCFtools - v0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf CHall.Dataset1.Final_1001.1842.vcf
	--keep HighLow.names
	--recode-INFO-all
	--out CH.all.HighLow
	--recode

Keeping individuals in 'keep' list
After filtering, kept 737 out of 1001 Individuals
Outputting VCF file...
After filtering, kept 1842 out of a possible 1842 Sites
Run Time = 1.00 seconds
vpn-89-206-116-38:PCAdapt alexjvr$ vcftools --vcf CHall.Dataset1.Final_1001.1842.vcf --keep HighMid.names --recode --recode-INFO-all --out CH.all.HighMid

VCFtools - v0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf CHall.Dataset1.Final_1001.1842.vcf
	--keep HighMid.names
	--recode-INFO-all
	--out CH.all.HighMid
	--recode

Keeping individuals in 'keep' list
After filtering, kept 689 out of 1001 Individuals
Outputting VCF file...
After filtering, kept 1842 out of a possible 1842 Sites
Run Time = 1.00 seconds
vpn-89-206-116-38:PCAdapt alexjvr$ vcftools --vcf CHall.Dataset1.Final_1001.1842.vcf --keep LowMid.names --recode --recode-INFO-all --out CH.all.LowMid

VCFtools - v0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf CHall.Dataset1.Final_1001.1842.vcf
	--keep LowMid.names
	--recode-INFO-all
	--out CH.all.LowMid
	--recode

Keeping individuals in 'keep' list
After filtering, kept 576 out of 1001 Individuals
Outputting VCF file...
After filtering, kept 1842 out of a possible 1842 Sites
Run Time = 1.00 seconds


```

Run PCAdapt in R on terminal 

```
setwd("/Users/alexjvr/2016RADAnalysis/5_CH.landscapeGenomics/Dataset1_forPCA/PCAdapt")
library(pcadapt)
path_to_High.Low <- "CH.all.HighLow.recode.vcf"

High.Low <- read.pcadapt(path_to_High.Low, type="vcf")

Summary:

        - input file      CH.all.HighLow.recode.vcf
        - output file     CH.all.HighLow.recode.pcadapt

	- number of individuals detected:	737
	- number of loci detected:		1838

For SNP info, please check CH.all.HighLow.recode.vcfsnp.

4 line(s) have been removed because these are not SNPs.
Please, check CH.all.HighLow.recode.removed file, for more information.

File has been sucessfully converted.

```

Check the nr of PCs

```
x <- pcadapt(High.Low,K=20,transpose=F)

Reading file CH.all.HighLow.recode.pcadapt...
Number of SNPs: 1838
Number of individuals: 737
Number of SNPs with minor allele frequency lower than 0.05 ignored: 284
124630 out of 1354606 missing data ignored.

poplist <- read.table("HighLow.pop")

```

Plot the PCA using population information
```


```




#####2. fastStructure

With Plink input: 

I used to convert this to fastStructure format in pgdspider, but to check the sample order it's better to use the PLINK input file. 

Convert to PLINK and then to bed. I had to run this on the gdcserver, because it was too big. 
```
vcftools --vcf CHall.Dataset1.Final_1001.1842.vcf --plink --out CHall.Dataset1.1001.1842.PLINK

 plink --file CHall.Dataset1.1001.1842.PLINK --out CHall.Dataset1.1001.1838 --make-bed 
```
plink read only 1838 loci

```
Options in effect:
	--file CHall.Dataset1.1001.1842.PLINK
	--make-bed

1838 (of 1838) markers to be included from [ CHall.Dataset1.1001.1842.PLINK.map ]
Warning, found 1001 individuals with ambiguous sex codes
Writing list of these individuals to [ plink.nosex ]
1001 individuals read from [ CHall.Dataset1.1001.1842.PLINK.ped ] 
0 individuals with nonmissing phenotypes
Assuming a disease phenotype (1=unaff, 2=aff, 0=miss)
Missing phenotype value is also -9
0 cases, 0 controls and 1001 missing
0 males, 0 females, and 1001 of unspecified sex
Before frequency and genotyping pruning, there are 1838 SNPs
1001 founders and 0 non-founders found
Total genotyping rate in remaining individuals is 0.895889
0 SNPs failed missingness test ( GENO > 1 )
0 SNPs failed frequency test ( MAF < 0 )
After frequency and genotyping pruning, there are 1838 SNPs
After filtering, 0 cases, 0 controls and 1001 missing
After filtering, 0 males, 0 females, and 1001 of unspecified sex
Writing pedigree information to [ plink.fam ] 
Writing map (extended format) information to [ plink.bim ] 
Writing genotype bitfile to [ plink.bed ] 
Using (default) SNP-major mode

```


run Structure for K2 and K3
```
/usr/bin/python2.6 /usr/local/fastStructure-20150714/structure.py -K 2 --format=bed --input=CHall.Dataset1.1001.1838 --output=CHall.sampleorder
```

Now look at the output with the correct sample names, and compare to the output from the optimisation fastStructure runs (K1-10x10) shown below. 

The order seems to be the same as what I got from fastStructure input file. I think this is because I didn't specify populations. 




With fastStructure input (most of the runs): 
convert to fastStructure format using pgdSpider. In the spid file, specify fastStructure format, and choose SNPs as markers. Also provide the pop file. 

```
/Users/alexjvr/2016RADAnalysis/5_CH.landscapeGenomics/Dataset1_forPCA/fastStructure/CHall_Dataset1_1001.1842.str
```
Run fastStructure on the gdcserver. I had a lot of problems trying to install this on my computer!!

Again, run K1-10 x 10. These need to be specified manually

```
/usr/bin/python2.6 /usr/local/fastStructure-20150714/structure.py -K 1 --format=str --input=CHall_Dataset1_1001.1842.str --output=CHall.Data1_K1.1
```

How many Ks?
```
/usr/bin/python2.6 /usr/local/fastStructure-20150714/chooseK.py --input=CHall.Data1_K*

Model complexity that maximizes marginal likelihood = 8
Model components used to explain structure in data = 1
```

Summarise structure plots with CLUMPP

First, create a paramfile. This can be a copy of the example file. Specify Datatype 0 for individuals (vs 1 for pops), and number of individuals. Check the example from my run or from the example input for the chicken dataset. Most of the other CLUMPP parameters can be specified via command line, which will override the paramfile. 

indfiles need to be created: paste all the structure outputs for a specific K below each other. No headers. 

I've specified Greedy option 2

```
CLUMPP paramfile -k 2 -i K2.Q.indfile.txt -o K2.meanQ.out
```

For these runs, the sample order is the same between the PLINK test run and the input files that I created using pgdspider (i.e. fastStructure). 




Based on the Structure analysis, I've identified some possible contaminants: individuals that assign to populations that they should not assign to. They were all sequenced on plate H22. The rest of the individuals seem to be assigning correctly. 

gola_19 - looks right, but note in HiSeqPlates_20150723.xls shows it was contaminated by an SE sample  (plate H21)

H22: 

kebe_06 - 09

mart_08-10

ente_14


fastStructure plots generated in Excel. These samples are ordered as follows: 

1. CHN ordered from West to East

2. Contact Zone ordered from North to South

3. CHS ordered from East to West

The groups (CHN, CHS, ContactZone) were decided based on geographic location. Contaminants have been removed from these graphs (see below)


![alt_txt][fastStr_CHall.K2]
[fastStr_CHall.K2]:https://cloud.githubusercontent.com/assets/12142475/19122731/13c70292-8b2c-11e6-94ad-651b798835c2.png

![alt_txt][fastStr_CHall.K3]
[fastStr_CHall.K3]:https://cloud.githubusercontent.com/assets/12142475/19122732/13c89634-8b2c-11e6-9d76-e06dc503911f.png

![alt_txt][fastStr_CHall.K4]
[fastStr_CHall.K4]:https://cloud.githubusercontent.com/assets/12142475/19122730/13c4fe2a-8b2c-11e6-9098-c72ee14e46e8.png

![alt_txt][fastStr_CHall.K5]
[fastStr_CHall.K5]:https://cloud.githubusercontent.com/assets/12142475/19122733/13cd0660-8b2c-11e6-99e4-437d03796613.png





#####3. TESS3


Run this in the command line. 

First convert the .vcf to .geno using LEA in R. Make sure a later version of R is chosen.
```
source("http://bioconductor.org/biocLite.R")
biocLite("LEA")

library(LEA)

setwd("/Users/alexjvr/2016RADAnalysis/5_CH.landscapeGenomics/Dataset1_forPCA/TESS3/")
output = vcf2geno("CHall.Dataset1.Final_1001.1842.vcf")

	- number of detected individuals:	1001
	- number of detected loci:		1838

For SNP info, please check ./CHall.Dataset1.Final_1001.1842.vcfsnp.

4 line(s) were removed because these are not SNPs.
Please, check ./CHall.Dataset1.Final_1001.1842.removed file, for more informations.
```

TESS3 removes variants with >1 alt allele. The four that were removed had the notation: 

50266 9 . C A,T 20 PASS NS=924;DP=4 GT REMOVED

829281 29 . G A,T 20 PASS NS=882;DP=4 GT REMOVED

872771 2 . C A,G 20 PASS NS=1002;DP=4 GT REMOVED

1625311 29 . C T,G 20 PASS NS=947;DP=4 GT REMOVED


Now I need the .coords file, which is a file with a lat & long column for each individual (no individual names). 

```
nano coords.CHall.Dataset1
```

Copy TESS3 executable over to the current directory and run K1-10 x 10 itirations

```
cp ~/Applications/TESS3-master/build/TESS3 .


./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 1 -q K1.1.Q -f K1.1.Fst -y K1.1.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 1 -q K1.2.Q -f K1.2.Fst -y K1.2.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 1 -q K1.3.Q -f K1.3.Fst -y K1.3.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 1 -q K1.4.Q -f K1.4.Fst -y K1.4.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 1 -q K1.5.Q -f K1.5.Fst -y K1.5.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 1 -q K1.6.Q -f K1.6.Fst -y K1.6.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 1 -q K1.7.Q -f K1.7.Fst -y K1.7.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 1 -q K1.8.Q -f K1.8.Fst -y K1.8.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 1 -q K1.9.Q -f K1.9.Fst -y K1.9.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 1 -q K1.10.Q -f K1.10.Fst -y K1.10.sum -c 0.05

./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 2 -q K2.1.Q -f K2.1.Fst -y K2.1.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 2 -q K2.2.Q -f K2.2.Fst -y K2.2.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 2 -q K2.3.Q -f K2.3.Fst -y K2.3.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 2 -q K2.4.Q -f K2.4.Fst -y K2.4.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 2 -q K2.5.Q -f K2.5.Fst -y K2.5.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 2 -q K2.6.Q -f K2.6.Fst -y K2.6.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 2 -q K2.7.Q -f K2.7.Fst -y K2.7.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 2 -q K2.8.Q -f K2.8.Fst -y K2.8.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 2 -q K2.9.Q -f K2.9.Fst -y K2.9.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 2 -q K2.10.Q -f K2.10.Fst -y K2.10.sum -c 0.05

./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 3 -q K3.1.Q -f K3.1.Fst -y K3.1.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 3 -q K3.2.Q -f K3.2.Fst -y K3.2.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 3 -q K3.3.Q -f K3.3.Fst -y K3.3.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 3 -q K3.4.Q -f K3.4.Fst -y K3.4.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 3 -q K3.5.Q -f K3.5.Fst -y K3.5.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 3 -q K3.6.Q -f K3.6.Fst -y K3.6.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 3 -q K3.7.Q -f K3.7.Fst -y K3.7.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 3 -q K3.8.Q -f K3.8.Fst -y K3.8.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 3 -q K3.9.Q -f K3.9.Fst -y K3.9.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 3 -q K3.10.Q -f K3.10.Fst -y K3.10.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 4 -q K4.1.Q -f K4.1.Fst -y K4.1.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 4 -q K4.2.Q -f K4.2.Fst -y K4.2.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 4 -q K4.3.Q -f K4.3.Fst -y K4.3.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 4 -q K4.4.Q -f K4.4.Fst -y K4.4.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 4 -q K4.5.Q -f K4.5.Fst -y K4.5.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 4 -q K4.6.Q -f K4.6.Fst -y K4.6.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 4 -q K4.7.Q -f K4.7.Fst -y K4.7.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 4 -q K4.8.Q -f K4.8.Fst -y K4.8.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 4 -q K4.9.Q -f K4.9.Fst -y K4.9.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 4 -q K4.10.Q -f K4.10.Fst -y K4.10.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 5 -q K5.1.Q -f K5.1.Fst -y K5.1.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 5 -q K5.2.Q -f K5.2.Fst -y K5.2.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 5 -q K5.3.Q -f K5.3.Fst -y K5.3.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 5 -q K5.4.Q -f K5.4.Fst -y K5.4.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 5 -q K5.5.Q -f K5.5.Fst -y K5.5.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 5 -q K5.6.Q -f K5.6.Fst -y K5.6.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 5 -q K5.7.Q -f K5.7.Fst -y K5.7.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 5 -q K5.8.Q -f K5.8.Fst -y K5.8.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 5 -q K5.9.Q -f K5.9.Fst -y K5.9.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 5 -q K5.10.Q -f K5.10.Fst -y K5.10.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 6 -q K6.1.Q -f K6.1.Fst -y K6.1.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 6 -q K6.2.Q -f K6.2.Fst -y K6.2.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 6 -q K6.3.Q -f K6.3.Fst -y K6.3.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 6 -q K6.4.Q -f K6.4.Fst -y K6.4.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 6 -q K6.5.Q -f K6.5.Fst -y K6.5.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 6 -q K6.6.Q -f K6.6.Fst -y K6.6.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 6 -q K6.7.Q -f K6.7.Fst -y K6.7.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 6 -q K6.8.Q -f K6.8.Fst -y K6.8.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 6 -q K6.9.Q -f K6.9.Fst -y K6.9.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 6 -q K6.10.Q -f K6.10.Fst -y K6.10.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 7 -q K7.1.Q -f K7.1.Fst -y K7.1.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 7 -q K7.2.Q -f K7.2.Fst -y K7.2.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 7 -q K7.3.Q -f K7.3.Fst -y K7.3.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 7 -q K7.4.Q -f K7.4.Fst -y K7.4.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 7 -q K7.5.Q -f K7.5.Fst -y K7.5.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 7 -q K7.6.Q -f K7.6.Fst -y K7.6.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 7 -q K7.7.Q -f K7.7.Fst -y K7.7.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 7 -q K7.8.Q -f K7.8.Fst -y K7.8.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 7 -q K7.9.Q -f K7.9.Fst -y K7.9.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 7 -q K7.10.Q -f K7.10.Fst -y K7.10.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 8 -q K8.1.Q -f K8.1.Fst -y K8.1.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 8 -q K8.2.Q -f K8.2.Fst -y K8.2.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 8 -q K8.3.Q -f K8.3.Fst -y K8.3.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 8 -q K8.4.Q -f K8.4.Fst -y K8.4.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 8 -q K8.5.Q -f K8.5.Fst -y K8.5.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 8 -q K8.6.Q -f K8.6.Fst -y K8.6.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 8 -q K8.7.Q -f K8.7.Fst -y K8.7.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 8 -q K8.8.Q -f K8.8.Fst -y K8.8.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 8 -q K8.9.Q -f K8.9.Fst -y K8.9.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 8 -q K8.10.Q -f K8.10.Fst -y K8.10.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 9 -q K9.1.Q -f K9.1.Fst -y K9.1.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 9 -q K9.2.Q -f K9.2.Fst -y K9.2.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 9 -q K9.3.Q -f K9.3.Fst -y K9.3.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 9 -q K9.4.Q -f K9.4.Fst -y K9.4.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 9 -q K9.5.Q -f K9.5.Fst -y K9.5.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 9 -q K9.6.Q -f K9.6.Fst -y K9.6.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 9 -q K9.7.Q -f K9.7.Fst -y K9.7.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 9 -q K9.8.Q -f K9.8.Fst -y K9.8.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 9 -q K9.9.Q -f K9.9.Fst -y K9.9.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 9 -q K9.10.Q -f K9.10.Fst -y K9.10.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 10-q K10.1.Q -f K10.1.Fst -y K10.1.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 10-q K10.2.Q -f K10.2.Fst -y K10.2.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 10-q K10.3.Q -f K10.3.Fst -y K10.3.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 10-q K10.4.Q -f K10.4.Fst -y K10.4.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 10-q K10.5.Q -f K10.5.Fst -y K10.5.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 10-q K10.6.Q -f K10.6.Fst -y K10.6.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 10-q K10.7.Q -f K10.7.Fst -y K10.7.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 10-q K10.8.Q -f K10.8.Fst -y K10.8.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 10-q K10.9.Q -f K10.9.Fst -y K10.9.sum -c 0.05
./TESS3 -x CHall.Dataset1.Final_1001.1842.geno -r coords.CH.Dataset1 -K 10-q K10.10.Q -f K10.10.Fst -y K10.10.sum -c 0.05
```

copy all the entropy scores to an excel sheet and plot in R

```
###################################
######Graph of cross-entropy scores

library(ggplot2)

CHall.entropy <- read.csv("cross.Entropy.K1_10.csv")
CHall.entropy <- as.data.frame(CHall.entropy)
CHall.entropy

ggplot(CHall.entropy, aes(x=CHall.entropy$K, y=CHall.entropy$cross.entropy.CHD1))+geom_point(shape=1) + ggtitle("Cross-entropy for CHall_1001.1842 ") + ylab("Cross-entropy")+xlab("K")
```
![alt_txt][Cross.entropy]
[Cross.entropy]:https://cloud.githubusercontent.com/assets/12142475/19119730/00e7d26a-8b21-11e6-86f1-d5826fede84e.png


According to this, it looks like K=2 or K=4. 


Use CLUMPP to average over all itirations of a given K. 

.indiv files need to be created by combining all the Q values into one file. And then paste 5 columns at the start of the doc as in Structure output. 
```
cat *2.Q > K2.allQ.indiv.csv
```

And manually paste the first five columns in. And leave a line open between runs. E.g. for K=2: 
```
1       1       (0)     1       :       0.576033        0.423967
2       2       (0)     1       :       0.855817        0.144183
3       3       (0)     1       :       0.787528        0.212472
4       4       (0)     1       :       0.827854        0.172146
5       5       (0)     1       :       0.822856        0.177144
6       6       (0)     1       :       0.806024        0.193976
7       7       (0)     1       :       0.913411        0.0865886
8       8       (0)     1       :       0.907361        0.0926394
9       9       (0)     1       :       0.797895        0.202105
10      10      (0)     1       :       0.849038        0.150962
```

copy these into the CLUMPP folder. Edit the .paramfile to reflect the number of runs. 
```
./CLUMPP Data1.paramfile -k 9 -i K9.allQ.txt -o K9.meanQ.out
```

These can be used to draw maps in R. 


K2-K4 in R: 

```
###Graphic display of TESS output
#########
library("fields")
library("RColorBrewer")
source("MapDisplay/POPSutilities.R")

Qmatrix <- read.table("K6.meanQ.out")
Qmatrix$V1 <- NULL
Qmatrix$V2 <- NULL
Qmatrix$V3 <- NULL
Qmatrix$V4 <- NULL
Qmatrix$V5 <- NULL

coords <- read.table("coords.992indivs")  ##these have the 9 potentially contaminated indivs removed
plot(coords, pch = 19, xlab = "Longitude", ylab= "Latitude")
#?map
map(add = T, boundary = T, interior = T, col = "grey80")

asc.raster=("alps.asc")
asc.raster
grid=createGridFromAsciiRaster(asc.raster)  ##the .raster file needs to have YLLCENTER and XLLCENTER specified. Won't run otherwise. This can be changed manually using nano

constraints=getConstraintsFromAsciiRaster(asc.raster,cell_value_min=0)   ##constrains the map to the raster file size
maps(matrix = Qmatrix, coords, grid, method = "max", main = "Ancestry coefficients", xlab = "Longitude", ylab = "Latitude")

map(add = T, boundary = T, interior = T, col = "grey80")
```

![alt_txt][CHall.TESS3_K2]
[CHall.TESS3_K2]:https://cloud.githubusercontent.com/assets/12142475/19122496/02d23764-8b2b-11e6-94e5-c77e721adb18.png

![alt_txt][CHall.TESS3_K3]
[CHall.TESS3_K3]:https://cloud.githubusercontent.com/assets/12142475/19122495/02d174f0-8b2b-11e6-8a0d-ad5b70610d6c.png

![alt_txt][CHall.TESS3_K4]
[CHall.TESS3_K4]:https://cloud.githubusercontent.com/assets/12142475/19122498/02dc59ce-8b2b-11e6-8390-7bc8d2d0e5fa.png

![alt_txt][CHall.TESS3_K5]
[CHall.TESS3_K5]:https://cloud.githubusercontent.com/assets/12142475/19123131/c5a9a928-8b2d-11e6-85aa-a46a123a21a3.png

![alt_txt][CHall.TESS3_K6]
[CHall.TESS3_K6]:https://cloud.githubusercontent.com/assets/12142475/19123129/c59f2e44-8b2d-11e6-8bb9-f311ec18eb2d.png

![alt_txt][CHall.TESS3_K7]
[CHall.TESS3_K7]:https://cloud.githubusercontent.com/assets/12142475/19123130/c5a0702e-8b2d-11e6-8de7-8e6aaf2ad091.png



After K=6, new colours need to be added to the source code. Check http://www.datavis.ca/sasmac/brewerpal.html for options. 





Based on the results from this reduced dataset, I've created a spreadsheet comparing fastStructure K2, K3, and geographic locations. I am choosing how to subset the data based on this. See excel sheet: CHall.subsetsbasedonK4_20161005.xls


####Dataset2: All CH and subsets

MAC of 60 ~3%  (what percentage should I use for the initial stats and then for the rest of the analyses??)

```
vcftools --vcf CH_6.100.vcf --mac 60 --recode --recode-INFO-all --out CHall_1027.s1 

VCFtools - v0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf CH_6.100.vcf
	--recode-INFO-all
	--mac 60
	--out CHall_2027.s1
	--recode

Eighth Header entry should be INFO: INFO    
After filtering, kept 1029 out of 1029 Individuals
Outputting VCF file...
After filtering, kept 142303 out of a possible 5784222 Sites
Run Time = 966.00 seconds

input file was 23Gb. Output 564Mb

vcftools --vcf CHall_1027.s1.recode.vcf --max-missing 0.5 --recode --recode-INFO-all --out CHall_1027.s2

VCFtools - v0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf CHall_2027.s1.recode.vcf
	--recode-INFO-all
	--max-missing 0.5
	--out CHall_2027.s2
	--recode

After filtering, kept 1029 out of 1029 Individuals
Outputting VCF file...
After filtering, kept 20113 out of a possible 142303 Sites
Run Time = 34.00 seconds


vcftools --vcf CHall_1027.s2.recode.vcf --thin 200 --recode --recode-INFO-all --out CHall.thin200.recode.vcf

VCFtools - v0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf CHall_2027.s2.recode.vcf
	--recode-INFO-all
	--thin 500
	--out CHall_1027.s3
	--recode

After filtering, kept 1029 out of 1029 Individuals
Outputting VCF file...
After filtering, kept 9760 out of a possible 20113 Sites
Run Time = 7.00 seconds


vcftools --vcf CHall.thin200.recode.vcf --missing-indv

mawk '!/IN/' out.imiss | cut -f5 > totalmissing

gnuplot << \EOF 
set terminal dumb size 120, 30
set autoscale 
unset label
set title "Histogram of % missing data per individual"
set ylabel "Number of Occurrences"
set xlabel "% of missing data"
#set yr [0:100000]
binwidth=0.01
bin(x,width)=width*floor(x/width) + binwidth/2.0
plot 'totalmissing' using (bin( $1,binwidth)):(1.0) smooth freq with boxes
pause -1
EOF
```

![alt_txt][CHmissing]
[CHmissing]:https://cloud.githubusercontent.com/assets/12142475/18841980/cda53a14-8413-11e6-85f1-fb6a6dd793e5.png


Based on the number of individuals lost per population, I've decided to keep individuals with <0.45 missing data. This means there is a bit of missing data, but it I dont lose any of the populations. 


```
vcftools --vcf CHall.thin200.recode.vcf --remove indvs.missingmorethan0.55 --recode --recode-INFO-all --out CHall_1027.s4

VCFtools - v0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf CHall_1027.s3.recode.vcf
	--exclude indvs.missingmorethan0.55
	--recode-INFO-all
	--out CHall_1027.s4
	--recode

Excluding individuals in exclude list
After filtering, kept 949 out of 1029 Individuals
Outputting VCF file...
After filtering, kept 9760 out of a possible 9760 Sites
Run Time = 6.00 seconds
```


Rename the 949 individuals

```

bcftools reheader CHall.thin200.recode.vcf -s new.names -o CHall.949.9760.vcf
```

4.Filter for >0.6 obs Het

Based on my recent checks on the pyRAD data, I should also filter all SNPs with >0.6 observed Heterozygosity.

I will do this in R using the PLINK file.

Convert to plink on gdcsrv1 (limited memory on mac)

```
vcftools --vcf CHall.940.9760.vcf.recode.vcf --plink --out CH.940.9760.plink
```

Calculate HWE for all loci in PLINK

```
plink --file CH.949.9760.plink --hardy
```

PLINK output plink.hwe has a very strange format - multiple spaces between columns - so I couldn't figure out how to cut a specific column using linux

I sorted everything in excel.

There are only 89 of 9696loci with O.Het >0.6 (i.e. 0.91%)

```
nano SNPsHWE.remove
```

Remove with plink

```
plink --file CH.940.9760.plink --exclude SNPsHWE.remove --recodeA --recode --out CHall.940.9608.plink

@----------------------------------------------------------@
|        PLINK!       |     v1.07      |   10/Aug/2009     |
|----------------------------------------------------------|
|  (C) 2009 Shaun Purcell, GNU General Public License, v2  |
|----------------------------------------------------------|
|  For documentation, citation & bug-report instructions:  |
|        http://pngu.mgh.harvard.edu/purcell/plink/        |
@----------------------------------------------------------@

Web-based version check ( --noweb to skip )
Connecting to web...  OK, v1.07 is current

+++ PLINK 1.9 is now available! See above website for details +++ 

Writing this text to log file [ CHall.940.9608.plink.log ]
Analysis started: Thu Oct  6 13:45:01 2016

Options in effect:
	--file CH.940.9760.plink
	--exclude SNPsHWE.remove
	--recodeA
	--recode
	--out CHall.940.9608.plink

** For gPLINK compatibility, do not use '.' in --out **
9696 (of 9696) markers to be included from [ CH.940.9760.plink.map ]
Warning, found 940 individuals with ambiguous sex codes
Writing list of these individuals to [ CHall.940.9608.plink.nosex ]
940 individuals read from [ CH.940.9760.plink.ped ] 
0 individuals with nonmissing phenotypes
Assuming a disease phenotype (1=unaff, 2=aff, 0=miss)
Missing phenotype value is also -9
0 cases, 0 controls and 940 missing
0 males, 0 females, and 940 of unspecified sex
Reading list of SNPs to exclude [ SNPsHWE.remove ] ... 88 read
Before frequency and genotyping pruning, there are 9608 SNPs
940 founders and 0 non-founders found
Total genotyping rate in remaining individuals is 0.698913
0 SNPs failed missingness test ( GENO > 1 )
0 SNPs failed frequency test ( MAF < 0 )
After frequency and genotyping pruning, there are 9608 SNPs
After filtering, 0 cases, 0 controls and 940 missing
After filtering, 0 males, 0 females, and 940 of unspecified sex
Writing recoded ped file to [ CHall.940.9608.plink.ped ] 
Writing new map file to [ CHall.940.9608.plink.map ]
```

Final dataset:

940 individuals

9608 SNPs

0.699 Genotyping rate

Use pgdspider to convert .ped PLINK file to vcf. And keep plink and vcf files on mac:

/Users/alexjvr/2016RADAnalysis/SE.MS1/subsets/

And replace the headers (pgdspider doubles the names). Remember oldnames newnames format in the reheader file

```
bcftools reheader CHall.940.9608.vcf -s 940.9608.newnames -o CHall.940.9608.newnames.vcf
```

Subset the data to create the following input files: 

```

vcftools --vcf CHall.940.9608.newnames.vcf --keep CHS.TI.indivstokeep --recode --recode-INFO-all --out CHS.TI
```


1. CHall.940.9608.newnames.vcf (already created)

2. CHN.229.9608.recode.vcf

3. CHS.283.9608.recode.vcf	

4. CHS.VS.135.9608.recode.vcf

5. CHS.TI.148.9608.recode.vcf

6. CZ.404.9608.recode.vcf




F-statistics

Het/nucleotide diversity

IBD


##Population Structure

TESS3


fastStructure



##Environmental variables: PCA

Decide which environmental variables to use. This should probably be based on the results from the Landscape genetic analysis. 


##Outlier Analysis

###1. PCAdapt



###2. BayeScan

This is available on the Sork computers: 

soney@sorklab3.eeb.ucla.edu

signem123

Check with Sorel before running anything: sorel@ucla.edu

more programs in ~/data




##EAA

I need to determine the corrolation between all climate and all landscape variables, so that I can choose a representative sample of variables. 

Josh extracted all these data. I will use the landscape data from the 200m buffers surrounding the sample site. 

in R:
```
##https://www.r-bloggers.com/introduction-to-feature-selection-for-bioinformaticians-using-r-correlation-matrix-filters-pca-backward-selection/
library(corrplot)
setwd("/Users/alexjvr/2016RADAnalysis/5_CH.landscapeGenomics/subsets/BayENV2")
datMy <- read.table("CHclimate.forCorr_20161006.txt", header=TRUE)

datMy.scale <- scale(datMy[1:ncol(datMy)], center=T, scale = T) #scale all the features (from feature 2 bacause feature 1 is the predictor output)

corMatMy <- cor(datMy.scale) #compute the correlation matrix

corrplot(corMatMy, order = "hclust", tl.cex = 0.5)
#visualize the matrix, clustering features by correlation index.

highlyCor <- findCorrelation(corMatMy, 0.80) #After inspection, apply correlation filter at 0.80,
#then we remove all the variable correlated with more 0.8.
datMyFiltered.scale <- datMy.scale[,-highlyCor]
corMatMy <- cor(datMyFiltered.scale)
corrplot(corMatMy, order = "hclust")
```
This leaves me with 6 environmental variables: 

![alt_txt][rcorr.CH43Env]
[rcorr.CH43Env]:https://cloud.githubusercontent.com/assets/12142475/19196863/7c7ce5ea-8cb7-11e6-85ab-5514ea25531d.png

![alt_txt][rcorr.CH6Env]
[rcorr.CH6Env]:https://cloud.githubusercontent.com/assets/12142475/19196864/7c7f5c80-8cb7-11e6-9be2-dd8b28c1bcae.png

The 7 ENV variables that I will use for the analyses. 



Some alternative methods
```
###Useful code that I didnt use
##read .csv in as numeric

read.csv(input_filename, stringsAsFactors = F) -> CH.climate ##input here was CHclimate.forCorr_20161006.csv
data.frame(data.matrix(CH.climate)) -> num_data
numeric_columns <- sapply(num_data,function(x){mean(as.numeric(is.na(x)))<0.5})
CH.final_data <- data.frame(num_data[,numeric_columns], CH.climate[,!numeric_columns])

##calculate correlation between all of the variables
cor(CH.final_data)

pairs(CH.final_data)  ##quick plot


###For prettier and more versatile plots 
####https://www.r-bloggers.com/five-ways-to-visualize-your-pairwise-comparisons/

library(Deducer)  ##install or load package for use of ggcorplot

ggcorplot(
  data = CH.final_data[5:11],   ##choose all precip columns
  var_text_size = 5,
  cor_text_limits = c(5,10))
  
  
 ####Correlation of all variables in R
###Aim: find reduced set of climate and landscape variables to use in EAA

library(Deducer)  ##install or load package for use of ggcorplot

ggcorplot(
  data = CH.final_data[5:11],   ##choose all precip columns
  var_text_size = 5,
  cor_text_limits = c(5,10))

#install.packages("Deducer", dependencies = T)
library(Deducer)


###in R.studio
setwd("/Users/alexjvr/2016RADAnalysis/5_CH.landscapeGenomics/subsets/BayENV2/")

read.csv("climate.annual.precip.csv", stringsAsFactors = F) -> CH.climate ##input here was CHclimate.forCorr_20161006.csv
data.frame(data.matrix(CH.climate)) -> num_data
numeric_columns <- sapply(num_data,function(x){mean(as.numeric(is.na(x)))<0.5})
CH.final_data <- data.frame(num_data[,numeric_columns], CH.climate[,!numeric_columns])

##calculate correlation between all of the variables
cor.mat.CH <- cor(CH.final_data) 

pairs(CH.final_data)  ##quick plot


corr.mat1<-cor.matrix(variables=d(annual.pcpt,SD.annual.pcpt,pcpt.Mar,pcpt.Apr,pcpt.May,pcpt.Jun,pcpt.Jul,pcpt.Aug),,
                      data=CH.final_data,
                      test=cor.test,
                      method='spearman',
                      alternative="two.sided",exact=FALSE)

ggcorplot(corr.mat1,data = CH.final_data)


###REinis way

#setwd("/Users/reinholdstockenhuber/Desktop/aha_t")
dat <- read.table("CHclimate.forCorr_20161006.txt", header=TRUE)
head(dat)
str(dat)
#check correlation of the different variables just by eye
plot(dat)

#the calculated correlation
library(Hmisc)
# correlate a matrix of several values, you might be interested in: here, i chose 4 environmental variables:
#alt = altitude, precyy = annual precipitation, sradyy = annual solar radation, swb = site water balance 

cdat<-rcorr(as.matrix(dat[,c("elev", "SD.annual.pcpt", "pcpt.May", "pcpt.Aug", "solar.rad.Aug", "temp.laying.date", "day10cm")]), type="pearson")
cdat
#you can now see a) the correlation coeff. (r) and b) the p-value of a linear model your correlations
#
#  in addition you may want to see the linear model of these two variables
plot(elev~lat,data=dat)
m1 <- lm(elev ~ lat, data=dat)
anova(m1);summary(m1)

dat2 <- dat[,1:41]
head(dat2)
HighCorr <- findCorrelation(cor(dat2), cutoff = 0.8, verbose=T)
head(HighCorr)
HighCorr <- sort(HighCorr)
head(HighCorr)
reduced_data <- dat[,-c(HighCorr)]
head(reduced_data)

??findCorrelation
 
```



###1. BayEnv2

https://bitbucket.org/tguenther/bayenv2_public/src/8e4039f64d61?at=default

 1.   Input file with all SNPs for the association analysis

 2.   Input file with subset of 500 SNPs for co-variance matrix (pop structure)

 3.   ENV input file with normalised environmental parameters. I'm using the 7 variables identified earlier (see above)

 NB: population order in the input files should all be the same.

####1. Large input

Convert using pgdspider

All subsets in their own folder in /Users/alexjvr/2016RADAnalysis/5_CH.landscapeGenomics/subsets/BayENV2/


####2. 500SNPs

Copy 1000 SNPs from the pgdspider output *_loci. 

```
head -n 1000 *_loci > SNPs1000CHS
```


keep only these SNPs in the vcf file. 

```
vcftools --vcf CHall.940.9608.newnames.vcf --snps SNPs1000 --recode --recode-INFO-all --out CHall.940.1000.vcf

VCFtools - v0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf CHall.940.9608.newnames.vcf
	--recode-INFO-all
	--out CHall.940.1000.vcf
	--recode
	--snps SNPs1000

After filtering, kept 940 out of 940 Individuals
Outputting VCF file...
After filtering, kept 999 out of a possible 9608 Sites
```
And convert to BayEnv using pgdspider



Generate the co-variance matrix:

Bayenv2 needs to be run from the command line from its folder: /Users/alexjvr/Applications/bayenv2/compiled_on_a_mac. I've copied the executable over to the mac and run everything there. The bayenv2 file can be copied into each folder. 

Estimate the matrix
```
./bayenv2 -i CHall.940.1000.Bayenv.txt -p 82 -k 100000 -r 63479 > CHall.matrix.out
```

Copy the last matrix from this .out file and paste into a new file (using nano). First paste into excel to make sure all the spacing is correct. Make sure of this! This was a problem before. 


####3. ENVIRON file

```
####ENV input for BayENV
##Columns = pops
##Rows = Env variables
##Standardise the data

#install.packages("clusterSim")
library(clusterSim)

setwd("/Users/alexjvr/2016RADAnalysis/5_CH.landscapeGenomics/subsets/BayENV2/")
file <- NULL
file <- read.csv("AllEnv.Data_CZ_20161010.csv", header=T)

df <- NULL
df <- data.frame(pop=file$site, elev=file$elev, shadow=file$shadow.days, temp=file$temp.laying.date, SD.pcpt=file$SD.annual.pcpt, pcptMay=file$pcpt.May, pcptAug=file$pcpt.Aug, solarRad.Aug=file$solar.rad.Aug, meanmintemp=file$mean.min.temp)  ##create dataframe with only the columns of interest
summary(df)

df.norm <- NULL
df.norm <- data.Normalization(df[,2:ncol(df)], type="n1", normalization="column") ##normalise the data. See --help for data.Normalisation to see other normalisation options

summary(df.norm)

##transpose the dataframe

n <- NULL
n<- df$pop  ##remember the pop names

# transpose all standardised data
df.norm.transposed <- as.data.frame(t(df.norm))
colnames(df.norm.transposed) <- n ##just to check the order of the pops in the file
head(df.norm.transposed)
colnames(df.norm.transposed) <- NULL ##and drop the column names
#df.norm.transposed$myfactor <- factor(row.names(df.norm.transposed))

str(df.norm.transposed) # Check the column types
head(df.norm.transposed)

write.table(df.norm.transposed, "ENVIRONFILE.CZ.csv", sep=",")##write to file

```

open the .csv. Copy and paste the environmental data to a new file on the server *.ENV
Do this to ensure that all the spacing works. This was a problem before, so check on this! 

####Run bayenv2

In the folder on the server: 

bayenv2 executable

.ENV input

.MATRIX input

.bayenv.txt input file (converted with pgdspider). 

First split the input file into individual loci
```
split -d -a 10 -l 2 CHall.940.9608.bayEnv2.txt snp_batch
```
This creates files with allele counts per locus. 

and loop bayenv through all input files: 
```
for f in $(ls snp_batch); do ./bayenv2 -i $f -e CHall.ENV -m CHall.MATRIX -k 100000 -p 82 -n 8 -r $RANDOM -t -c; done 
```

pop sizes: 

CHall -p 82

CZ -p 38

CHN -p 19

CHS -p 25

CHS.VS -p 10

CHS.TI -p 15



###2. LFMM

Make sure that R3.3.1 is launched. (Or later than R3.2)

LEA is a bioconductor package.

http://www.bioconductor.org/packages/release/bioc/html/LEA.html

In R:

```
source("http://bioconductor.org/biocLite.R")
biocLite("LEA")

library(LEA)
```

Remove any non-polymorphic sites from the vcf file. I've used the list of SNPs from the bayenv2 input to keep using --snps in vcftools
```
vcftools --vcf input.vcf --snps listofnames.snps --recode --recode-INFO-all --out n.snps.vcf
```

Convert the vcf file to lfmm format in R

```
library(LEA)

genotype = vcf2geno("name.vcf")
```

Convert the environmental data to the specific .ENV format needed by lfmm. Remember that .csv environmental input file needs env data for all individuals. 

```
env <- read.csv("BIOclim_allindivs_SEsubset.csv.env", header=F) ###read in the environmental data
write.env(env, "SE.env")   ##convert to correct .env format
[1] "SE.env"
```


use snmf to determine how many latent factors best describe the population structure:
```
obj.snmf = snmf(genotype, K = 1:20, entropy = T, ploidy = 2, project="new")   ###K range to be tested should be increased as needed. 
plot(obj.snmf)  ###see at which K cross-entropy is the lowest

```


CHN: K4

![alt_txt][CHN.K4]
[CHN.K4]:https://cloud.githubusercontent.com/assets/12142475/19263984/339c8016-8f9f-11e6-9c78-6782777aa717.png



CHS.TI: K6

![alt_txt][CHS.TI.K6]
[CHS.TI.K6]:https://cloud.githubusercontent.com/assets/12142475/19264160/ed7b7992-8f9f-11e6-82af-74788205ae5b.png


CHS.VS: K4
![alt_txt][CHS.VS.K4]
[CHS.VS.K4]:https://cloud.githubusercontent.com/assets/12142475/19264069/94ee38c8-8f9f-11e6-9667-bb48bfef4c83.png


CHS: K10
![alt_txt][CHS.K11]
[CHS.K11]:https://cloud.githubusercontent.com/assets/12142475/19264518/487c5ab8-8fa1-11e6-9d1e-3690e948430c.png


CZ: K9

![alt_txt][CZ.K9]
[CZ.K9]:https://cloud.githubusercontent.com/assets/12142475/19264784/800d6fde-8fa2-11e6-8517-bcb3832d2619.png


CHall K19 or 20  - but what about overfitting???
![alt_txt][CHall.K4]
[CHall.K4]:https://cloud.githubusercontent.com/assets/12142475/19264778/7b663f9c-8fa2-11e6-8998-6faa85e504be.png




And run lfmm at the chosen K. This should be run on the server. 
```

project = lfmm("SEsubset.Final2.geno", "SE.env", K = 2, repetitions = 5, project = "new")  ##run LFMM with this .env file

```

Postprocessing: 







##Comparison between the different datasets and different analyses (Venn Diagram)








##Genomic Turnover: Gradient Forest






##Genomic Turnover: GDM






##Other Analyses??
