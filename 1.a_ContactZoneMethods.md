# Methods for Contact zone MS

NBNB 

Popgen code: 

https://popgencode.wordpress.com

https://github.com/rystanley/genepopedit




Questions:

1. Are Alps barrier to dispersal?

2. Contact zone - How genomically distinct?

3. Is differentiation structured or bias in introgression?

4. For biased loci, any association with temperature/elevation?








## Sampling

To determine the genomic cline across the contact zone, populations were sampled from pure northern mitochondrial haplotypes across the contact zone including pure southern mitochonridal haplotypes. 

Reduced representation libraries were produced using the double digest Restriction Associated DNA (ddRAD) sequencing protocol (Peterson et al. 2012) with some modifications. Specifically, EcoRI and MSeI were chosen as restriction enzymes. 

Single end libraries were sequenced for 150bp on an Illumina xx. 

## Datasets

### 1. SNP calling with pyRAD

### 2. Generate datasets
    
    a. subset: 2Mil reads per sample (downsampled .trim reads and rerun pyRAD)
    
    b. Full dataset. 
    
    
a. subset: 

This was run on gdcsrv. Located at alexjvr@gdcsrv1.ethz.ch:/gdc_home4/alexjvr/CH.Phylogenomics/outfiles_subset.CH.Phylo

Filtering: 

1. Keep only the EAST individuals

2. MAC

3. Missingness

4. Convert to Plink and filter for Het >0.7


#### 1. Keep all the EAST individuals

Got the list of names from /Users/alexjvr/2016RADAnalysis/1_Phylo/GenomicClines/EAST.names

copied it to the server and renamed to the full names (including cat & .fq.trim)

```
vcftools --vcf subset.CH.Phylo.vcf --keep EAST.names --recode --recode-INFO-all --out subset.EAST.s1
```

Kept 118 out of 230 individuals 


#### 2. Filters

Filter for missingness of 0.5 and MAC 3 (3/(118*2) = 1.2% MAF)

50% genotyping rate. And MAC of 3. (across 230 indivs = 3/460 = 0.65%) - I should probably increase this! Rather use a MAF of 1%
```
vcftools --vcf subset.EAST.s1.recode.vcf --max-missing 0.5 --mac 3 --recode --recode-INFO-all --out subset.EAST.s2
```

Output: 
```
Parameters as interpreted:
	--vcf subset.EAST.s1.recode.vcf
	--recode-INFO-all
	--mac 3
	--max-missing 0.5
	--out subset.EAST.s2
	--recode

After filtering, kept 118 out of 118 Individuals
Outputting VCF file...
After filtering, kept 30981 out of a possible 1063455 Sites
Run Time = 48.00 seconds
```


And check the missingness for the individuals: 
```
vcftools --vcf subset.EAST.s2.recode.vcf --missing-indv

mawk '!/IN/' out.imiss | cut -f5 > totalmissing

gnuplot << \EOF 
set terminal dumb size 120, 30
set autoscale 
unset label
set title "Histogram of % missing data per individual"
set ylabel "Number of Occurrences"
set xlabel "% of missing data"
#set yr [0:100000]
binwidth=0.01
bin(x,width)=width*floor(x/width) + binwidth/2.0
plot 'totalmissing' using (bin( $1,binwidth)):(1.0) smooth freq with boxes
pause -1
EOF
```

Output: 

![Fig1](https://cloud.githubusercontent.com/assets/12142475/17170713/47a3577e-53e5-11e6-9c2f-9c422b357f6b.png)


All of the samples have <50% missing data. 


And if I try with --max-missing 0.8 followed by the rest of the filtering 

```
vcftools --vcf CH.Phylo.vcf.recode.vcf --max-missing 0.8 --mac 3 --recode --recode-INFO-all --out s1.Phylo.RAD.vcf

Parameters as interpreted:
	--vcf subset.EAST.s1.recode.vcf
	--recode-INFO-all
	--mac 3
	--max-missing 0.8
	--out subset.EAST.s2
	--recode

After filtering, kept 118 out of 118 Individuals
Outputting VCF file...
After filtering, kept 5802 out of a possible 1063455 Sites
Run Time = 43.00 seconds
```

![Fig2](https://cloud.githubusercontent.com/assets/12142475/17170898/1e328a4e-53e6-11e6-9865-140dbbd990c9.png)

So <0.3 missing data. 


Rename the samples in vcf file: 

First get a list of all the samples: 
```
bcftools query -l subset.imiss80.recode.vcf

```

copy and paste this to excel. And rename accordingly (I remove the "cat" and ".fq.trim"). Nano and paste into a new file. 

Paste back: 
```
bcftools reheader subset.EAST.s2.recode.vcf -s EAST.names -o subset.EAST.s3.vcf
```


###3. Thin to 1 SNP per locus: 

```
vcftools --vcf subset.EAST.s3.vcf --thin 500 --recode --recode-INFO-all --out subset.EAST.thinned.vcf

Parameters as interpreted:
	--vcf subset.EAST.s3.vcf
	--recode-INFO-all
	--thin 500
	--out subset.EAST.thinned.vcf
	--recode

After filtering, kept 118 out of 118 Individuals
Outputting VCF file...
After filtering, kept 2399 out of a possible 5802 Sites
Run Time = 0.00 seconds
```

####4.Filter for >0.7 obs Het

Based on my recent checks on the pyRAD data, I should also filter all SNPs with >0.7 observed Heterozygosity. 

I will do this in R using the PLINK file.

Convert to plink
```
vcftools --vcf subset.EAST.s4THIN.recode.vcf --plink --out subset.EAST.s4
```

Calculate HWE for all loci in PLINK
```
plink --file subset.EAST.s4 --hardy
```

PLINK output plink.hwe has a very strange format - multiple spaces between columns - so I couldn't figure out how to cut a specific column using linux

I sorted everything in excel.

There are only 24 SNPs with O.Het >0.6 (i.e. 0.19%) 

62398:4
78226:93
133358:7
267920:70
39465:59
126930:112
19060:14
286067:81
178295:84
173522:78
79355:21
140229:67
277990:41
161923:106
133065:51
191402:71
3053:75
61372:10
157987:33
19818:115
229342:14
758:72
17377:3
247581:17

Remove with plink 
```
nano SNPstoexclude.txt

plink --file subset.EAST.s4 --exclude SNPtoexclude.txt --recodeA --recode --out subsetEAST.Final
```

Rename with shorter names. Rememeber to specify the old and the new names
```
bcftools reheader subsetEAST.Final.vcf -s reheader.newnames -o ContactZone.newnames.vcf
```

Final dataset: 

118 individuals

2358 SNPs 

0.885 Genotyping rate

Use pgdspider to convert .ped PLINK file to vcf. And keep plink and vcf files on mac: 

/Users/alexjvr/2016RADAnalysis/1.2_Phylo/input.files/

And replace the headers
    
##Population Structure



Dataset 1. 

### 1. Geographic prior

   #### a. TESS3
 
 TESS3 uses a new method to infer ancestry: Geographically constrained least-squares estimation of ancestry coefficients.  
http://onlinelibrary.wiley.com/doi/10.1111/1755-0998.12471/epdf

K is chosen by evaluating the cross-entropy criterion for each K. This method finds the minimum number of "bits" or samples from a normal probability distribution (p) that can predict a non-normal probability distribution (q). So the smaller this number is, the better the K. 


R package has been released in devtools: 

https://github.com/cayek/TESS3/blob/master/README.md

I need to use LEA to convert my data into TESS3 format: 

For this I had to upgrade R. The following link shows how to set up R-studio to use different versions of R: 

https://support.rstudio.com/hc/en-us/articles/200486138-Using-Different-Versions-of-R

In command line: 

```
export RSTUDIO_WHICH_R=/usr/local/bin/R

open -a rstudio
```

Make sure that R3.2.5 is launched. 

LEA is a bioconductor package. 

http://www.bioconductor.org/packages/release/bioc/html/LEA.html


In R: 

```
source("http://bioconductor.org/biocLite.R")
biocLite("LEA")

library(LEA)

setwd(/Users/alexjvr/2016RADAnalysis/1_Phylo/TESS)
output = vcf2geno("CH.230.Phylo.FINAL.vcf")
```

```
	- number of detected individuals:	118
	- number of detected loci:		2358

For SNP info, please check ./subsetEAST.Final.vcfsnp.

0 line(s) were removed because these are not SNPs.
Please, check ./subsetEAST.Final.removed file, for more informations.
```

Now I need the .coords file, which is a file with a lat & long column for each individual (no individual names). 

list all the samples in the vcf file

```
bcftools query -l subsetEAST.Final.vcf
```

```
nano subsetEAST.Final.coords  ##paste all the coords into this file
```

To run TESS3: 

The executable needs to be copied to the current directory
```
cp ~/Applications/TESS3-master/build/TESS3 .

./TESS3 -x subsetEAST.Final.geno -r subsetEAST.coords -K 2 -q K2.1.Q -g K2.1.G -f K2.1.Fst -y K2.1.sum -c 0.05
```

Run this for K 1-5 x 10 iterations. 

-I can be used to select a random subset of samples. But this full dataset ran in ~10sec, so probably not necessary. 

-y = least-squares criterion

-c = percentage of the masked genotypes. (0.05 by default). If this is set, the cross-entropy criterion is calculated. 

-i = max nr of iterations. (default = 200)

Paste all of the entropy scores into a csv file. And plot in R: 

```
####################################
######Graph of cross-entropy scores

setwd("/Users/alexjvr/2016RADAnalysis/1_Phylo/TESS")
library(ggplot2)

CHS.entropy <- read.csv("Cross-entropy.scores.CHS.Brown.csv")
CHS.entropy <- as.data.frame(CHS.entropy)
CHS.entropy

ggplot(CHS.entropy, aes(x=CHS.entropy$K, y=CHS.entropy$Cross.entropy)) + geom_point(shape=1) + ggtitle("Cross-entropy for CHS subset") + ylab("Cross-entropy") + xlab("K")
```



From the Min-Entropy graph, K = 2

I interpret this as the biggest change in cross-entropy scores, as they do in this tutorial: http://membres-timc.imag.fr/Olivier.Francois/tutoRstructure.pdf

![Fig3](https://cloud.githubusercontent.com/assets/12142475/17185505/4631bba8-5429-11e6-9c3b-300fb94c6f9e.png)


```
###Graphic display of TESS output
#########
setwd("/Users/alexjvr/2016RADAnalysis/1_Phylo/TESS")

install.packages("fields")
install.packages("RColorBrewer")
source("MapDisplay/POPSutilities.R")

Qmatrix <- read.table("CH.230.Phylo.FINAL.3.Q")
coords <- read.table("CH.230.new.coords")
plot(coords, pch = 19, xlab = "Longitude", ylab= "Latitude")
#?map
map(add = T, boundary = T, interior = T, col = "grey80")

asc.raster=("srtm_38_02.asc")
asc.raster
grid=createGridFromAsciiRaster(asc.raster)
constraints=getConstraintsFromAsciiRaster(asc.raster,cell_value_min=0)   ##constrains the map to the raster file size
maps(matrix = Qmatrix, coords, grid, method = "max", main = "Ancestry coefficients", xlab = "Longitude", ylab = "Latitude")


```
Remember to swap long & lat from the order in my own data. And move MapDisplay and ascii files to the working directory. 


Tess3 graph for K=2 and K=3

![EAST.K2](https://cloud.githubusercontent.com/assets/12142475/17185599/9b31e2c2-5429-11e6-9278-9a99ace217d9.png)


![EAST.K3](https://cloud.githubusercontent.com/assets/12142475/17185606/a03470e6-5429-11e6-9c50-58ad4caeb3d4.png)

    
   ### b. sPCA

### 2. Non-geographic prior

   ### a. fastStructure
    
Information here:

https://rajanil.github.io/fastStructure/

http://phylobotanist.blogspot.co.uk/2014/08/trying-to-use-faststructure.html

#### Run fastStructure

Convert input to Structure format using pgdSpider. Choose the specific fastStructure format. And change marker type to SNPs. Everything else should be left as is. All the columns are in the PLINK files.

fastStructure can be run from the Applications folder, or specify the path in bash: 

```
python /Users/alexjvr/Applications/fastStructure/fastStructure/structure.py -K 1 --format=str --input=subsetEAST.Final --output=subsetEAST_K1.1
```

I haven't figured out how to write a script to loop through fastStructure, but change the output file for each run. I.e. I have to manually run K 1-10 x 10 runs. According to the google group, this is how it has to be done. The runs take just a few seconds each.


#### Assessing K:

```    
python /Users/alexjvr/Applications/fastStructure/fastStructure/chooseK.py --input=subsetEAST_*


Model complexity that maximizes marginal likelihood = 2
Model components used to explain structure in data = 3
```

chooseK.py gives a range of best K, rather than an optimal K. So this is not very useful for me!!

https://groups.google.com/forum/#!topic/structure-software/s_rc_ueq6CU

Google groups suggests comparing plots for all optimal K, here K2-3. The way I've chosen the populations, I'm trying to differentiate between two clades with secondary contact. I'm quite confident that K=2, based on my sampling scheme. So I will compare both K, but wil work with K=2. 

In stead of choosing the most likely K as before in Structure, use CLUMPP to average over all the iterations for the most likely K.

#### CLUMPP

http://web.stanford.edu/group/rosenberglab/papers/clumppNote.pdf

    
   ### b. DAPC
    


## Hybrid Index calculation

Dataset 2. 

1. Identify "pure" individuals

2. Simulate hybrids

3. Calculate hybrid index of all individuals. 


## Genomic Cline Analysis

I'm using the subset data (2358 loci, 118 individuals) to test the Genomic Cline Analysis in Introgress. 

Manual: 

https://cran.r-project.org/web/packages/introgress/introgress.pdf


1. Download introgress package in R

Input files needed: 

1. admix.dat = transposed .str file of genotypes of all admixed individuals (or non-parentals)

2. P1 & P2 = same as admix.dat, but for each of the parents. 

	For inputs 1 & 2, first split the vcf file into the three datasets. Then convert to .str using pgdspider. Lastly, transpose in R.  
	
I need the following files for this: 

1. admix.gen = transposed .str of all admixed individuals

2. loci.dat = info on all the markers (column 1 = marker name, column 2 = Dominance (c), column 3 (opt) = linkage grp

3. Parental 1 & 2 = same format as the admix.gen file.  

	
Rename the sample names in subsetEAST.Final.vcf  --out subsetEAST.Final.2.vcf


```
#list of names in vcf file

bcftools query -l subsetEAST.Final.2.vcf

nano CHS.P2.names

nano CHN.P1.names

nano EAST.admix.names

###Split dataset in bash

```

`**I'm having trouble splitting my .vcf file.` 

Error: ID required in FORMAT field description: T,1,String,"Genotype"

In one of the working .vcf files, this is how FORMAT is coded: 

hashtag hashtag FORMAT= (smaller than symbol) ID=GT,Number=1,Type=String,Description="Genotype" (bigger than symbol)

i.s.o

hashtag hashtag FORMAT=GT,1,String,"Genotype"

Once I corrected this with nano, the file worked. 

```
##Split the dataset with bash: 

vcftools --vcf subsetEAST.Final.2.vcf --keep CHN.P1.names --recode --recode-INFO-all --out CHN.P1

Keeping individuals in 'keep' list
After filtering, kept 15 out of 118 Individuals
Outputting VCF file...
After filtering, kept 2358 out of a possible 2358 Sites

vcftools --vcf subsetEAST.Final.2.vcf --keep CHS.P2.names --recode --recode-INFO-all --out CHS.P2

Keeping individuals in 'keep' list
After filtering, kept 11 out of 118 Individuals
Outputting VCF file...
After filtering, kept 2358 out of a possible 2358 Sites

vcftools --vcf subsetEAST.Final.2.vcf --keep EAST.admix.names --recode --recode-INFO-all --out EAST.admix

Keeping individuals in 'keep' list
After filtering, kept 92 out of 118 Individuals
Outputting VCF file...
After filtering, kept 2358 out of a possible 2358 Sites


```

Convert to .str using pgdspider

In nano add "name" tab "pop" to the header otherwise it won't read into R. 


### 2. loci.dat

loci.dat = column 1: locus names, column 2 (type): c (for co-dominant markers)
	
	Generate this by copying all the locus names from the structure file and pasting c in the second column.  


```
head -1 CHN.P1.str > loci.names
```

nano & delete "name" & "pop"

Transpose with excel


Transpose

Tried some code (see below), but in the end transposed in excel and added a column with c (dominance). 

`**** Couldn't get this to work!!`

n is nr of columns to be printed (should match dashes in "paste")

-F is the separator 

```
rowcount=2358
for (( i=1; i<=rowcount; i++ )); do
    awk -v i="$i" -F : '{printf("%s\t ", $i)}' loci.names 
    echo | awk '{print}' >qq.tmp
done
```


### 3. P1 & P2

Correct P1 & P2 structure files by removing individual and pop info: 

```
cut -f 3- CHS.P2.str > CHS.P2.str.nonames
```


## R

```
###INTROGRESS for genomic cline analysis

setwd("/Users/alexjvr/2016RADAnalysis/1.2_Phylo/Introgress/")
library(introgress)

EAST <- read.table("EAST.admix.str")
EAST.1 <- as.matrix(EAST)
rawdata <- t(EAST.1)

P1 <- read.table("CHN.P1.str.nonames")
P1.1 <- as.matrix(P1)
P1.2 <- t(P1.1)

P2 <- read.table("CHS.P2.str.nonames")
P2.1 <- as.matrix(P2)
P2.2 <- t(P2.1)

loci.names <- read.table("loci.names2")
loci.names.2 <- as.matrix(loci.names)
loci.names.2

EASTnew <- prepare.data(admix.gen = rawdata, loci.data = loci.names.2, parental1 = P1.2, parental2 = P2.2, pop.id=T, ind.id=T, fixed=F, sep.rows=F)

```


## UPDATE

Introgress on their website has a disclaimer: Please note that while introgress does a fine job at summarizing and detecting variation in introgression among loci, it does not necessarily lead to strong inferences about the causes of the variation (e.g., detection of selected loci). For example, variation can arise due to genetic drift and does so commonly under certain reasonable conditions. For detecting expectionally differentiated loci, with less sensititivity to genetic drift, we suggest using bgc. Please see Gompert and Buerkle 2012 for a comparison of bgc and introgress. In both cases please be aware of the mutliple evolutionary processes that can lead to expectional differentiation.

They suggest using bgc in stead. 



# BGC 

Bayesian Genomic Cline Analysis

https://sites.google.com/site/bgcsoftware/

I just found a conversion package that's under development. I'll see if this works: 

https://github.com/rystanley/genepopedit

##Install Genepopedit

This doesn't work on older versions of R, so I'm running R from the command line: 

```
install.packages("devtools") # to install

devtools::install_github("rystanley/genepopedit")

library(genepopedit) # load the library
```

There was a problem with package stringr ->

I had to remove a folder and then reinstall this package separately. 

http://stackoverflow.com/questions/31866299/cannot-install-ggplot2-error-in-library-dynamlib-package-package-lib-sha

Then install genepopedit as above. 


Genepopedit takes genepop format. But it also needs the indiv names to be in a specific format: 

pop_indivname

So rename all the individuals with the following populations: P1, P2, Admix (you can use the normal pop names if the pops perfectly correspond with P1, P2 and Admix. But since I have multiple individuals per pop falling into the different catagories, this won't work)

```
bcftools reheader subsetEAST.Final.2.vcf -s genepopedit.names -o subsetEAST.newnames.vcf
```


Convert the correct vcf into genepop format using pgdspider

```
subsetEAST.newnames.vcf  ##renamed individuals

##make pop file, but use P1, P2, and admix as the populations

P1_indname	P1
P2_indname 	P2
...

BGC.newnames ##pop file for the .spid file
```

R

```
setwd("/Users/alexjvr/2016RADAnalysis/1.2_Phylo/BGC")

output_dir <- "/Users/alexjvr/2016RADAnalysis/1.2_Phylo/BGC/"

#specify which populations are going to be included in the analysis and to which class they belong. Note Pops identified in P1 and-or P2 can also be specified as "Admixed" to test BGC output. 
  BGC_groups = data.frame(pops = c("Admix","P1","P2"),groups = c("Admixed","P1","P2"))

#convert Genepop to BGC input files (3). Note in this case the variable path is a path to the directory where the input files will be saved.
  genepop_bgc(genepop="subsetEAST.genepop.txt",popdef = BGC_groups, fname="BGC_EAST",path = output_dir)
```



Input files: 

1. Parental files

list of loci with total allele counts in the population

locus 1
count count
locus 2
count count

2. Admix file

list of each locus, each pop, and allele count for each individual at each locus. 

locus 1
pop0
1 1
2 0 
...
locus 2



How to do it manually: 



### 1 Parental file

Get the allele counts using vcftools

```
vcftools --vcf subsetEAST.Final.2.vcf --counts --recode-INFO-all --out subsetEAST.Final.2.allele.counts
```

Cut and paste the allele counts in excel. Text to column and then nano into a new file

```
nano P1.allelecounts
```

Use the textfile from before with the locus names in and create the parental input files. Do this for both parental files: 

```
paste -d '\n' locusnames P1.allelecounts > P1.BGCinput
```

### 2 Admix file

Change all the allele counts to 012 coding: this counts the number of non-reference alleles at that locus in a particular individual. 

```
vcftools --vcf input.files/EAST.admix.recode.vcf --012 --out BGC/EAST.admix.count
```

open this in excel. Add in column headers (locus names), and pop (i.e. first two rows). Paste back with nano. 

Replace all missing data (-1) with -9. 

```
sed -i -e 's/-1/-9/g' EAST.admix.count.012_2
```

### BGCanalysis

Genomic cline analysis: 
Detects the loci that are dominant, underdominant, or under selection based on deviation from neutral expectations. Neutral expectations = based on hybrid index of the individual. 
So in a specific individual of hybrid index 0.5, we expect ab at locus. So if aa, then there's likely selection on that locus. 

It relates allele frequencies to genomic background

Geographic cline: 
Relates allele frequency to geographic background

Along a transition/ proposed contact zone. Are there some loci that have different geographic clines? This could indicate loci that are geographically important. 



Now we have the input files from genepopedit: 

Gompert et al. 2012 (Mol Ecol Resources)

and BGC R manual


#### Install BGC

```
h5c++ -Wall -O2 -o bgc bgc_main.C bgc_func_readdata.C bgc_func_initialize.C bgc_func_mcmc.C bgc_func_write.C bgc_func_linkage.C bgc_func_ngs.C bgc_func_hdf5.C mvrandist.c -lgsl -lm
```

I kept getting an error: Fatal error, missing omp.h. 

I thought this might be a problem with gcc/c++ on the mac. I've reinstalled gcc with the latest version and exported to $PATH, but still get this error. 

Christine said she deleted "omp.h" from all the .C files in the BGC folder (for me this was bgc_main.C and bgc_mcmc.C). 

This took care of the error, but now bgc doesn't run, and I can't autocomplete any of the files in the folder, even though I can see them. I can't understand what the problem is. 

Had BGC installed on the GDC server: /usr/local/bgc-1.03/bgc

Copied my input files onto the server and ran bgc: 

```
/gdc_home4/alexjvr/CH.ContactZone/bgc

/usr/local/bgc-1.03/bgc -a BGC_EAST_Parental1_BGC.txt -b BGC_EAST_Parental2_BGC.txt -h BGC_EAST_Admixed_BGC.txt -x 125000 -n 25000 -p 1 -q 1 -N 1 -t 10 -E 0.0001

Reading input files
Number of loci: 2358
Number of admixed populations: 1
Number of individuals: 92
Allowing for uncertainty in allele counts
Allocating memory
Initializing MCMC chain
Initialization complete
mcmc iteration: 0 ........ LnL: -235733
mcmc iteration: 1000 ........ LnL: -221988
mcmc iteration: 2000 ........ LnL: -223612
mcmc iteration: 3000 ........ LnL: -222707
mcmc iteration: 4000 ........ LnL: -220551
mcmc iteration: 5000 ........ LnL: -224167
mcmc iteration: 6000 ........ LnL: -220827
mcmc iteration: 7000 ........ LnL: -222873
mcmc iteration: 8000 ........ LnL: -229443
mcmc iteration: 9000 ........ LnL: -225135
mcmc iteration: 10000 ........ LnL: -227014
mcmc iteration: 11000 ........ LnL: -239949
...
mcmc iteration: 124000 ........ LnL: -231983
Finished mcmc
Runtime: 38 hr 19 min 26 sec
```

Time taken: ~39 hours


For next gen data, 2 independent runs need to be assessed. 

Tuning parameters may need adjustment to achieve sufficient mixing of the mcmc chains. 

Evaluate mixing and convergence by 

1. convert the output from hdf5 to ascii using estpost

2. plotting in R

```
/usr/local/bgc-1.03/estpost -i mcmcout.hdf5 -p alpha -o a.out -s 0 -c 0.95 -w 0
parameter dimensions for alpha: loci = 2358, samples = 10000, pouplations = 1

estpost -i mcmcout.hdf5 -p beta -o b.out -s 0 -c 0.95 -w 0
parameter dimensions for beta: loci = 2358, samples = 10000, pouplations = 1

estpost -i mcmcout.hdf5 -p LnL -o LnL.out -s 2 -c 0.95 -w 0
parameter dimensions for LnL: samples = 10000
```

copy over to mac and plot in R

```
scp alexjvr@gdcsrv1.ethz.ch:/gdc_home4/alexjvr/CH.ContactZone/bgc/*out .
```

`***I'm doing this in R now, but this is good to know: 

add column of row numbers as the x variable  
```
awk '$1=(FNR FS $1)' a.out > a.out2
```

R code: Plot alpha, beta, and LnL to check for convergence. If necessary, adjust burn-in and run parameters (see bgc manual). And run a second independent bgc analysis (i.e. 2 total). 
```
####Plots of BGC
##test for convergence

setwd("/Users/alexjvr/2016RADAnalysis/1.2_Phylo/BGC")

##alpha1
a1 <- read.csv("a.out", header = F)

colnames(a1) <- c("y1", "y2", "y3", "y4")  ##add column names
head(a1)

a1$x <- 1:nrow(a1) ##add column x
head(a1)


library("ggplot2")
library("reshape")

a1.melt <- melt(a1, id.vars=5)
head(a1.melt)

ggplot(a1.melt, aes(x, value, colour=variable)) +
  geom_point() +
  scale_color_manual(values = c("black", "black", "black", "black"))+
  xlab("mcmc") +
  ylab("alpha1") +
  ggtitle("EASTsubset alpha BGC run1") +
  theme(legend.position="none")

##beta1
b1 <- read.csv("b.out", header = F)

colnames(b1) <- c("y1", "y2", "y3", "y4")  ##add column names
head(b1)

b1$x <- 1:nrow(b1) ##add column x
head(b1)


library("ggplot2")
library("reshape")

b1.melt <- melt(b1, id.vars=5)
head(b1.melt)

ggplot(b1.melt, aes(x, value, colour=variable)) +
  geom_point() +
  scale_color_manual(values = c("black", "black", "black", "black"))+
  xlab("mcmc") +
  ylab("beta1") +
  ggtitle("EASTsubset beta BGC run1") +
  theme(legend.position="none")
  
##LnL1  
##This uses a function tcsv that transforms the data and reads in the header. I.e. can keep the numeric format, while specifying a text header
###Add "LnL," to the start of the file using nano in bash

read.tcsv = function(file, header=TRUE, sep=",", ...) {
  
  n = max(count.fields(file, sep=sep), na.rm=TRUE)
  x = readLines(file)
  
  .splitvar = function(x, sep, n) {
    var = unlist(strsplit(x, split=sep))
    length(var) = n
    return(var)
  }
  
  x = do.call(cbind, lapply(x, .splitvar, sep=sep, n=n))
  x = apply(x, 1, paste, collapse=sep) 
  out = read.csv(text=x, sep=sep, header=header, ...)
  return(out)
  
}

LnL1 <- read.tcsv("LnL.out.s2")
head(LnL1)

LnL1$x <- 1:nrow(LnL1) ##add column x
head(LnL1)

ggplot(LnL1, aes(x, LnL1$LnL, colour="black")) +
  geom_point() +
  scale_color_manual(values = c("black"))+
  xlab("mcmc") +
  ylab("LnL1") +
  ggtitle("EASTsubset Log likelihood BGC run1") +
  theme(legend.position="none")

```

Assessing BGC TestRun 1

![BGC_1](https://cloud.githubusercontent.com/assets/12142475/17731320/b03352e6-6464-11e6-8c21-d69e8bfb43ed.png)

![BGC_2](https://cloud.githubusercontent.com/assets/12142475/17731321/b0337d3e-6464-11e6-98aa-3bd18ceb186e.png)

![BGC_3](https://cloud.githubusercontent.com/assets/12142475/17731322/b036e08c-6464-11e6-892d-1d5795280380.png)






##### Run 2: 

From the plots, it looks like I need a longer burn-in. I will increase the run to 100k burn-in + 100k mcmc

```
/usr/local/bgc-1.03/bgc -a BGC_EAST_Parental1_BGC.txt -b BGC_EAST_Parental2_BGC.txt -h BGC_EAST_Admixed_BGC.txt -x 200000 -n 100000 -p 1 -q 1 -N 1 -t 10 -E 0.0001
```

This should take 76hrs to run. I've started the second run as well. 

![Run2](https://cloud.githubusercontent.com/assets/12142475/17969822/ce57b006-6acb-11e6-9676-fe02a66f1c74.png)


LnL still not stabilised. I could use a larger burn-in or start changing the tuning parameters. 


##### Run 3: 

I've changed the tuning params as Christine did in her paper, but using shorter run again: 

```
/usr/local/bgc-1.03/bgc -a /gdc_home4/alexjvr/CH.ContactZone/bgc/BGC_EAST_Parental1_BGC.txt -b /gdc_home4/alexjvr/CH.ContactZone/bgc/BGC_EAST_Parental2_BGC.txt -h /gdc_home4/alexjvr/CH.ContactZone/bgc/BGC_EAST_Admixed_BGC.txt -x 150000 -n 125000 -p 1 -q 1 -N 1 -t 10 -E 0.0001 -u 0.05 -g 0.1, -z 0.025
```

28 hrs runtime. 

So this plots only the last 25k runs (burn-in 125k)

![Run3](https://cloud.githubusercontent.com/assets/12142475/17969826/d494a366-6acb-11e6-8e9c-f7b2e4ba9a91.png)



Asked Christine's opinion: 

```
25 Aug 2016

Hi Alex,

I did spend quite some time tuning the parameters for bgc and was still not completely happy with the outcome at the end…

I mostly varied u, g and z and then (as they are related) I also plotted hi, alpha and beta over iterations.
to plot tau can be helpful as well.
Thats about what Zach suggested me in an email (which I searched for without success :( )
He also said many people run too view iterations and suggested about the numbers I used in the paper.

I think your likelihoods don’t look too bad. If your runs don’t take ages, I would consider running them a bit longer and just using the last 25000 or so.
And have a quick look at hi, alpha and beta over the iterations as well.

Hope that helps!

See you soon! :)

Christine
```


Now running the longer run with the new tuning params and longer burnin: Run4.1 and 4.2
```
/usr/local/bgc-1.03/bgc -a /gdc_home4/alexjvr/CH.ContactZone/bgc/BGC_EAST_Parental1_BGC.txt -b /gdc_home4/alexjvr/CH.ContactZone/bgc/BGC_EAST_Parental2_BGC.txt -h /gdc_home4/alexjvr/CH.ContactZone/bgc/BGC_EAST_Admixed_BGC.txt -x 200000 -n 150000 -p 1 -q 1 -N 1 -t 10 -E 0.0001 -u 0.05 -g 0.1, -z 0.025
```
~40 hours

Graphs: 

Run4_alpha

![4.1_alpha](https://cloud.githubusercontent.com/assets/12142475/18048332/668b6be6-6dd9-11e6-8a29-b1e2805d2dca.png)

![4.2_alpha](https://cloud.githubusercontent.com/assets/12142475/18048334/6e20b460-6dd9-11e6-8441-f2d21d326a86.png)


Run4_beta

![4.1_beta](https://cloud.githubusercontent.com/assets/12142475/18048342/775460c2-6dd9-11e6-829f-52ceebe2f1ec.png)

![4.2_beta](https://cloud.githubusercontent.com/assets/12142475/18048350/7e1095c0-6dd9-11e6-8b25-8dc543987262.png)

Run4_LnL

![4.1_LnL](https://cloud.githubusercontent.com/assets/12142475/18048360/89879ca0-6dd9-11e6-91e3-fbe8ab61eac0.png)

![4.2_LnL](https://cloud.githubusercontent.com/assets/12142475/18048369/8fcfcaec-6dd9-11e6-9993-dbafa5f5973c.png)



The likelihoods look stable enough now. 


But, when I compare the hybrid index between runs, it seems like the MCMC steps are getting stuck: 

```
/usr/local/bgc-1.03/estpost -i mcmcout.hdf5 -p hi -o hi.4b.out -s 0 -c 0.95 -w 0

##Look at these in excel

Run 1: ~0.5

Run 2: ~0.0

Run 3: ~1.00
```


#### EAST_5.1 - 5.3

So I need to work on the MCMC tuning parameters for the BGC run. Christine says she thinks it's the z-parameter (tau). The informatino in the manual is very unclear. But I've found out that the outputs for Beta and Alpha are always in the original order of the loci, and the hybrid index always in the original order of individuals. 

From the manual it looks to me to be parameter -u: max deviate from uniform for proposed hybrid index. In the last run this was set really strictly (-u 0.05). I've changed this to 0.2


```
/usr/local/bgc-1.03/bgc -a /gdc_home4/alexjvr/CH.ContactZone/bgc/BGC_EAST_Parental1_BGC.txt -b /gdc_home4/alexjvr/CH.ContactZone/bgc/BGC_EAST_Parental2_BGC.txt -h /gdc_home4/alexjvr/CH.ContactZone/bgc/BGC_EAST_Admixed_BGC.txt -x 200000 -n 150000 -p 1 -q 1 -N 1 -t 10 -E 0.0001 -u 0.2 -g 0.1, -z 0.025

```

Started 12 Sept 14:10. Expected finish: 15 Sept  (Total time 55hrs)

The Hybrid index from these runs are more congruent, but they aren't right. Across all samples they're ~0.06. I.e. the MCMC didn't find any hybrids. I have to optimise the tuning parameters. 

Things to vary: 

1. -I 0 use information from the data to initialize ancestry and hybrid index (currently this is on the default 0, but they use -I in the example analysis.)

2. -u MCMC tuning parameter, maximum deviate from uniform for proposed hybrid index hybrid index [default = 0.1].

	I changed this in run 5 to be bigger - i.e. more parameter space searched by the MCs. This meant that the runs converged, but the results were still completely incorrect. 
	
#### RUNS: (2 of each)

Set 1: -I 0; -u 0.2 (as in run 5)

Set 2: -I 0; -u 0.1

Set 3: -I 0; -u 0.05 (closer to Christine and the BGC example values)


I'm running these with a reduced dataset of 999 loci for a faster result

Subset the data
```
##Create a file of SNP names. This is easily copied from the genpop file: 

nano 1000loci

vcftools --vcf subsetEAST.newnames.vcf --snps EAST_1000loci/1000loci --recode --recode-INFO-all --out subsetEAST1000

Parameters as interpreted:
	--vcf subsetEAST.newnames.vcf
	--recode-INFO-all
	--out subsetEAST1000
	--recode
	--snps EAST_1000loci/1000loci

After filtering, kept 118 out of 118 Individuals
Outputting VCF file...
After filtering, kept 999 out of a possible 2358 Sites
Run Time = 0.00 seconds

```

Convert the correct vcf into genepop format using pgdspider

```
subsetEAST1000.recode.vcf  ##renamed individuals

##make pop file, but use P1, P2, and admix as the populations

P1_indname	P1
P2_indname 	P2
...

BGC.newnames ##pop file for the .spid file
```

R
Remember to run this from command line R

```
install.packages("devtools") # to install

devtools::install_github("rystanley/genepopedit")

library(genepopedit) # load the library

setwd("/Users/alexjvr/2016RADAnalysis/1.2_Phylo/BGC/EAST_1000loci/")

output_dir <- "/Users/alexjvr/2016RADAnalysis/1.2_Phylo/BGC/EAST_1000loci/"

#specify which populations are going to be included in the analysis and to which class they belong. Note Pops identified in P1 and-or P2 can also be specified as "Admixed" to test BGC output. 
  BGC_groups = data.frame(pops = c("Admix","P1","P2"),groups = c("Admixed","P1","P2"))

#convert Genepop to BGC input files (3). Note in this case the variable path is a path to the directory where the input files will be saved.
  genepop_bgc(genepop="EAST_1000loci.genpop.txt",popdef = BGC_groups, fname="BGC_EAST",path = output_dir)
```

Copy over to the GDC server and start the 6 runs: 

#### RUNS: (2 of each)

Set 1: -I 0; -u 0.2 (as in run 5)
```
/usr/local/bgc-1.03/bgc -a /gdc_home4/alexjvr/CH.ContactZone/bgc/EAST1000_Parental1_BGC.txt -b /gdc_home4/alexjvr/CH.ContactZone/bgc/EAST1000_Parental2_BGC.txt -h /gdc_home4/alexjvr/CH.ContactZone/bgc/EAST1000_Admixed_BGC.txt -x 250000 -n 200000 -p 1 -q 1 -N 1 -t 10 -E 0.0001 -u 0.2 -g 0.1, -z 0.025 -I 0
```

Set 2: -I 0; -u 0.1

```
/usr/local/bgc-1.03/bgc -a /gdc_home4/alexjvr/CH.ContactZone/bgc/EAST1000_Parental1_BGC.txt -b /gdc_home4/alexjvr/CH.ContactZone/bgc/EAST1000_Parental2_BGC.txt -h /gdc_home4/alexjvr/CH.ContactZone/bgc/EAST1000_Admixed_BGC.txt -x 250000 -n 200000 -p 1 -q 1 -N 1 -t 10 -E 0.0001 -u 0.1 -g 0.1, -z 0.025 -I 0

```

Set 3: -I 0; -u 0.05 (closer to Christine and the BGC example values)
```
/usr/local/bgc-1.03/bgc -a /gdc_home4/alexjvr/CH.ContactZone/bgc/EAST1000_Parental1_BGC.txt -b /gdc_home4/alexjvr/CH.ContactZone/bgc/EAST1000_Parental2_BGC.txt -h /gdc_home4/alexjvr/CH.ContactZone/bgc/EAST1000_Admixed_BGC.txt -x 250000 -n 200000 -p 1 -q 1 -N 1 -t 10 -E 0.0001 -u 0.05 -g 0.1, -z 0.025 -I 0

```

```
/usr/local/bgc-1.03/estpost -i mcmcout.hdf5 -p alpha -o a10.9.out -s 0 -c 0.95 -w 0

/usr/local/bgc-1.03/estpost -i mcmcout.hdf5 -p beta -o b10.9.out -s 0 -c 0.95 -w 0

/usr/local/bgc-1.03/estpost -i mcmcout.hdf5 -p LnL -o LnL10.9.out -s 2 -c 0.95 -w 0

/usr/local/bgc-1.03/estpost -i mcmcout.hdf5 -p hi -o hi10.9.out -s 0 -c 0.95 -w 0
```


None of the runs had converged. But it seems like -I 0 works well. 
I'll run all three for longer: from -x 200000 -n 150000 -> -x 250000 -n 200000

--> Only 2 out of 6 runs converged. Not sure why this is. 

I'm setting up a 6 way test: 


|Run|I|u|z|g|Time(hrs)|LnL(converge)|HI|alpha|beta|Data|
|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|
|7.1|0|0.05|0.025|0.05|49|No||||1000loci|
|7.2|0|0.05|0.05|0.05|49|Yes|~0|-30:30|///|1000loci|
|7.3|0|0.1|0.025|0.05|49|No||||1000loci|
|7.4|0|0.1|0.05|0.05|46|Yes|~0|-30:30|///|1000loci|
|7.5|0|0.2|0.025|0.05|49h30|No||||1000loci|
|7.6|0|0.2|0.05|0.05|49h30|Yes|~0.5|-10:10|Yes|1000loci|
|8.1|1|0.05|0.025|0.05|49h30|No||||1000loci|
|8.2|1|0.05|0.05|0.05|48h40|Yes|~0|-30:30|Yes|1000loci|
|8.3|1|0.1|0.025|0.05|47h30|Yes|~0|-30:30|///|1000loci|
|8.4|1|0.1|0.05|0.05|46|Yes|~0|-40:40|///|1000loci|
|8.5|1|0.2|0.025|0.05|49|No||||1000loci|
|8.6|1|0.2|0.05|0.05|49|Yes|~0.5|-5:5|Yes|1000loci|
|9.1|1|0.2|0.05|0.05||||||Full|
|9.2|1|0.2|0.05|0.1||||||Full|
|9.3|1|0.2|0.05|0.3||||||Full|
|9.4|1|0.2|0.1|0.05||||||Full|
|9.5|1|0.2|0.1|0.1||||||Full|
|9.6|1|0.2|0.1|0.3||||||Full|
|9.7|1|0.2|0.3|0.05||||||Full|
|9.8|1|0.2|0.3|0.1||||||Full|
|9.9|1|0.2|0.3|0.3||||||Full|
|10.1|1|0.4|0.05|0.05||||||Full|
|10.2|1|0.4|0.05|0.1||||||Full|
|10.3|1|0.4|0.05|0.3||||||Full|
|10.4|1|0.4|0.1|0.05||||||Full|
|10.5|1|0.4|0.1|0.1||||||Full|
|10.6|1|0.4|0.1|0.3||||||Full|
|10.7|1|0.4|0.3|0.05||||||Full|
|10.8|1|0.4|0.3|0.1||||||Full|
|10.9|1|0.4|0.3|0.3||||||Full|






##### BGC Final input	

I realised that the problem with the Hybrid Index was that the samples must've been misassigned to their populations. This must have been happening with running the genepop_bgc script from genepopedit in R. 

I've run a test using 100 loci after carefully preparing the input and manually running throught he genepop_bgc script. This seems to have corrected the problem. 

I also checked how sample order was changed when converting inputs in pgdspider. When populations are specified, the population order is used (starting with the first one in the file). Otherwise it seems to be random. 

For fastStructure, I think it's better to use the PLINK input as the .bed file with specify the sample order for the .meanQ output. 

Prepare the BGC input: 

1. rename samples using "P1_/P2/Admix_"sample name

Also, specify old_name new_name in this pop.names file to ensure the correct renaming. 
```
bcftools reheader file.vcf -s pop.names -o output.vcf

```

2. Prepare a population file for pgdspider

```
indiv_name Pop
Admix_name Admix
P1_name P1
P2_name P2
```


3. Convert vcf to genepop using pgdspider

4. Add header onto file 

genepop_bgc looks for a Stacks v x header, but this header can really be anything. 

5. Convert to bgc in R using the following script:
```
####Check conversion script for BGC
#############
# Genepop -> Bayesian Genomic Clines (BGC)
#' @title Convert Genepop to Bayesian Genomic Clines (BGC) format.
#' @description Function to convert Genepop to BGC format.
#' @param genepop the genepop data to be manipulated. This can be either a file path
#' or a dataframe read in with tab separation, header=FALSE , quote="", and stringsAsFactors=FALSE.
#' This will the standard genepop format with a the first n+1 rows corresponding the the n loci names,
#' or a single comma deliminated row of loci names followed by the locus data. Populations are
#' separated by "Pop". Each individual ID is linked to the locus data by " ,  " (space,space space) and is read in as
#' as a single row (character).
#' @param popdef is a dataframe or path to a csv.
#' This dataframe contains two columns. Column 1 corresponds to the population names. These names
#' should match the individual IDs (e.g. BON_01 ,  110110 would be 'BON'). The next column
#' has the grouping classification corresponding to each population
#' defining parental 1 ("P1") parental 2 ("P2") and admixed ("Admixed") populations.
#' Note the classifications must be exactly as specified (caps sensitive). If populations are omitted from
#' this dataframe then they will be omitted from the output files.
#' @param fname collective name assigned to each of the output files for BGC.
#' e.g. "Lobster_analysis" would result in
#' "Lobster_analysis_P1.txt","Lobster_analysis_P2.txt", and "Lobster_analysis_Admixed.txt"
#' @param path file path to directory where the BGC files (3) will be saved.
#' @rdname genepop_bgc
#' @import magrittr
#' @import dplyr
#' @importFrom data.table fread
#' @importFrom utils write.table
#' @importFrom utils read.csv
#' @export

#genepop_bgc <- function(genepop,popdef,fname,path){  ##this can be dehashed to run as a script. Also bracket right at the end

setwd("/Users/alexjvr/2016RADAnalysis/1.2_Phylo/input.files/BGCinput/")

genepop <- data.table::fread("genepop.BGC.txt",
                             header = FALSE, sep = "\t",
                             stringsAsFactors = FALSE)


header <- genepop[1,]
if(length(gregexpr(',', header, fixed=F)[[1]])>1){
  lociheader <- strsplit(header,",")
  lociheader <- gsub(" ","",unlist(lociheader))
  #remove the first column of loci names
  genepop <- as.vector(genepop)
  genepop <- genepop[-1,]
  genepop <- c(lociheader,genepop)
  genepop <- as.data.table(genepop,stringsAsFactors = FALSE)
}
header ###this is the first row. i.e. if the locus names are in one row and separated my ","

## Stacks version information
stacks.version <- genepop[1,] #this could be blank or any other source. First row is ignored by genepop


genepop <- genepop[-1,]
colnames(genepop) <- "data"  ##adds colname "data" to the first column
head(genepop)


Pops  <-  which(genepop$data == "Pop" | genepop$data =="pop" | genepop$data == "POP")
Pops ##check that the line numbers make sense. i.e. double the nr of indivs for each pop
npops  <-  1:length(Pops)
npops ##should be 3 if named Admix, P1, P2
  
## separate the data into the column headers and the rest
ColumnData <- genepop$data[1:(Pops[1]-1)]
ColumnData <- gsub("\r","",ColumnData)#remove any hidden carriage returns
summary(ColumnData)   ##length should be equal to nr of loci
snpData <- genepop[Pops[1]:NROW(genepop),]
head(snpData)

#Get a datafile with just the snp data no pops
tempPops <- which(snpData$data=="Pop"| snpData$data =="pop" | snpData$data == "POP") ## Changed because we allowed
tempPops
snpData <- snpData[-tempPops,]
head(snpData)

#separate the snpdata
temp <- as.data.frame(do.call(rbind, strsplit(snpData$data," ")))
summary(temp)

#data format check
if(unique(temp[,2])!="," | !length(which(temp[,3]==""))>1){
  stop("Genepop sampleID delimiter not in proper format. Ensure sampleIDs are separated from loci by ' ,  ' (space comma space space). Function stopped.",call. = FALSE)
}
temp2 <- temp[,4:length(temp)] #split characters by spaces

#Contingency to see if R read in the top line as the "stacks version"
if (length(temp2)!=length(ColumnData)){colnames(temp2) <- c(stacks.version,ColumnData)}
if (length(temp2)==length(ColumnData)){colnames(temp2) <- ColumnData}
if (length(temp2)!=length(ColumnData)){stacks.version="No STACKS version specified"}

#stacks version character
stacks.version <- as.character(stacks.version)

## Get the population names (prior to the _ in the Sample ID)
NamePops <- temp[,1] # Sample names of each
NameExtract <- substr(NamePops,1,regexpr("_",NamePops)-1)  ##each sample name should start with "pop_" for this to work


#convert the snp data into character format to get rid of factor levels
temp2[] <- lapply(temp2, as.character)

#allele coding length
alleleEx <- max(sapply(temp2[,1],FUN=function(x){nchar(as.character(x[!is.na(x)]))})) #presumed allele length
alelleEx ##should be 6 if you used pgdspider for the conversion to genepop


#check to make sure the allele length is a even number
if(!alleleEx %% 2 ==0){stop(paste("The length of each allele is assumed to be equal (e.g. loci - 001001 with 001 for each allele), but a max loci length of", alleleEx, "was detected. Please check data."))}

#get the allele values summary header
firstAllele <-  as.data.frame(sapply(temp2,function(x)as.numeric(as.character(substring(x,1,(alleleEx/2))))))
secondAllele <-  as.data.frame(sapply(temp2,function(x)as.numeric(as.character(substring(x,(alleleEx/2)+1,alleleEx)))))

# switch from combined allele in one row to two allele each in their own row according to a given locus
holdframe <- rbind(firstAllele,secondAllele)#create a dummy data frame
holdframe[!1:nrow(holdframe) %% 2 == 0,] = firstAllele #odd rows
holdframe[1:nrow(holdframe) %% 2 == 0,] = secondAllele #even rows

holdframe[holdframe==0]= -9 # replace missing values with -9

groupvec <- NameExtract
for (i in 1:length(unique(NameExtract))) # replace pop names with numbers
{
  groupvec[which(groupvec==unique(NameExtract)[i])] = i
}

holdframe=cbind(rep(NamePops,each=2),rep(groupvec,each=2),rep(NameExtract,each=2),holdframe)
colnames(holdframe)[1:3]=c("ID","PopID","Pop")

popdef <- data.frame(pops=c("P1", "P2", "Admix"), group=c("P1", "P2", "Admixed"))  ##create popdef. First bracket is pop names. Second bracket corresponds to the BGC group names. Order doesn't seem to matter, and this is needed only at pop level (not indiv)


##if(is.character(popdef)){popdef <- utils::read.csv("BGC_popdef.csv",header=F)} #if popdef is a path then read it in 

#Extract the parental data and admixed data
P1_raw <- holdframe[which(holdframe$Pop %in% popdef[which(popdef[,2]=="P1"),1]),]#Parental 1
P2_raw <- holdframe[which(holdframe$Pop %in% popdef[which(popdef[,2]=="P2"),1]),]#Parental 2
P3_raw <- holdframe[which(holdframe$Pop %in% popdef[which(popdef[,2]=="Admixed"),1]),]#Admixed

summary(P1_raw) ##check popID that only the right pop is represented. SampleID can also be checked
# names of the snps
snpnames <- colnames(temp2)  ##names of loci from column1

#map to be used for missing alleles (if any present across loci)
Allele_Map <- data.frame(SNP=snpnames,
                         Allele1=rep(999,length(snpnames)),
                         Allele2=rep(999,length(snpnames))) # 999 is a dummy placeholder

for(i in 1:length(snpnames)){
  #unique alleles for a given snp (locus)
  alleleVals <- as.data.frame(table(as.character(c(P1_raw[,snpnames[i]],P2_raw[,snpnames[i]],P3_raw[,snpnames[i]]))))
  
  # if there is missing data (-9) delete it as a possibe allele
  if(length(which(alleleVals[,1]==(-9)))>0){
    alleleVals <- alleleVals[-which(alleleVals[,1]==(-9)),]
  }
  
  Allele_Map[i,"Allele1"]=as.character(alleleVals[1,1])
  Allele_Map[i,"Allele2"]=as.character(alleleVals[2,1])
}

#NULL vectors
P1_BGC <- NULL
P2_BGC <- NULL

for(i in snpnames){
  # grab vector of alleles and delete replace missing values (-9) with NA
  P1_alleles <- P1_raw[,i];P1_alleles[which(P1_alleles==-9)]=NA
  P2_alleles <- P2_raw[,i];P2_alleles[which(P2_alleles==-9)]=NA
  
  #If the population only has one allele for a given locus then a zero and the allele have be be added
  if(length(table(P1_alleles))==1|sum(is.na(P1_alleles))==length(P1_alleles)){
    if(length(table(P1_alleles))==1){
      hold <- as.data.frame(table(P1_alleles))
      hold[,1] <- as.character(hold[,1])
      hold <- rbind(hold,c(setdiff(as.numeric(Allele_Map[which(Allele_Map$SNP==i),c("Allele1","Allele2")]),hold[1,1]),0)) #add in the extra value
      hold <- hold[order(hold[,1]),] #sort the right order from a conventional table output
      P1_alleles <- hold[,2]
      rm(hold)} else {P1_alleles <- c(0,0)}
  } else {P1_alleles <- as.character(as.data.frame(table(P1_alleles))[,2])}
  
  if(length(table(P2_alleles))==1 | sum(is.na(P2_alleles))==length(P2_alleles)){
    if(length(table(P2_alleles))==1){
      hold <- as.data.frame(table(P2_alleles))
      hold[,1] <- as.character(hold[,1])
      hold <- rbind(hold,c(setdiff(as.numeric(Allele_Map[which(Allele_Map$SNP==i),c("Allele1","Allele2")]),hold[1,1]),0)) #add in the extra value
      hold <- hold[order(hold[,1]),] #sort the right order from a conventional table output
      P2_alleles <- hold[,2]
      rm(hold)} else{P2_alleles <- c(0,0)}
  } else {P2_alleles <- as.character(as.data.frame(table(P2_alleles))[,2])}
  
  
  #for a given locus get the format for BGC
  P1_temp <- c(paste("locus_",i,sep=""),paste(P1_alleles[1],P1_alleles[2],sep=" "))
  P2_temp <- c(paste("locus_",i,sep=""),paste(P2_alleles[1],P2_alleles[2],sep=" "))
  
  #Combine output sequentially for each locus
  P1_BGC <- c(P1_BGC,P1_temp)
  P2_BGC <- c(P2_BGC,P2_temp)
}

path="/Users/alexjvr/2016RADAnalysis/1.2_Phylo/input.files/BGCinput/"  ##specify path
fname="EASTall.new"  ##specify start of name

##Save output for BGC formatted for the parental populations ------------
if(substring(path,nchar(path))!="/"){path=paste0(path,"/")}

utils::write.table(x = P1_BGC,file=paste0(path,fname,"_Parental1_BGC.txt",sep=""),
                   sep="\t",quote=FALSE,row.names=FALSE,col.names=FALSE)

utils::write.table(x = P2_BGC,file=paste0(path,fname,"_Parental2_BGC.txt",sep=""),
                   sep="\t",quote=FALSE,row.names=FALSE,col.names=FALSE)


#Convert the admixed data to BGC format --------------

###specify majorminor function
majorminor<- function(Vec, allele_length = 6){
  if(sum(is.na(Vec))!=length(Vec)){
    Vec <- as.character(Vec)
    firstAllele <-  as.data.frame(sapply(Vec,function(x)as.character(substring(x,1,(allele_length/2)))),stringsAsFactors = F)
    secondAllele <-  as.data.frame(sapply(Vec,function(x)as.character(substring(x,(allele_length/2)+1,allele_length))),stringsAsFactors = F)
    x=c(firstAllele[,1],secondAllele[,1])
    AlleleMajor <- as.character(names(which(table(x)==max(table(x)))))
    AlleleMinor <- as.character(names(which(table(x)==min(table(x)))))
    if(length(AlleleMajor)>1){AlleleMajor <- AlleleMajor[1];AlleleMinor=AlleleMinor[2]}
    
    Vec[is.na(Vec)]="-9 -9" #missing data
    Vec=gsub(paste0(AlleleMajor,AlleleMajor),"2 0",Vec) #homozygous major
    Vec=gsub(paste0(AlleleMajor,AlleleMinor),"1 1",Vec) #heterozygous
    Vec=gsub(paste0(AlleleMinor,AlleleMajor),"1 1",Vec) #heterozygous
    Vec=gsub(paste0(AlleleMinor,AlleleMinor),"0 2",Vec) #homozygous minor
  } else {Vec=rep("0 0",length(Vec))}
  return(Vec)
}


#subset data for admixed populations
missingfix<- function(x){ #create functions for apply loop
  hold=x
  hold[grep("000",hold)]=NA
  return(hold)}

#Remove Alleles with missing data and replace with NA
temp3 <- apply(temp2,2,missingfix)

#convert to zygosity format (2 0 - homozygous major, 0 2 - homozygous minor, 1 1 - heterozygous, -9 -9 - missing data )
temp4 <- apply(temp3,2,FUN = function(x) {majorminor(x,allele_length=alleleEx)})

MixedStruct <- temp4[which(NameExtract %in% popdef[which(popdef[,2]=="Admixed"),1]),]
MixedPops <- NameExtract[which(NameExtract %in% popdef[which(popdef[,2]=="Admixed"),1])]

#the number of individuals for all populations but the last (Pop tagged to the end)
PopLengths <- table(MixedPops)[-length(table(MixedPops))]

if(length(table(MixedPops))==2){PopPosition = PopLengths+1}

if(length(table(MixedPops))>2){
  PopPosition <- c(PopLengths[1]+1,rep(NA,(length(PopLengths)-1)))
  for (i in 2:length(PopLengths)){
    PopPosition[i] <- PopLengths[i]+PopPosition[i-1]
  }
}

#Insert the population labels
if(length(table(MixedPops))!=1){
  temp5 <- apply(MixedStruct,2,function(x){insert_vals(x,breaks=PopPosition,
                                                       newVal=paste0("pop_",unique(MixedPops)[2:length(unique(MixedPops))]))})} else {
                                                         temp5 <- MixedStruct}

temp5=as.data.frame(temp5,stringsAsFactors = FALSE)

#Add the "locus_" and first "pop_" labels
temp6=as.matrix(rbind(paste0("locus_",colnames(temp5)),
                      rep(paste0("pop_",unique(MixedPops)[1]),length(temp5)),
                      temp5))

#redim as a single vector
MixedData=as.vector(temp6)

##Save output for BGC formatted for the parental and mixed populations ------------
utils::write.table(x = MixedData,file=paste(path,fname,"_Admixed_BGC.txt",sep=""),
                   sep="\t",quote=FALSE,row.names=FALSE,col.names=FALSE)

#} #end of function

```

copy input to gdcsrv1 and run BGC with following command: 

```
/usr/local/bgc-1.03/bgc -a EASTall.new_Parental1_BGC.txt -b EASTall.new_Parental2_BGC.txt -h EASTall.new_Admixed_BGC.txt -x 250000 -n 200000 -p 1 -q 1 -N 1 -t 10 -E 0.0001 -u 0.05 -g 0.1 -z 0.025 -I 0
```

Get outputs from mcmc using 

```
/usr/local/bgc-1.03/estpost -i mcmcout.hdf5 -p alpha -o aEASTall.1.out -s 0 -c 0.95 -w 0

/usr/local/bgc-1.03/estpost -i mcmcout.hdf5 -p beta -o bEASTall.1.out -s 0 -c 0.95 -w 0

/usr/local/bgc-1.03/estpost -i mcmcout.hdf5 -p LnL -o LnL.EASTall.1.out -s 2 -c 0.95 -w 0

/usr/local/bgc-1.03/estpost -i mcmcout.hdf5 -p hi -o hiEASTall.1.out -s 0 -c 0.95 -w 0
```

Copy this over to the mac and look at results in R using scripts as before: 
```


```


2. Combine output from independent runs

3. Test for excess loci

	Def:locus-specific introgression signal significantly deviates from the genome-wide average introgression

	ie. if 2-tailed 95% confidence interval doesn't include 0
	
	a. graph alpha and beta
	
	b. a.out and b.out include confidence interval (lower bound and upper bound). 
	
I need a way to identify these loci. I can't think of how to do it in R. 
At the moment I've identified them in excel. 

Alpha is analgous to geographic cline center, and Beta to the slope

Results: 1049 loci with negative alpha. i.e. excess parent 2 (CHN) ancestry

	536 loci with positive alpha. i.e. excess parent 1 (CHS) ancestry
	
	773 Neutral. 

	262 loci with negative Beta
	
	250 loci with positive Beta
	
These numbers are much higher than what Christine found. 
	
	
```
##This code doesn't work yet


```


4. Test for outlier loci

	Def: if the posterior estimate of αi or βi was not included in the quantile interval 0.025 and 0.975 of a normal distribution with mean zero and standard deviation given by the cline precision parameter τ-α or τ-β, respectively. τ-α and τ-β were defined as τ = (1/sigma2) and estimated from MCMC samples. 
	
	A more detailed discussion of the above-mentioned parameters can be found in Gompert & Buerkle (2012).


```
##Still can't get the colours to work on this graph

##Identify outliers
##2.5% tails

setwd("/Users/alexjvr/2016RADAnalysis/1.2_Phylo/BGC/EASTrun4/")

a1 <- read.csv("a.4b.out", header = F)

colnames(a1) <- c("mean", "median", "CI_LB", "CI_UB")  ##add column names
head(a1)

a1$x <- 1:nrow(a1) ##add column x
head(a1)


library("ggplot2")
library("reshape")
#Calculate the variance

alpha.postDist <- a1$mean

tau.alpha <- (sqrt(var(alpha.postDist)))
tau.alpha  ##SD used for the calculation of outliers

alpha.pos <- tau.alpha*1.96
alpha.pos

alpha.neg <- 0-(tau.alpha*1.96)
alpha.neg



CIlimits <- aes (ymax=a1$CI_UB, ymin=a1$CI_LB)

library("ggplot2")
library("reshape")

ggplot(a1, aes(x=a1$x, y=a1$mean, color=a1$mean)) +
  geom_point(aes(color = cut(a1$mean, c(-Inf, -26.87914, 26.87924, Inf)))) +
  scale_color_manual(name = "mean", values = c("(-Inf,-26.87914]" = "green",
                                               "(-26.87914,26.87914]" = "black",
                                               "(26.87914, Inf]" = "purple")) +
  xlab("x") +
  ylab("alpha + CI") +
  ggtitle("EASTsubset alpha BGC run4 + CI") +
  theme(legend.position="none")

#scale_color_manual(colours = c("green", "black", "purple"), values=c(Inf,26.87914,-26.87914,-Inf)) +
#geom_pointrange(CIlimits, width=0.2) +

```

I used excel to identify loci that didn't cross 0. These were either positive or negative for alpha and Beta. 

I then counted these up. 

Remember, Parent 1 = CHN, and Parent 2 = CHS


Excess ancestry from CHS (+'ve alpha) = 536 loci (22.7%)

Excess ancestry from CHN (-'ve alpha) = 1049 loci (44.5%)

Increased rate of introgression at locus (+ Beta) = 250 loci (10.6%)

Reduced rate of introgression at locus (- Beta) = 262 loci (11.1%)



## Geographic Cline

1. Are the mtDNA and RAD clines the same? 

2. Comparison of neutral RAD cline to some loci that are under selection. 

3. 

See figure 6 in Grossen et al. 2016

1. Hzar geographic cline based on hybrid index as calculated by Structure q

2. 


INPUT FILE: 

|loc| Dist| loc1 AlleleA| Loc1 AlleleB| nsamples (nr of individuals) | mtDNA Alelle1 | mtDNA Allele2 | nsamples | Hybrid Index.mu |Hybrid Index_sigma|
|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|
|||||||||||


### Loc

I need to collapse the data down to populations rather than individuals, since they'll have the same distance measures. 

I'm not sure how much of a difference this makes, but I will first run the population level analysis and then perhaps a subset of individuals to see if the result is the same. 

My main concern is that I don't have "pure" parental populations. i.e. if I use the average q-value for a population, none would be pure. So this might have to be run on the individual level, or by removing the hybrids from these populations. 


### Distance

Hzar needs a geographic distance for each population from the cline center or from some point.  I will use the distance from the norther-most population as the 0-point. 

47.29642	8.8123   birk

Calculate great circle distances in R

Make sure birk is the first population in the input file. 

```
#Great circle distance between samples

##Geographic distance between all EAST contact zone populations
##using package Rdist

library(fields)
#Import .csv with coordinates

setwd("2016RADAnalysis/1.2_Phylo/HZAR/")

EAST.dist <- read.csv("EAST.2358.118_kmdist.csv", header=T)
head(EAST.dist)



#rdist.earth (in fields package) wants only long & lat
EAST_lon.lat <- cbind(EAST.dist$long, EAST.dist$lat)
EAST_lon.lat

#calculate great circle distances
distance.matrix.CHRAD <- rdist.earth(EAST_lon.lat)
summary(distance.matrix.CHRAD)
dim(distance.matrix.CHRAD)

#and use only the lower half of the matrix
upper.tri(distance.matrix.CHRAD)
distance.matrix.CHRAD[lower.tri(distance.matrix.CHRAD)]<-NA
distance.matrix.CHRAD

#change from matrix to dataframe
bli <- as.data.frame(distance.matrix.CHRAD)
head(bli)
colnames(bli) <- EAST.dist$pop
rownames(bli) <- EAST.dist$pop

bli[lower.tri(bli,diag=TRUE)]=NA  #Prepare to drop duplicates and meaningless information
bli=as.data.frame(as.table(as.matrix(bli)))  #Turn into a 3-column table
bli
bli=na.omit(bli)  #Get rid of the junk we flagged above
bli
colnames(bli)<-c("site1", "site2", "dist(km)")
head(bli)

bli2 <- bli[sort("site2"),]

head(bli2)


##write to csv
write.csv(bli, file="distance.EAST.csv",row.names=F)

```

Delete all non-birk comparisons. 



### Hybrid Index

Averaged all Q values per population from TESS3 results

File: EAST.2358.118_loci.xlsx


### Allele frequencies: RAD data

Calculate per locus per population allele frequencies using Plink. (First I converted the vcf subsetEAST.Final.2.vcf file to PLINK to make sure I have the latest version of the data file). 

```
vcftools --vcf subsetEAST.Final.2.vcf --plink --out subsetEAST.Final2

VCFtools - v0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf subsetEAST.Final.2.vcf
	--out subsetEAST.Final2
	--plink

After filtering, kept 118 out of 118 Individuals
Writing PLINK PED and MAP files ... 
Done.
After filtering, kept 2358 out of a possible 2358 Sites
```


I need to specify the hierarchy of the data (i.e. the subgroups). Since I haven't specified populations, the names in the .ped file are just duplicates of the sample file: sample_1 sample_1

So for the hierarchy file, I specify: 
(make sure all the names are correct. Otherwise the PLINK names can be found in the .nosex file)

```
nano PlinkCluster.txt

alpl_07	alpl_07	alpl
alpl_08	alpl_08	alpl
apla_01	apla_01	apla
apla_02	apla_02	apla
apla_03	apla_03	apla
apla_04	apla_04	apla
apla_05	apla_05	apla
...
```


And then calculate allele frequencies using PLINK 

```
plink --file subsetEAST.Final2 --within PlinkCluster.txt --freq

+++ PLINK 1.9 is now available! See above website for details +++ 

Writing this text to log file [ plink.log ]
Analysis started: Wed Sep  7 12:11:37 2016

Options in effect:
	--file subsetEAST.Final2
	--within PlinkCluster.txt
	--freq

2358 (of 2358) markers to be included from [ subsetEAST.Final2.map ]
Warning, found 118 individuals with ambiguous sex codes
These individuals will be set to missing ( or use --allow-no-sex )
Writing list of these individuals to [ plink.nosex ]
118 individuals read from [ subsetEAST.Final2.ped ] 
0 individuals with nonmissing phenotypes
Assuming a disease phenotype (1=unaff, 2=aff, 0=miss)
Missing phenotype value is also -9
0 cases, 0 controls and 118 missing
0 males, 0 females, and 118 of unspecified sex
Reading clusters from [ PlinkCluster.txt ]
118 of 118 individuals assigned to 28 cluster(s)
Before frequency and genotyping pruning, there are 2358 SNPs
118 founders and 0 non-founders found
Writing stratified allele frequencies (founders-only) to [ plink.frq.strat ] 

Analysis finished: Wed Sep  7 12:11:38 2016
```

This file can now be uploaded in R and manipulated. 

SNPs are in the same order as in the BGC analysis and could be renamed. (1-2358)

But this is not so easy, as there are 28 copies of each SNP name. 

1. Open the .frq in excel and delimit with tab, space, and ":". 

2. Delete ":nr" from locus name and save the plink file as "plink.frq.strat.2.txt"

3. Create 3 excel sheets in R with: Major allele freq, Minor allele freq, and n.samples per population per locus. (See R code below)

4. Open excel sheets and rename loci according to the BGC names: "BGC_HZAR_Allelenames.csv"

5. Copy major and minor allele frequency into one file and sort. Final input "InputEAST.txt"


R for point 3
```
##HZAR geographic cline analysis

#What does the input file look like? 

library(hzar)

setwd("~/2016RADAnalysis/1.2_Phylo/HZAR/")
freq <- read.table("plink.frq.strat.2.txt", header = T, stringsAsFactors = F)
head(freq)
str(freq)

#freq <- as.data.frame(freq, stringsAsFactors = F)
#str(freq)


freq$CHR = NULL##get rid of some of the columns
freq$A1 = NULL
freq$A2 = NULL
freq$MAC = NULL
##freq$MAF = NULL ##for the test

##Step 2
#freq$n.samples <- with(freq, NCHROBS/2) #Calculate the number of individuals typed for each locus per pop
#head(freq)
freq$NCHROBS = NULL #delete this column

#colnames(freq)[colnames(freq)=="MAF"] <- "B" ##rename the MAF to B. (This specifies a particular column)


#freq <- freq[,c(1,2,4,3)]#change the order of the columns
#head(freq)


library("ggplot2")
library("reshape2")

freq2 <- melt(freq, id.vars = c("CLST", "SNP"), variable_name = c("MAF"))
str(freq2)
head(freq2)


freq3 <- dcast(freq2, formula= CLST ~ SNP)
head(freq3)
write.csv(freq3, file="freq3.csv")


##Now do the sampe with n.samples
##Step 2: nsamples

freq <- read.table("plink.frq.strat.2.txt", header = T, stringsAsFactors = F)
head(freq)

freq$n.samples <- with(freq, NCHROBS/2) #Calculate the number of individuals typed for each locus per pop
head(freq)
freq$NCHROBS = NULL #delete this column

freq$CHR = NULL##get rid of some of the columns
freq$A1 = NULL
freq$A2 = NULL
freq$MAC = NULL
freq$MAF = NULL

head(freq)

library("ggplot2")
library("reshape2")


freq2 <- melt(freq, id.vars = c("CLST", "SNP"), variable_name = c("n.samples"))
str(freq2)
head(freq2)


freq3 <- dcast(freq2, formula= CLST ~ SNP)
head(freq3)
write.csv(freq3, file="nsamples.csv")

##Now do the sampe with n.samples
##Step 3: Major Allele freq

freq <- read.table("plink.frq.strat.2.txt", header = T, stringsAsFactors = F)
head(freq)

freq$A <- with(freq, 1-MAF) ##add column with major allele freq.
head(freq) 

freq$NCHROBS = NULL #delete this column
freq$CHR = NULL##get rid of some of the columns
freq$A1 = NULL
freq$A2 = NULL
freq$MAC = NULL
freq$MAF = NULL

head(freq)

library("ggplot2")
library("reshape2")


freq2 <- melt(freq, id.vars = c("CLST", "SNP"), variable_name = c("A"))
str(freq2)
head(freq2)


freq3 <- dcast(freq2, formula= CLST ~ SNP)
head(freq3)
write.csv(freq3, file="MajorAllele.csv")
```


And run HZAR
```
##HZAR example to run

setwd("~/2016RADAnalysis/1.2_Phylo/HZAR/")


library(hzar)
CZinput <- read.csv("EAST.HZARinputv2.csv", header = T)

write.table(CZinput, # The data we just loaded
            file="EAST.input2.txt", # The file to overwrite
            col.names=TRUE, # The columns are named
            row.names=FALSE, # The rows are not named
            sep="\t", # The file will be tab-delimited
            quote=TRUE) # Use quotes as needed.

## As we no longer need the in-memory copy, drop the local reference
CZ <- NULL

##BOILERPLATE LOADER CODE FOR MOLECULAR DATA
## Assumes:
##  'loci' are the loci you wish to load (eg X66, X95, X15)
##  'EAST' is a data table with siteID row names (eg A, P7, LD, etc)
##    and appropriate columns (for the 'loci' example above: 
##      distance, X66.A, X95.A, X15.A, X66.nSamples, X95.nSamples, X15.nSamples)

## Load example Molecular data from the data table.
EAST <- read.table("EAST.input2.txt",header=TRUE)

loci <- read.csv("EASTloci.csv", header=F)$V1  ##read in a list of the loci names 
loci <- as.character(loci)
loci

EASTobsData <-
  sapply(loci,
         function(snpIter) hzar.doMolecularData1DPops(
           EAST$distance,
           EAST[[paste(snpIter,"A",sep=".")]],
           EAST[[paste(snpIter,"nsamples",sep=".")]],
           rownames(EAST)),
         simplify=FALSE)
summary(EASTobsData)
```



```
##BOILERPLATE FOR COMPILING MODELS FOR MOLECULAR DATA
##http://elizabethderryberry.tulane.edu/derryberrylab/Software/Entries/2014/10/1_Boilerplate_for_compiling_models_for_molecular_data.html
##This creates an object with 15 models specified to be fit to the molecular data
##started at 14:30 (14 Sept) - 19:00 (15 Sept) (3 CPUs on fgczsrv)


## Use parallel to speed code up: 
library(parallel)

## Determine range of observed data 
##   (assumes site distances in 'snp.freq$distance'
obs.range <- extendrange(EAST$distance)


## This code assumes that:
##  'loci' are the loci you wish to load (eg X66, X95, X15)
##  'obsData' is a named list of hzar.obsData objects, 
##     such as the result of the boilerplate loader code

## Assume cache of result in "cache.fq.models.dat.gz"
if(file.exists("cache.fq.models.dat.gz")){
  load("cache.fq.models.dat.gz") }else{
    fq.models <- local({
      mkFQModel <- function(locusID,scaling,tails){
        res <-
          hzar.model.addBoxReq(hzar.makeCline1DFreq(
            data=EASTobsData[[locusID]],
            scaling=scaling,tails=tails),
            low=obs.range[[1]],high=obs.range[[2]])
        hzar.first.fitRequest.old.ML(res,EASTobsData[[locusID]],verbose=FALSE)
      }
      allModels <- expand.grid(s=c("none","fixed","free"),
                               t=c("none","left","right","mirror","both"))
      mkFQModelA <- function(s,t){
        res <- mclapply(loci,mkFQModel,scaling=s,tails=t,mc.cores=3)
        
        ##res <- lapply(res, hzar.first.fitRequest.old.ML)
        names(res) <- paste(loci,s,t,sep=".")
        res
      }
      res <- list()
      for(iter in 1:nrow(allModels))
        res <- c(res,mkFQModelA(allModels$s[[iter]],allModels$t[[iter]]))
      print(    res.names <- names(res))
      res <- hzar.multiFitRequest(res)
      res.names -> names(res)
      res
    })
    ## Save cache of result in "cache.fq.models.dat.gz"
    save(fq.models,file="cache.fq.models.dat.gz") 
  }

EAST.cache.fq.models.dat.gz <- cache.fq.models.dat.gz ##if it needs renaming
```

Helper codes that need to be run: 
```
library(hzar)
library(subplex)

temp.doMLE <- function(fitR){
    mP <- fitR$modelParam
    res <- subplex(mP$init,
                   function(theta) -fitR$llFunc(theta),
                   control=list(parscale=sapply(names(mP$init),
                                    function(x) (mP$upper[[x]]-mP$lower[[x]])/50)))
    if(attr(fitR, "fit.success"))
        fitR$mcmcRaw <- rbind(fitR$mcmcRaw ,res$par)
    else{
        fitR$mcmcRaw <- res$par
        fitR$modelParam$init <- as.list(res$par)
    }
    fitR
}


temp.getMLE <- function(fitR){
    mP <- fitR$modelParam
    res <- subplex(mP$init,
                   function(theta) -fitR$llFunc(theta),
                   control=list(parscale=sapply(names(mP$init),
                                    function(x) (mP$upper[[x]]-mP$lower[[x]])/50)))
    hzar.gen.cline(res$par, fitR)
}
```


```
##RUNNING MODELS & MODEL SELECTION
###Boilerplate code to run models, do model selection, and then analyze the selected models (using the subplex helper snippet). ##Includes caching.

## This code assumes:
##  'obsData' is a named list of hzar.obsData objects, 
##     such as the result of the boilerplate loader code
##  'fq.models' is named list of hzar.fitRequest objects,
##     such as the result of the boilerplate molecular model compile code
library(doMC)
registerDoMC(12)


if(file.exists("EAST.cache.fq.init.run.dat.gz")){
  load("EAST.cache.fq.init.run.dat.gz")
}else{
  hzar.doFit.multi(fq.models,doPar=TRUE)->fq.init.run;
  save(fq.init.run,file="EAST.cache.fq.init.run.dat.gz")
}
fq.sel.dG <- list()   ###Model fit up to here ran for ~10days on 12 CPUs on gdcsrv2


for(iter in 1:length(EASTobsData)) {
  
  fq.tmp <- local({
    load("EAST.cache.fq.init.run.dat.gz")
    foreach(run=fq.init.run) %:%
      when(hzar.sameObsData(run,EASTobsData[[iter]])) %dopar% hzar.fit2DataGroup(temp.doMLE(run))
  })
  fq.tmp <- hzar.copyModelLabels(fq.models,
                                 hzar.make.obsDataGroup( fq.tmp ));
  
  
  print(fq.aic <- hzar.AICc.hzar.obsDataGroup(fq.tmp,show.count=TRUE));
  fq.sel.dG <- c( fq.sel.dG,fq.tmp$data.groups[ which.min(fq.aic$AICc)]);
  print(names(fq.sel.dG))
  rm(fq.tmp)
  print(gc())
}    ##This ran on gdcsrv2 (12 CPU, although most of the time only 1 was used) for 2 weeks. 

if(file.exists("EAST.cache.fq.chains.dat.gz")){
  load("EAST.cache.fq.chains.dat.gz")
}else{
  names(fq.models) -> names(fq.init.run)
  fq.sel.run <- fq.init.run[names(fq.sel.dG)]
  fq.chains.init <- foreach(fq.run=fq.sel.run) %dopar% {
    hzar.next.fitRequest(fq.run) }
  fq.chains.init <- lapply(fq.chains.init,function(x) {
    x$modelParam$tune <- sapply(x$modelParam$tune,
                                function(y) 0.8*y, simplify=FALSE);
    x })
  fq.chains <-
    hzar.doChain.multi(doPar=TRUE,
                       hzar.multiFitRequest( fq.chains.init,
                                             each=3,
                                             baseSeed=NULL,
                                             baseChannel=60,adjChannel=10))
  save(fq.chains,file="EAST.cache.fq.chains.dat.gz")
}   ###started 13 Oct at 16:00

```







HZAR: A test using just one locus
```
##import final input file

setwd("2016RADAnalysis/1.2_Phylo/HZAR/")

hzar1 <- read.table("InputEAST.txt", header = T)
head(hzar1)

HZAR <- function(file, col){

EAST.i <- hzar.doMolecularData1DPops(hzar1$Dist,
                                            col,
                                            hzar1$nsamples);
hzar.plot.obsData(EAST.Allele01);

EAST.A1model <- hzar.makeCline1DFreq(EAST.Allele01, scaling="fixed",tails="none");
EAST.A1Amodel <-
  hzar.model.addBoxReq(EAST.A1model,-30,600);
EAST.A1modelFitR <-
  hzar.first.fitRequest.old.ML(model=EAST.A1model ,
                               EAST.Allele01,
                               verbose=FALSE);
EAST.A1modelFitR$mcmcParam$chainLength <- 2e3;
EAST.A1modelFitR$mcmcParam$burnin <- 5e2;
EAST.A1modelFit <- hzar.doFit(EAST.A1modelFitR)
plot(hzar.mcmc.bindLL(EAST.A1modelFit))
EAST.A1modelData <-
  hzar.dataGroup.add(EAST.A1modelFit);
## Not run:
EAST.A1modelData <-
  hzar.dataGroup.add(
    EAST.A1modelData,
    hzar.chain.doSeq(hzar.next.fitRequest(EAST.A1modelFit)));
hzar.plot.cline(EAST.A1modelData);
hzar.plot.fzCline(EAST.A1modelData);

## End(Not run)
print(hzar.getLLCutParam(EAST.A1modelData,c("center","width")));
EAST.A1modelNull <- hzar.dataGroup.null(EAST.Allele01);
EAST.A1AdGs <- list(clineModel = EAST.A1modelData,
                   nullModel = EAST.A1modelNull);
EAST.A1oDG <- hzar.make.obsDataGroup(EAST.A1AdGs);
EAST.A1oDG <- hzar.copyModelLabels(EAST.A1AdGs,EAST.A1oDG);
hzar.plot.cline(EAST.A1oDG);
print(hzar.AICc.hzar.obsDataGroup(EAST.A1oDG));
}

for (i in 1:ncol(hzar1)){
HZAR(file,col=i)
}



```

## Loci under selection

To see if there are loci likely associated with temperature or elevation, I used 2x environmental association analyses, and 2 x outlier analyses. 

Env parameters: temp/degree days & elevation


### EEA

Environmental association analyses. 

1. lfmm

2. BayEnv2

#### BayEnv2

https://bitbucket.org/tguenther/bayenv2_public/src/8e4039f64d61?at=default

1. Create input file for 500SNPs (to generate the co-variance matrix)

2. Input file for the full association anaylsis using all SNPs

3. ENVIRONFILE -> environmental variables per line. Pops = columns. Standardised: (x-mean)/SD

`**as an aside, this is a useful post about melt() in R: https://www.r-statistics.com/tag/transpose/`

1. 500SNPs
```
##list of SNPs from genepop file as before (subsetEAST.genepop.txt). 

###Randomly select 500 SNPs

nano 500Snps

vcftools --vcf subsetEAST.Final.2.vcf --snps 500Snps --recode --recode-INFO-all --out subsetEAST500

VCFtools - v0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf subsetEAST.Final.2.vcf
	--recode-INFO-all
	--out subsetEAST500
	--recode
	--snps 500Snps

After filtering, kept 118 out of 118 Individuals
Outputting VCF file...
After filtering, kept 501 out of a possible 2358 Sites
Run Time = 0.00 seconds

##Convert using pgdspider as below
```

#### Estimate co-variance matrix

Bayenv2 needs to be run from the command line from its folder: /Users/alexjvr/Applications/bayenv2/compiled_on_a_mac

Estimate the matrix 
```
./bayenv2 -i /Users/alexjvr/2016RADAnalysis/1.2_Phylo/BayEnv2/EAST.500snps_BayEnv.txt -p 28 -k 100000 -r 63479 > matrix.out
```
run on mac. Started 15 Sept 19:50 - ~2 hours (didn't run very long)


2. Input full dataset
```
bcftools query -l subsetEAST.Final.2.vcf > names.txt

##create popnames file (popnames.All)
##Convert in pgdspider. Yes to all extra files. 
```

3. ENVIRONFILE - I will first use only days above 6deg as the ENV parameter

```
setwd("/Users/alexjvr/2016RADAnalysis/1.2_Phylo/BayEnv2/")
file <- NULL
file <- read.csv("EnvVariables.BayEnvprep.csv", header=T)

df <- NULL
df <- data.frame(pop=file$pop, temp=file$days.above.6)

summary(df)
file <- NULL ##drop file from memory

file <- data.frame(pop=df$pop, temp=df$temp) ##create dataframe with only the columns of interest
file
m <- mean(file$temp, na.rm = F) #calculate the mean
s <- sd(file$temp, na.rm = F) #calculate standard deviation
file$norm <- ((file$temp-m)/s) #calculate and add column of normalised data

file$temp<-NULL #drop extra column

write.table(file, "ENVIRONFILE.prep.csv", sep="\t")

##Open in excel and transpose the columns to rows
##I need to figure out how to do this in R for when there are more variables. 
```

#### Env-Association

This can be run on the server. Copy the folder with the executable onto the server: gdcsrv:/alexjvr/CH.ContactZone/bayenv2

For the full dataset, multiple SNPSfiles should be created - i.e one SNP per file. 

A script is provided to loop over all these files for the associations: 

first split the files. The easiest is to split this on the server (split -d not available for mac). And copy all the files back to the mac. 

```
split -d -a 10 -l 2 EAST.all_BayEnv.txt snp_batch
```

for loop for the environmental association
```
for f in $(ls snp_batch*); do ./bayenv2 -i $f -e EAST.poporder.env -m EASTmatrix.out -k 100000 -r $RANDOM -p 28 -n 1 -t -c; done
```



### Outlier Analysis

#####Environmental variables: 

I wanted to look at elevation and temperature. I have data from Josh on the number of days >6deg (i.e. growth days) for each site. 

Elevation and deg days are highly correlated, though, so I'm using elevation as a proxy for environmental differences. 

![Elev.Temp](https://cloud.githubusercontent.com/assets/12142475/18553348/64e93f72-7b60-11e6-8d6b-974f76dfda26.png)


```
setwd("/Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/")

elev.vs.temp <- read.csv("EnvVariables.prep.csv", header=T)

file <- data.frame(x=elev.vs.temp$days.above.6, y=elev.vs.temp$elev)

library(ggplot2)


##Function to calculate lm equation and r2

lm_eqn <- function(df){
  m <- lm(y ~ x, df);
  eq <- substitute(italic(y) == a + b %.% italic(x)*","~~italic(r)^2~"="~r2, 
                   list(a = format(coef(m)[1], digits = 2), 
                        b = format(coef(m)[2], digits = 2), 
                        r2 = format(summary(m)$r.squared, digits = 3)))
  as.character(as.expression(eq));                 
}


##plot 

ET <- ggplot(elev.vs.temp, aes(x = elev.vs.temp$days.above.6, y=elev.vs.temp$elev)) +
  xlab("Days above"*6~degree*C) +
  ylab("Elevation")+
  stat_smooth(method=lm) + geom_point() + 
  geom_text(size=4, x=200, y=2500, label = lm_eqn(file), parse = TRUE)
ET

```



##### Conclusion: 

- It was difficult to get rid of the primary pop structure signal from the CHN-CHS division. 

- 3 outlier loci identified for high vs low in a dataset which included only individuals with 0.25`<q<0.75` (i.e targeting the hybrid zone). 

- pizo excluded as an outlier population from PCA. 


#### 1. PCAdapt

http://membres-timc.imag.fr/Michael.Blum/PCAdapt.html

Data: 

I have data about elevation and degree days above 6deg C (i.e. growing days). 

This is completely correlated. And it falls into roughly 3 classes. 

So I will use elevation as my env variable, and split the data into 3 classes: 

High: 1900-2600m

![High.1](https://cloud.githubusercontent.com/assets/12142475/18545673/6dd58c74-7b3a-11e6-94aa-69e87f793bed.png)

![High.2](https://cloud.githubusercontent.com/assets/12142475/18545819/189e2918-7b3b-11e6-9f67-c356c85562de.png)

Mid: 1000-1700m

![Mid](https://cloud.githubusercontent.com/assets/12142475/18545670/6dd03d1e-7b3a-11e6-900a-082745542dcf.png)


Low: 400-600m

![Low](https://cloud.githubusercontent.com/assets/12142475/18545672/6dd3751a-7b3a-11e6-9ad8-84e28cf01eb0.png)


Dataset HighLow

```
vcftools --vcf subsetEAST.Final.2.vcf --keep pcadapt/HighLow.names --recode --recode-INFO-all --out EAST.HighLow
 
VCFtools - v0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf subsetEAST.Final.2.vcf
	--keep pcadapt/HighLow.names
	--recode-INFO-all
	--out EAST.HighLow
	--recode

Keeping individuals in 'keep' list
After filtering, kept 95 out of 118 Individuals
Outputting VCF file...
After filtering, kept 2358 out of a possible 2358 Sites
Run Time = 1.00 seconds

##for the popfile: 

bcftools query -l EAST.HighLow.recode.vcf > High.Low.pop

##open in excel and remove all individual numbers
```

Run PCAdapt (R command line)
```
library(pcadapt)

path_to_High.Low <- "/Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/EAST.HighLow.recode.vcf"

High.Low <- read.pcadapt(path_to_High.Low, type="vcf")

Summary:

        - input file      /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/EAST.HighLow.recode.vcf
        - output file     /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/EAST.HighLow.recode.pcadapt

	- number of individuals detected:	95
	- number of loci detected:		2358

For SNP info, please check /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/EAST.HighLow.recode.vcfsnp.

0 line(s) have been removed because these are not SNPs.
Please, check /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/EAST.HighLow.recode.removed file, for more information.

File has been sucessfully converted.


###Choose nr of principal components (I know I want 2, but I will run this just to check)

x <- pcadapt(High.Low,K=20,transpose=F)

plot(x,option="screeplot")  ##PC for pop structure = on the steep curve

##PC plot per population (here HighLow)


```
![K20_HighLow](https://cloud.githubusercontent.com/assets/12142475/18546727/ca5572b6-7b3f-11e6-8970-b614f48e70df.png)

![PC_HighLow](https://cloud.githubusercontent.com/assets/12142475/18549296/f50d2752-7b4d-11e6-9924-6835cdc43568.png)


Dataset: High-Mid
```
--vcf subsetEAST.Final.2.vcf --keep pcadapt/HighMid.names --recode --recode-INFO-all --out EAST.HighMid
 
VCFtools - v0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf subsetEAST.Final.2.vcf
	--keep pcadapt/HighMid.names
	--recode-INFO-all
	--out EAST.HighMid
	--recode

Keeping individuals in 'keep' list
After filtering, kept 83 out of 118 Individuals
Outputting VCF file...
After filtering, kept 2358 out of a possible 2358 Sites
Run Time = 0.00 seconds

##for the popfile: 

bcftools query -l EAST.HighMid.recode.vcf > High.Mid.pop

##open in excel and remove all individual numbers

```

PCadapt in R

```
path_to_High.Mid <- "/Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/EAST.HighMid.recode.vcf"
> High.Mid <- read.pcadapt(path_to_High.Mid, type="vcf")
Summary:

        - input file      /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/EAST.HighMid.recode.vcf
        - output file     /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/EAST.HighMid.recode.pcadapt

	- number of individuals detected:	83
	- number of loci detected:		2358

For SNP info, please check /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/EAST.HighMid.recode.vcfsnp.

0 line(s) have been removed because these are not SNPs.
Please, check /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/EAST.HighMid.recode.removed file, for more information.

File has been sucessfully converted.
> x <- pcadapt(High.Mid,K=20,transpose=F)
Reading file /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/EAST.HighMid.recode.pcadapt...
Number of SNPs: 2358
Number of individuals: 83
Number of SNPs with minor allele frequency lower than 0.05 ignored: 875
13457 out of 195714 missing data ignored.
> x <- pcadapt(High.Mid,K=20,transpose=F)
Reading file /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/EAST.HighMid.recode.pcadapt...
Number of SNPs: 2358
Number of individuals: 83
Number of SNPs with minor allele frequency lower than 0.05 ignored: 875
13457 out of 195714 missing data ignored.
> poplist <- read.table("HighMid.pop")
> plot(x,option="screeplot")
> plot(x,option="scores",pop=poplist)
Warning message:
In if (pop[i] != idx) { :
  the condition has length > 1 and only the first element will be used
```
  
![K20_HighMid](https://cloud.githubusercontent.com/assets/12142475/18549310/083281ba-7b4e-11e6-9333-ffcbec7b02d4.png)

![PC_HighMid](https://cloud.githubusercontent.com/assets/12142475/18549314/0db1a896-7b4e-11e6-94c4-2aaa2c1f929b.png)

  




Dataset: Low-Mid
```
vcftools --vcf subsetEAST.Final.2.vcf --keep pcadapt/LowMid.names --recode --recode-INFO-all --out EAST.LowMid

VCFtools - v0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf subsetEAST.Final.2.vcf
	--keep pcadapt/LowMid.names
	--recode-INFO-all
	--out EAST.LowMid
	--recode

Keeping individuals in 'keep' list
After filtering, kept 58 out of 118 Individuals
Outputting VCF file...
After filtering, kept 2358 out of a possible 2358 Sites
Run Time = 0.00 seconds

##for the popfile: 

bcftools query -l EAST.LowMid.recode.vcf > Low.Mid.pop

##open in excel and remove all individual numbers


```

pcadapt in R

```
> path_to_Low.Mid <- "/Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/EAST.LowMid.recode.vcf"
> Low.Mid <- read.pcadapt(path_to_Low.Mid, type="vcf")
Summary:

        - input file      /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/EAST.LowMid.recode.vcf
        - output file     /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/EAST.LowMid.recode.pcadapt

	- number of individuals detected:	58
	- number of loci detected:		2358

For SNP info, please check /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/EAST.LowMid.recode.vcfsnp.

0 line(s) have been removed because these are not SNPs.
Please, check /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/EAST.LowMid.recode.removed file, for more information.

File has been sucessfully converted.
> x <- pcadapt(Low.Mid,K=20,transpose=F)
Reading file /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/EAST.LowMid.recode.pcadapt...
Number of SNPs: 2358
Number of individuals: 58
Number of SNPs with minor allele frequency lower than 0.05 ignored: 908
10594 out of 136764 missing data ignored.
> plot(x,option="screeplot")
> poplist <- read.table("LowMid.pop")
> plot(x,option="scores",pop=poplist)
Warning message:
In if (pop[i] != idx) { :
  the condition has length > 1 and only the first element will be used

```

![K20_LowMid](https://cloud.githubusercontent.com/assets/12142475/18549319/12753974-7b4e-11e6-9dcf-1a3415b20729.png)

![PC_LowMid](https://cloud.githubusercontent.com/assets/12142475/18549323/16ebce5a-7b4e-11e6-8c60-74fc0245f123.png)

  

So it doesn't make sense to use these outlier analyses, because most of the population structure is between CHN and CHS rather than across elevation. 


But what if I use only the admixed individuals? 

- filter the vcf dataset to include only individuals with Q 0.25 - 0.75

- and subset by elevation. 

Low-Mid
``` 
vcftools --vcf subsetEAST.Final.2.vcf --keep pcadapt/LowMid.names --recode --recode-INFO-all --out LowMid_EAST

VCFtools - v0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf subsetEAST.Final.2.vcf
	--keep pcadapt/LowMid.names
	--recode-INFO-all
	--out LowMid_EAST
	--recode

Keeping individuals in 'keep' list
After filtering, kept 38 out of 118 Individuals
Outputting VCF file...
After filtering, kept 2358 out of a possible 2358 Sites
Run Time = 0.00 seconds
```

```
> path_to_Low.Mid <- "/Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/LowMid_EAST.recode.vcf"
> Low.Mid <- read.pcadapt(path_to_Low.Mid, type="vcf")
Summary:

        - input file      /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/LowMid_EAST.recode.vcf
        - output file     /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/LowMid_EAST.recode.pcadapt

	- number of individuals detected:	38
	- number of loci detected:		2358

For SNP info, please check /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/LowMid_EAST.recode.vcfsnp.

0 line(s) have been removed because these are not SNPs.
Please, check /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/LowMid_EAST.recode.removed file, for more information.

File has been sucessfully converted.
> x <- pcadapt(Low.Mid,K=20,transpose=F)
Reading file /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/LowMid_EAST.recode.pcadapt...
Number of SNPs: 2358
Number of individuals: 38
Number of SNPs with minor allele frequency lower than 0.05 ignored: 914
7510 out of 89604 missing data ignored.
> plot(x,option="screeplot")
> poplist <- read.table("")
LowHigh.names  LowMid.names   MidHigh.names  
> poplist <- read.table("/Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/lowmid.pop")
> plot(x,option="scores",pop=poplist)
Warning message:
In if (pop[i] != idx) { :
  the condition has length > 1 and only the first element will be used
```

![Admix_LM](https://cloud.githubusercontent.com/assets/12142475/18551707/ee290f3a-7b59-11e6-8970-c6070eb43b44.png)


![Admix_LM.PC](https://cloud.githubusercontent.com/assets/12142475/18551706/ee284ea6-7b59-11e6-880f-dd8a3431d664.png)


Mid-High
```
vcftools --vcf subsetEAST.Final.2.vcf --keep pcadapt/MidHigh.names --recode --recode-INFO-all --out MidHigh_EAST

VCFtools - v0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf subsetEAST.Final.2.vcf
	--keep pcadapt/MidHigh.names
	--recode-INFO-all
	--out MidHigh_EAST
	--recode

Keeping individuals in 'keep' list
After filtering, kept 46 out of 118 Individuals
Outputting VCF file...
After filtering, kept 2358 out of a possible 2358 Sites
Run Time = 0.00 seconds

```

```
> path_to_MidHigh <- "/Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/MidHigh_EAST.recode.vcf"
> MidHigh <- read.pcadapt(path_to_MidHigh, type="vcf")
Summary:

        - input file      /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/MidHigh_EAST.recode.vcf
        - output file     /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/MidHigh_EAST.recode.pcadapt

	- number of individuals detected:	46
	- number of loci detected:		2358

For SNP info, please check /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/MidHigh_EAST.recode.vcfsnp.

0 line(s) have been removed because these are not SNPs.
Please, check /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/MidHigh_EAST.recode.removed file, for more information.

File has been sucessfully converted.
> x <- pcadapt(MidHigh,K=20,transpose=F)
Reading file /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/MidHigh_EAST.recode.pcadapt...
Number of SNPs: 2358
Number of individuals: 46
Number of SNPs with minor allele frequency lower than 0.05 ignored: 926
7188 out of 108468 missing data ignored.
> plot(x,option="screeplot")
> poplist <- read.table("/Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/midhigh.pop")
> plot(x,option="scores",pop=poplist)
Warning message:
In if (pop[i] != idx) { :
  the condition has length > 1 and only the first element will be used
```

![Admix_MH](https://cloud.githubusercontent.com/assets/12142475/18551704/ee26b2a8-7b59-11e6-88ec-0311416998d1.png)


![Admix_MH.PC](https://cloud.githubusercontent.com/assets/12142475/18551703/ee226a04-7b59-11e6-8617-0d966242a50e.png)



Low-High
```
vcftools --vcf subsetEAST.Final.2.vcf --keep pcadapt/LowHigh.names --recode --recode-INFO-all --out LowHigh_EAST

VCFtools - v0.1.14
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf subsetEAST.Final.2.vcf
	--keep pcadapt/LowHigh.names
	--recode-INFO-all
	--out LowHigh_EAST
	--recode

Keeping individuals in 'keep' list
After filtering, kept 62 out of 118 Individuals
Outputting VCF file...
After filtering, kept 2358 out of a possible 2358 Sites
Run Time = 0.00 seconds

```

```
> path_to_LowHigh <- "/Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/LowHigh_EAST.recode.vcf"
> LowHigh <- read.pcadapt(path_to_LowHigh, type="vcf")
Summary:

        - input file      /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/LowHigh_EAST.recode.vcf
        - output file     /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/LowHigh_EAST.recode.pcadapt

	- number of individuals detected:	62
	- number of loci detected:		2358

For SNP info, please check /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/LowHigh_EAST.recode.vcfsnp.

0 line(s) have been removed because these are not SNPs.
Please, check /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/LowHigh_EAST.recode.removed file, for more information.

File has been sucessfully converted.
> x <- pcadapt(LowHigh,K=20,transpose=F)
Reading file /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/LowHigh_EAST.recode.pcadapt...
Number of SNPs: 2358
Number of individuals: 62
Number of SNPs with minor allele frequency lower than 0.05 ignored: 902
10905 out of 146196 missing data ignored.
> plot(x,option="screeplot")
> poplist <- read.table("/Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/lowhigh.pop")
> plot(x,option="scores",pop=poplist)

```

![Admix_LH](https://cloud.githubusercontent.com/assets/12142475/18551705/ee27611c-7b59-11e6-873e-44d06d9add89.png)


![Admix_LH.PC](https://cloud.githubusercontent.com/assets/12142475/18551698/ee10dac8-7b59-11e6-92e4-a1e5e638b87b.png)


If I draw the PC plot specifying all of the populations: 


![allpops](https://cloud.githubusercontent.com/assets/12142475/18551699/ee110520-7b59-11e6-9ee5-f2ec041c5c02.png)


So Pizo is the outlier. 

I'm rerunning the PCA without pizo, followed by a PCAdapt analysis: 

```
> path_to_pizoless <- "/Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/LowHig_EAST.pizoless.recode.vcf"
> pizoless <- read.pcadapt(path_to_pizoless, type="vcf")
Summary:

        - input file      /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/LowHig_EAST.pizoless.recode.vcf
        - output file     /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/LowHig_EAST.pizoless.recode.pcadapt

	- number of individuals detected:	58
	- number of loci detected:		2358

For SNP info, please check /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/LowHig_EAST.pizoless.recode.vcfsnp.

0 line(s) have been removed because these are not SNPs.
Please, check /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/LowHig_EAST.pizoless.recode.removed file, for more information.

File has been sucessfully converted.
> x <- pcadapt(pizoless,K=20,transpose=F)
Reading file /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/LowHig_EAST.pizoless.recode.pcadapt...
Number of SNPs: 2358
Number of individuals: 58
Number of SNPs with minor allele frequency lower than 0.05 ignored: 900
10521 out of 136764 missing data ignored.
> plot(x,option="screeplot")
> poplist <- read.table("/Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/pizoless.pop")
> plot(x,option="scores",pop=poplist)
Warning message:
In if (pop[i] != idx) { :
  the condition has length > 1 and only the first element will be used

```

![pizoless](https://cloud.githubusercontent.com/assets/12142475/18551700/ee15286c-7b59-11e6-882e-7a83e6b6c97c.png)

![pizoless.PC](https://cloud.githubusercontent.com/assets/12142475/18551701/ee15b76e-7b59-11e6-9ac8-3ea00626cf74.png)


PCadapt
```
> x <- pcadapt(pizoless,K=2)
Reading file /Users/alexjvr/2016RADAnalysis/1.2_Phylo/OutlierAnalysis/LowHig_EAST.pizoless.recode.pcadapt...
Number of SNPs: 2358
Number of individuals: 58
Number of SNPs with minor allele frequency lower than 0.05 ignored: 900
10521 out of 136764 missing data ignored.
> summary(x)
                Length Class  Mode   
maf             2358   -none- numeric
loadings        4716   -none- numeric
singular.values    2   -none- numeric
scores           116   -none- numeric
zscores         4716   -none- numeric
stat            2358   -none- numeric
gif                1   -none- numeric
chi2.stat       2358   -none- numeric
pvalues         2358   -none- numeric
> plot(x,option="manhattan")
> plot(x,option="qqplot",threshold=0.1)
```

![manhattan.LH](https://cloud.githubusercontent.com/assets/12142475/18551702/ee193bf0-7b59-11e6-94f6-651d570834ed.png)


![qq.LH](https://cloud.githubusercontent.com/assets/12142475/18551697/ee103d20-7b59-11e6-9266-9dabfb2262dc.png)


```
> biocLite("qvalue")
> library(qvalue)
> qval <- qvalue(x$pvalues)$qvalues
> alpha <- 0.1
> outliers <- which(qval<alpha)
> print(outliers)
[1]  324 1430 1824
> snp_pc <- get.pc(x,outliers)
> head(snp_pc)
      SNP PC
[1,]  324  1
[2,] 1430  1
[3,] 1824  1

```

Three SNPs identified, all on PC1, which seemed to be the major High -Low PC. 






